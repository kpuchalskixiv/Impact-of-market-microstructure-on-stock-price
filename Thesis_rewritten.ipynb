{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as scs\n",
    "from sklearn.preprocessing import normalize as norm\n",
    "from sklearn import linear_model\n",
    "import datetime\n",
    "import time\n",
    "from datetime import datetime , timedelta\n",
    "\n",
    "import zipfile\n",
    "import math\n",
    "\n",
    "from csv import reader\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns;\n",
    "import re\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_companies_number = ['1080', '1113', '1221', '1229', '1243', '1388', '1431', '1472', '1694', '1769', '1865', '1907', '1956', '2028',\n",
    "                           '2050', '2051', '2057', '2094', '2197', '2290', '2368', '2645', '2651', '2730', '2748', '2813', '2822', '2890', \n",
    "                           '3022', '3035', '3107', '3161', '3388', '3459', '3757', '3879', '4060', '4154', '4218', '4320', '4481', \n",
    "                            '4549', '4575', '4618', '4695', '4736', '4799', '4851', '5836', '7843', '7858', '8080', '9034', '9058', '9061',\n",
    "                           '9062', '9063', '9064', '9065', '9067', '9069', '9074', '9086', '9094', '9265', '9266', '9268', '9269',\n",
    "                            '9270', '9761', '10166', '10470', '10484', '10508', '10795', '10887', '11038', '11234', '11244', '11390', '11399',\n",
    "                           '11583','11618','11714', '11867', '11869', '11946', '12059', '12098', '12255', '12327', '12417', '12456', '12534',\n",
    "                           '12552', '12713', '13003', '13061', '13113']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape = [(nr of company, every possible timeslot from 8.00 till 16.29, bid/ask, price/volume, 5 best offers from 9.15!))]\n",
    "data = np.zeros(shape = (100, 5100,2,2,5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_best_offers(record, k=5):\n",
    "    count = 0\n",
    "    count_bid = 0\n",
    "    count_ask = 0\n",
    "    k_best_bids_and_asks = np.zeros(shape = (2,2,k))\n",
    "    while(record[count]!='ASK'):\n",
    "        count+=1\n",
    "    for counter in range(1,k*2 + 1):\n",
    "        #bid\n",
    "        if record[count-counter]=='BID':\n",
    "            continue\n",
    "        k_best_bids_and_asks[0][counter%2][(counter-1)//2]=record[count-counter]\n",
    "        #ask\n",
    "        k_best_bids_and_asks[1][(counter-1)%2][(counter-1)//2]=record[count+counter]\n",
    "        \n",
    "    return k_best_bids_and_asks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mid_price(record): #shape = (2,2,5) (bid/ask, price/volume, best offers):\n",
    "    return (record[1][0][0]+record[0][0][0])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_price(record): # Qa*Pb/(Qa+Qb) + Qb*Pa/(Qa+Qb)\n",
    "    Qa=record[1][1][0] #ask quantity\n",
    "    Qb=record[0][1][0] #bid quantity\n",
    "    Q=Qa+Qb\n",
    "    Pa=record[1][0][0] #ask price\n",
    "    Pb=record[0][0][0] #bid price\n",
    "    return Qa*Pb/(Q+1e-10) + Qb*Pa/(Q+1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sweep_to_fill_price(record, order_size, midprice, sweep_buys=False): #record.shape=(2,2,5)\n",
    "    if sweep_buys:\n",
    "        record=record[0] # sweep buys\n",
    "    else:\n",
    "        record=record[1] # sweep asks\n",
    "    order_left = order_size\n",
    "    counter=0\n",
    "    weighted_price = 0\n",
    "    while order_left>0:\n",
    "        curr_vol = record[1][counter]\n",
    "        curr_price = record[0][counter]\n",
    "        if curr_vol >= order_left:\n",
    "            weighted_price+=order_left*curr_price\n",
    "            order_left =0\n",
    "        else:\n",
    "            weighted_price+=curr_vol*curr_price\n",
    "            order_left-=curr_vol\n",
    "        counter+=1\n",
    "        if counter==5:\n",
    "            print(\"Unable to fill an order\", order_size)\n",
    "            return midprice\n",
    "    return weighted_price/order_size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sweep_to_fill_price_raising_error(record, order_size, midprice, sweep_buys=False): #record.shape=(2,2,5)\n",
    "    if record.shape!=(2,2,5):\n",
    "        raise ValueError('Bad record shape!')\n",
    "    if order_size==0:\n",
    "        raise ValueError(\"Order size is 0\")\n",
    "    if sweep_buys:\n",
    "        record=record[0] # sweep buys\n",
    "    else:\n",
    "        record=record[1] # sweep asks\n",
    "    order_left = order_size\n",
    "    counter=0\n",
    "    weighted_price = 0\n",
    "    while order_left>0:\n",
    "        curr_vol = record[1][counter]\n",
    "        curr_price = record[0][counter]\n",
    "        if curr_vol >= order_left:\n",
    "            weighted_price+=order_left*curr_price\n",
    "            order_left =0\n",
    "        else:\n",
    "            weighted_price+=curr_vol*curr_price\n",
    "            order_left-=curr_vol\n",
    "        counter+=1\n",
    "        if counter==5:\n",
    "            raise ValueError(\"Unable to fill an order of size \" + str(order_size))\n",
    "    return weighted_price/order_size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PO co?\n",
    "def apply_moving_average(record, num_of_days_prev):\n",
    "    for i in range(num_of_days_prev, record.shape[0]):\n",
    "        record[i] = np.sum(record[i-num_of_days_prev+1:i+1])/num_of_days_prev\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_time(index):\n",
    "    hour=index//60\n",
    "    minute=index%60\n",
    "    return hour+8, minute, 0 \n",
    "# why minute+1???? was because orderbook[0] was from 8:01\n",
    "def time_tuple_to_hr_mn_str(time_tuple):\n",
    "    if time_tuple[0]<10:\n",
    "        hour='0'+str(time_tuple[0])\n",
    "    else:\n",
    "        hour=str(time_tuple[0])\n",
    "    if time_tuple[1]<10:\n",
    "        minute='0'+str(time_tuple[1])\n",
    "    else:\n",
    "        minute=str(time_tuple[1])\n",
    "    return hour+':'+minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADD valueerrors?\n",
    "\n",
    "def get_true_price_after_sweep_to_fill(record, order_size, midprice):\n",
    "    curr_record = record\n",
    "    order_left = order_size\n",
    "    counter=0\n",
    "    while order_left>0:\n",
    "        curr_vol = curr_record[1][1][counter]\n",
    "        if curr_vol >= order_left:\n",
    "            curr_record[1][1][counter]-=order_left\n",
    "            order_left =0\n",
    "            counter-=1\n",
    "        else:\n",
    "            curr_record[1][1][counter] = 0\n",
    "            order_left-=curr_vol\n",
    "        counter+=1\n",
    "        if counter==5:\n",
    "            print(\"Unable to fill an order\", order_size)\n",
    "            return midprice #???? bad?\n",
    "    Qa=0 #ask quantity\n",
    "    Qb=0 #bid quantity\n",
    "    Pa=0 #ask price\n",
    "    Pb=0 #bid price\n",
    "    row_in_queue = 0\n",
    "    while curr_record[1][1][row_in_queue]==0:\n",
    "        row_in_queue+=1\n",
    "    Qa=curr_record[1][1][row_in_queue]\n",
    "    Pa=curr_record[1][0][row_in_queue]\n",
    "    row_in_queue = 0\n",
    "    while curr_record[0][1][row_in_queue]==0:\n",
    "        row_in_queue+=1\n",
    "    Qb=curr_record[0][1][row_in_queue] \n",
    "    Q=Qa+Qb \n",
    "    Pb=curr_record[0][0][row_in_queue] \n",
    "    return Qa*Pb/Q + Qb*Pa/Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def get_order_inbalance(record): #single company\\n    \\n    timestamps=record.shape[0]\\n    result=np.zeros(timestamps)\\n    for i in range (0,timestamps):\\n        result[i]=math.log((1e-10+np.sum(record[i][0][1]))/(1e-10+np.sum(record[i][1][1]))) # ln(bid size/ask size)\\n    return result'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def get_order_inbalance(record): #single company\n",
    "    \n",
    "    timestamps=record.shape[0]\n",
    "    result=np.zeros(timestamps)\n",
    "    for i in range (0,timestamps):\n",
    "        result[i]=math.log((1e-10+np.sum(record[i][0][1]))/(1e-10+np.sum(record[i][1][1]))) # ln(bid size/ask size)\n",
    "    return result'''\n",
    "#uhmmm wrong func???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read order books into data\n",
    "mom_count = 0\n",
    "count_comp = -1\n",
    "for num_comp in list_of_companies_number:\n",
    "    with open('FTSE100\\OrderBookSnapshots.csv.'+num_comp+'\\OrderBookSnapshots.csv', 'r') as read_obj:\n",
    "        csv_reader = reader(read_obj)\n",
    "        count = 0\n",
    "        count_comp+=1\n",
    "        prev_hour = 8\n",
    "        prev_date = '20130902'\n",
    "        prev_min=0\n",
    "        prev_elements = []\n",
    "        for row in csv_reader:\n",
    "            elements = row[0].split('\\t')\n",
    "            date_time = elements[0]\n",
    "            date_holder, time_holder = date_time.split(' ')\n",
    "            if date_holder != prev_date:\n",
    "                prev_hour = 8\n",
    "                prev_min=0\n",
    "            cur_hour = int(time_holder[:2])\n",
    "            cur_min = int(time_holder[2:4])\n",
    "            if((cur_hour==8 and cur_min>=0) or (cur_hour>8 and cur_hour<16) or (cur_hour==16 and cur_min<30)):\n",
    "                data[count_comp][count] = get_k_best_offers(elements[1:])  \n",
    "                count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad acting day or data, please check both\n",
      " 1 30\n",
      "854.5066 4596 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 1 8\n",
      "900.0 4848 (0, 0, 0)\n",
      "Bad acting day or data, please check both\n",
      " 2 30\n",
      "561.9 670 (9, 52, 54)\n",
      "Bad acting day or data, please check both\n",
      " 2 30\n",
      "561.9 670 (9, 52, 54)\n",
      "Bad acting day or data, please check both\n",
      " 2 30\n",
      "561.9 670 (9, 52, 54)\n",
      "Bad acting day or data, please check both\n",
      " 3 30\n",
      "841.9143 11354 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 5 30\n",
      "389.3276 3223 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 7 30\n",
      "435.4457 4675 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 9 30\n",
      "2146.5318 1115 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 12 30\n",
      "290.7493 3328 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 13 30\n",
      "120.01 100 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 16 30\n",
      "1103.1111 414 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 17 30\n",
      "1090.5 25000 (17, 37, 50)\n",
      "Bad acting day or data, please check both\n",
      " 20 30\n",
      "761.5762 1273 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 28 30\n",
      "388.2389 2494 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 33 30\n",
      "745.615 6954 (11, 16, 0)\n",
      "Bad acting day or data, please check both\n",
      " 33 30\n",
      "746.103 56 (12, 23, 13)\n",
      "Bad acting day or data, please check both\n",
      " 33 29\n",
      "748.037 129 (9, 39, 43)\n",
      "Bad acting day or data, please check both\n",
      " 36 30\n",
      "332.2 30000 (17, 37, 50)\n",
      "Bad acting day or data, please check both\n",
      " 36 30\n",
      "332.6677 7933 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 37 30\n",
      "1142.0 25668 (10, 22, 56)\n",
      "Bad acting day or data, please check both\n",
      " 39 30\n",
      "3106.0435 1264 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 41 30\n",
      "344.4019 22331 (17, 36, 9)\n",
      "Bad acting day or data, please check both\n",
      " 41 30\n",
      "345.3792 394 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 42 30\n",
      "963.9644 2979 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 43 30\n",
      "4406.4336 339 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 46 30\n",
      "1316.884639 373000 (16, 42, 31)\n",
      "Bad acting day or data, please check both\n",
      " 48 30\n",
      "2386.7272 205 (13, 53, 33)\n",
      "Bad acting day or data, please check both\n",
      " 49 30\n",
      "527.0 4000 (8, 16, 27)\n",
      "Bad acting day or data, please check both\n",
      " 53 30\n",
      "1886.8738 310 (12, 25, 29)\n",
      "Bad acting day or data, please check both\n",
      " 53 30\n",
      "1884.1885 870 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 54 30\n",
      "676.6412 4391 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 54 29\n",
      "686.48283407 100000 (16, 5, 28)\n",
      "Bad acting day or data, please check both\n",
      " 55 30\n",
      "2937.5454 335 (10, 29, 6)\n",
      "Bad acting day or data, please check both\n",
      " 55 30\n",
      "2937.5454 125 (10, 29, 6)\n",
      "Bad acting day or data, please check both\n",
      " 55 30\n",
      "2923.7786 3877 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 56 30\n",
      "446.9086 5806 (12, 37, 10)\n",
      "Bad acting day or data, please check both\n",
      " 56 30\n",
      "447.1229 30490 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 57 28\n",
      "72.0 7000 (10, 23, 10)\n",
      "Bad acting day or data, please check both\n",
      " 58 30\n",
      "1657.914 3619 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 58 27\n",
      "1677.1818 650 (11, 30, 47)\n",
      "Bad acting day or data, please check both\n",
      " 59 28\n",
      "3208.9546 666 (13, 58, 12)\n",
      "Bad acting day or data, please check both\n",
      " 59 30\n",
      "3190.1951 606 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 60 30\n",
      "283.6 3000 (15, 38, 47)\n",
      "Bad acting day or data, please check both\n",
      " 60 30\n",
      "282.9 440 (10, 39, 12)\n",
      "Bad acting day or data, please check both\n",
      " 60 30\n",
      "282.5563 12084 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 61 30\n",
      "2094.3232 793 (11, 8, 18)\n",
      "Bad acting day or data, please check both\n",
      " 62 30\n",
      "205.74794027 4191940 (16, 43, 13)\n",
      "Bad acting day or data, please check both\n",
      " 62 30\n",
      "208.6 2000000 (22, 0, 0)\n",
      "Bad acting day or data, please check both\n",
      " 62 30\n",
      "208.77 1000000 (22, 0, 0)\n",
      "Bad acting day or data, please check both\n",
      " 62 30\n",
      "208.73 3000000 (22, 0, 0)\n",
      "Bad acting day or data, please check both\n",
      " 62 30\n",
      "206.25 450000 (18, 1, 55)\n",
      "Bad acting day or data, please check both\n",
      " 62 30\n",
      "207.1 347820 (17, 41, 35)\n",
      "Bad acting day or data, please check both\n",
      " 62 30\n",
      "206.375 32450 (17, 21, 18)\n",
      "Bad acting day or data, please check both\n",
      " 62 30\n",
      "207.9856 827298 (16, 41, 3)\n",
      "Bad acting day or data, please check both\n",
      " 64 30\n",
      "3280.91400957 22142 (9, 5, 34)\n",
      "Bad acting day or data, please check both\n",
      " 64 30\n",
      "3280.91399728 77858 (9, 5, 48)\n",
      "Bad acting day or data, please check both\n",
      " 64 30\n",
      "3280.0 6675 (13, 42, 6)\n",
      "Bad acting day or data, please check both\n",
      " 64 30\n",
      "3275.8291 313 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 64 29\n",
      "3280.91399728 77858 (9, 5, 48)\n",
      "Bad acting day or data, please check both\n",
      " 64 29\n",
      "3280.91399728 77858 (9, 5, 48)\n",
      "Bad acting day or data, please check both\n",
      " 64 29\n",
      "3280.91400957 22142 (9, 5, 34)\n",
      "Bad acting day or data, please check both\n",
      " 64 29\n",
      "3280.91400957 22142 (9, 5, 34)\n",
      "Bad acting day or data, please check both\n",
      " 65 30\n",
      "1451.4855 27555 (9, 42, 26)\n",
      "Bad acting day or data, please check both\n",
      " 65 29\n",
      "1445.88182371 618812 (15, 29, 34)\n",
      "Bad acting day or data, please check both\n",
      " 67 30\n",
      "371.03025232 1811319 (8, 54, 46)\n",
      "Bad acting day or data, please check both\n",
      " 67 30\n",
      "372.125 2370 (8, 25, 8)\n",
      "Bad acting day or data, please check both\n",
      " 67 29\n",
      "370.95133883 370800 (8, 55, 19)\n",
      "Bad acting day or data, please check both\n",
      " 67 29\n",
      "372.80509784 2182119 (8, 56, 5)\n",
      "Bad acting day or data, please check both\n",
      " 67 30\n",
      "372.29 100 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 67 29\n",
      "370.95133883 370800 (8, 55, 19)\n",
      "Bad acting day or data, please check both\n",
      " 68 28\n",
      "2211.64 65 (9, 16, 56)\n",
      "Bad acting day or data, please check both\n",
      " 68 29\n",
      "2200.2463 187 (14, 43, 51)\n",
      "Bad acting day or data, please check both\n",
      " 68 30\n",
      "2180.61 200 (11, 34, 31)\n",
      "Bad acting day or data, please check both\n",
      " 68 30\n",
      "2180.61 4327 (11, 34, 31)\n",
      "Bad acting day or data, please check both\n",
      " 70 30\n",
      "3086.3073 218 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 74 29\n",
      "1397.1372 11147 (16, 54, 47)\n",
      "Bad acting day or data, please check both\n",
      " 74 29\n",
      "1397.1372 1065 (16, 53, 0)\n",
      "Bad acting day or data, please check both\n",
      " 76 30\n",
      "1000.178 66166 (16, 50, 7)\n",
      "Bad acting day or data, please check both\n",
      " 76 30\n",
      "1000.178 62030 (16, 50, 35)\n",
      "Bad acting day or data, please check both\n",
      " 77 30\n",
      "1118.3636 525 (15, 12, 35)\n",
      "Bad acting day or data, please check both\n",
      " 77 30\n",
      "1117.6862 525 (12, 23, 33)\n",
      "Bad acting day or data, please check both\n",
      " 77 30\n",
      "1118.3636 525 (15, 12, 35)\n",
      "Bad acting day or data, please check both\n",
      " 77 30\n",
      "1118.3636 525 (15, 12, 35)\n",
      "Bad acting day or data, please check both\n",
      " 78 30\n",
      "306.7 25000 (10, 3, 36)\n",
      "Bad acting day or data, please check both\n",
      " 78 30\n",
      "308.0 2000 (14, 55, 6)\n",
      "Bad acting day or data, please check both\n",
      " 78 30\n",
      "305.43 800 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 78 30\n",
      "305.2 45000 (15, 38, 34)\n",
      "Bad acting day or data, please check both\n",
      " 81 30\n",
      "1986.5 112 (10, 8, 43)\n",
      "Bad acting day or data, please check both\n",
      " 81 30\n",
      "2015.2017 962 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 81 30\n",
      "1991.5 3558 (9, 22, 8)\n",
      "Bad acting day or data, please check both\n",
      " 83 30\n",
      "1369.2804 47676 (16, 41, 49)\n",
      "Bad acting day or data, please check both\n",
      " 83 30\n",
      "1378.0662 4051 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 87 30\n",
      "333.8 100000 (17, 37, 53)\n",
      "Bad acting day or data, please check both\n",
      " 87 30\n",
      "334.7 25000 (17, 37, 53)\n",
      "Bad acting day or data, please check both\n",
      " 87 30\n",
      "336.8 70000 (17, 37, 53)\n",
      "Bad acting day or data, please check both\n",
      " 87 30\n",
      "335.4 30000 (17, 37, 53)\n",
      "Bad acting day or data, please check both\n",
      " 87 30\n",
      "336.3197 3964 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 87 29\n",
      "334.6435917 30 (6, 59, 55)\n",
      "Bad acting day or data, please check both\n",
      " 88 30\n",
      "1138.631 159393 (9, 58, 50)\n",
      "Bad acting day or data, please check both\n",
      " 88 30\n",
      "1138.631 64200 (9, 58, 50)\n",
      "Bad acting day or data, please check both\n",
      " 88 30\n",
      "1138.631 4600 (9, 58, 50)\n",
      "Bad acting day or data, please check both\n",
      " 93 30\n",
      "1230.6306 2428 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 94 30\n",
      "489.8 25000 (14, 59, 55)\n",
      "Bad acting day or data, please check both\n",
      " 94 30\n",
      "489.8 25000 (15, 0, 30)\n",
      "Bad acting day or data, please check both\n",
      " 94 30\n",
      "489.3481 582 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 94 30\n",
      "489.4 143 (13, 15, 7)\n",
      "Bad acting day or data, please check both\n",
      " 95 30\n",
      "1233.7687 33910 (17, 36, 9)\n",
      "Bad acting day or data, please check both\n",
      " 95 30\n",
      "1223.6211 190 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 96 30\n",
      "417.890945 110000 (17, 37, 51)\n",
      "Bad acting day or data, please check both\n",
      " 96 30\n",
      "418.9415 1011 (7, 5, 24)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad acting day or data, please check both\n",
      " 97 30\n",
      "345.1342 1168 (7, 5, 24)\n",
      "Bad acting day or data, please check both\n",
      " 98 30\n",
      "1596.4102 231 (7, 5, 24)\n"
     ]
    }
   ],
   "source": [
    "# read trades into trades\n",
    "days={\n",
    "    2:0,\n",
    "    3:1,\n",
    "    4:2,\n",
    "    5:3,\n",
    "    6:4,\n",
    "    9:5,\n",
    "    10:6,\n",
    "    11:7,\n",
    "    12:8,\n",
    "    13:9,\n",
    "}\n",
    "if_first_row = True\n",
    "which_comp = 0\n",
    "\n",
    "#comp = list_of_companies_number\n",
    "comp = list_of_companies_number\n",
    "comp_id = -1\n",
    "trades = np.empty( shape=(len(comp), 10), dtype = list)\n",
    "for i in range(trades.shape[0]):\n",
    "    for j in range(10):\n",
    "        trades[i,j]=list()\n",
    "for num_comp in comp:\n",
    "    comp_id+=1\n",
    "    if_first_row = True\n",
    "    with open('FTSE100trades\\TradeDetailsExtract.'+num_comp+'.csv', 'r') as read_obj:\n",
    "        csv_reader = reader(read_obj)\n",
    "        for row in csv_reader:\n",
    "            if if_first_row:\n",
    "                if_first_row = False\n",
    "                continue\n",
    "            date = row[4]\n",
    "            date_elem = date.split(\" \")\n",
    "            act_day = int(date_elem[0][8:10])\n",
    "            time_tuple=time.strptime(date_elem[1], '%H:%M:%S')\n",
    "            time_tuple=(time_tuple.tm_hour, time_tuple.tm_min, time_tuple.tm_sec)\n",
    "          #  trades=np.append(trades, (row[2], row[3], time_tuple),  axis=1)\n",
    "            #print(\"XD\", comp_id, act_day, date_elem, row[2], row[3], time_tuple)\n",
    "            try:\n",
    "                trades[comp_id][days[act_day]].append((float(row[2]), int(row[3]), time_tuple)) # price, volume, timestamp\n",
    "            except:\n",
    "                print(\"Bad acting day or data, please check both\\n\", comp_id, act_day)\n",
    "                print((row[2]), (row[3]), time_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5100, 2, 2, 5)\n",
      "(99, 10)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(trades.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameters calculation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DONT USE VVV\n",
    "def get_order_inbalance_interval_bad(record, interval=1): #interval in minutes\n",
    "    timestamps=record.shape[0]//interval\n",
    "    result=np.zeros(timestamps)\n",
    "    for i in range (0,timestamps):\n",
    "        for j in range(interval):\n",
    "            #print(np.sum(record[i:i+interval,0,1]))\n",
    "            result[i]+=math.log((1e-10+np.sum(record[i+j][0][1]))/(1e-10+np.sum(record[i+j][1][1]))) # ln(bid size/ask size)\n",
    "    return result\n",
    "###DONT USE AAAA\n",
    "\n",
    "def get_order_inbalance_interval(record, interval=1): #interval in minutes\n",
    "    timestamps=record.shape[0]//interval\n",
    "    result=np.zeros(timestamps)\n",
    "    for i in range (0,timestamps):\n",
    "        pom=i*interval\n",
    "        result[i]=math.log((1e-10+np.sum(record[pom:pom+interval,0,1]))/(1e-10+np.sum(record[pom:pom+interval,1,1]))) # ln(bid size/ask size)\n",
    "    return result\n",
    "\n",
    "def get_order_inbalance_comp(comp_id=1, interval=1, time_to_skip=0): #interval in minutes\n",
    "    order_inbalance_comp=np.empty(shape=(10,(510-time_to_skip)//interval))\n",
    "    for i in range(10): #we have data from 10 days, 2 work weeks\n",
    "        order_inbalance_comp[i]=get_order_inbalance_interval(data[comp_id, 510*i+time_to_skip:510*(i+1)], interval)\n",
    "    return order_inbalance_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1504.,  466., 2115., 8682.,  667.],\n",
       "       [3396.,  701., 2615., 8682.,  501.],\n",
       "       [3582.,  701., 2115., 8682., 1001.],\n",
       "       [3323., 3262., 3146., 9713., 2032.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pom=data[3, 510:510*(2)]\n",
    "pom[1:5,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07873018, -0.06199148,  0.19954649, -0.03546426,  0.01784012,\n",
       "       -0.08710945, -0.2216419 , -0.25986639])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_order_inbalance_comp(interval=60, time_to_skip=30)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07873018, -0.06199148,  0.19954649, -0.03546426,  0.01784012,\n",
       "       -0.08710945, -0.2216419 , -0.25986639])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_order_inbalance_comp(interval=60, time_to_skip=30)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vwap_and_ordersizes_comp(comp_id=3, interval=5, time_to_skip=0, use_abs=True, max_vol=math.inf):\n",
    "    order_book_comp=np.empty(shape=(10, 510-time_to_skip, 2, 2, 5))\n",
    "    for i in range(10): #we have data from 10 days, 2 work weeks\n",
    "        order_book_comp[i]=data[comp_id, 510*i+time_to_skip:510*(i+1)]\n",
    "\n",
    "    trades_time_comp=np.copy(trades[comp_id])\n",
    "    for day in trades_time_comp:\n",
    "        day.sort(key=lambda hour: hour[2]) # sort by trade time\n",
    "\n",
    "    timestamps=(510-time_to_skip)//interval\n",
    "    # buys on even, sells on odd\n",
    "    vwaps=np.zeros(shape=(10,2*timestamps)) \n",
    "    order_sizes=np.zeros(shape=(10,2*timestamps))\n",
    "    #vwaps_sells=np.zeros(shape=(10,timestamps))\n",
    "    empty_sells=0\n",
    "    empty_buys=0\n",
    "   # last_time=index_to_time(0)\n",
    "    for day in range(vwaps.shape[0]):\n",
    "        trade_counter=0\n",
    "        skip_time_tuple=index_to_time(time_to_skip)\n",
    "        while skip_time_tuple>trades_time_comp[day][trade_counter][2]:\n",
    "            trade_counter+=1\n",
    "        for counter in range(timestamps):\n",
    "            true_price=get_true_price(order_book_comp[day,counter])\n",
    "            time_tuple=index_to_time(time_to_skip+interval*(counter+1))\n",
    "            last_time=time_tuple\n",
    "            buys=[]\n",
    "            sells=[]\n",
    "            buys_weights=[]\n",
    "            sells_weights=[]\n",
    "            while time_tuple>trades_time_comp[day][trade_counter][2]:\n",
    "                if true_price<trades_time_comp[day][trade_counter][0]:\n",
    "                    buys.append(trades_time_comp[day][trade_counter][0])\n",
    "                    buys_weights.append(trades_time_comp[day][trade_counter][1])\n",
    "                else:\n",
    "                    sells.append(trades_time_comp[day][trade_counter][0])\n",
    "                    sells_weights.append(trades_time_comp[day][trade_counter][1])               \n",
    "                trade_counter+=1\n",
    "            try:\n",
    "                buys_avg, buys_vol=np.average(buys, weights=buys_weights, returned=True)\n",
    "                vwaps[day,2*counter]=buys_avg-true_price\n",
    "            except:\n",
    "                buys_avg=true_price\n",
    "                buys_vol=0\n",
    "                empty_buys+=1\n",
    "                vwaps[day,2*counter]=math.nan\n",
    "            try:\n",
    "                sells_avg, sells_vol=np.average(sells, weights=sells_weights, returned=True)\n",
    "                if use_abs:\n",
    "                    vwaps[day,2*counter +1]=true_price-sells_avg\n",
    "                else:\n",
    "                    vwaps[day,2*counter +1]=sells_avg-true_price \n",
    "            except:\n",
    "                sells_avg=true_price\n",
    "                sells_vol=0\n",
    "                empty_sells+=1\n",
    "                vwaps[day,2*counter +1]=math.nan\n",
    "            if sells_vol>max_vol:\n",
    "               # print(day, time_tuple)\n",
    "                sells_vol=math.nan\n",
    "            if buys_vol>max_vol:\n",
    "                #print(day, time_tuple)\n",
    "                buys_vol=math.nan \n",
    "                           \n",
    "            order_sizes[day,2*counter]=buys_vol\n",
    "            order_sizes[day,2*counter +1]=sells_vol\n",
    "  #  print('{}% of intervals were SELL empty'.format(100*empty_sells/(10*2*timestamps)))\n",
    "   # print('{}% of intervals were BUY empty'.format(100*empty_buys/(10*2*timestamps)))    \n",
    "  #  print(last_time)\n",
    "    return vwaps, order_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_trade_x_comp(comp_id=3, interval=5, time_to_skip=0, get_x='price'):\n",
    "\n",
    "    order_book_comp=np.empty(shape=(10, 510-time_to_skip, 2, 2, 5))\n",
    "    for i in range(10): #we have data from 10 days, 2 work weeks\n",
    "        order_book_comp[i]=data[comp_id, 510*i+time_to_skip:510*(i+1)]\n",
    "\n",
    "    trades_time_comp=np.copy(trades[comp_id])\n",
    "    for day in trades_time_comp:\n",
    "        day.sort(key=lambda hour: hour[2]) # sort by trade time\n",
    "    timestamps=(510-time_to_skip)//interval\n",
    "        \n",
    "    next_trade_x=np.empty(shape=(10,timestamps))\n",
    "    for day in range(next_trade_x.shape[0]):\n",
    "        trade_counter=0\n",
    "        start_time=index_to_time(0+time_to_skip)\n",
    "        while start_time>=trades_time_comp[day][trade_counter][2]:\n",
    "            trade_counter+=1\n",
    "        for book_counter in range(timestamps):            \n",
    "            time_tuple=index_to_time(time_to_skip+book_counter*interval)\n",
    "            while time_tuple>=trades_time_comp[day][trade_counter][2]:\n",
    "                trade_counter+=1\n",
    "            if get_x=='price':\n",
    "                next_trade_price=trades_time_comp[day][trade_counter][0]\n",
    "                true_price=get_true_price(order_book_comp[day, book_counter])\n",
    "                next_trade_x[day, book_counter]=(next_trade_price-true_price) #no abs\n",
    "                #why abs?#abs(nexttradeprice-trueprice)\n",
    "            elif get_x=='size':\n",
    "                next_trade_size=trades_time_comp[day][trade_counter][1]\n",
    "                next_trade_x[day, book_counter]=next_trade_size                \n",
    "            elif get_x=='time':\n",
    "                trade_time_tuple=trades_time_comp[day][trade_counter][2]\n",
    "                next_trade_x[day, book_counter]=(timedelta(hours=trade_time_tuple[0],minutes=trade_time_tuple[1],seconds=trade_time_tuple[2])\n",
    "                                                 -timedelta(hours=time_tuple[0],minutes=time_tuple[1],seconds=time_tuple[2])).seconds\n",
    "            # time to next trade given in seconds\n",
    "            else:\n",
    "                raise ValueError(\"trying to get nonexisting parameter\")\n",
    "    return next_trade_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s2f_impact_and_ordersizes_comp(comp_id=3, interval=5, time_to_skip=0, use_abs=True):\n",
    "    order_book_comp=np.empty(shape=(10, 510-time_to_skip, 2, 2, 5))\n",
    "    for i in range(10): #we have data from 10 days, 2 work weeks\n",
    "        order_book_comp[i]=data[comp_id, 510*i+time_to_skip:510*(i+1)]\n",
    "\n",
    "    trades_time_comp=np.copy(trades[comp_id])\n",
    "    for day in trades_time_comp:\n",
    "        day.sort(key=lambda hour: hour[2]) # sort by trade time\n",
    "\n",
    "    timestamps=(510-time_to_skip)//interval\n",
    "    # buys on even, sells on odd\n",
    "    s2f_impacts=np.zeros(shape=(10,2*timestamps)) \n",
    "    order_sizes=np.zeros(shape=(10,2*timestamps))\n",
    "    #s2f_impacts_sells=np.zeros(shape=(10,timestamps))\n",
    "    empty_sells=0\n",
    "    empty_buys=0\n",
    "    for day in range(s2f_impacts.shape[0]):\n",
    "        trade_counter=0\n",
    "        skip_time_tuple=index_to_time(time_to_skip)\n",
    "        while skip_time_tuple>trades_time_comp[day][trade_counter][2]:\n",
    "            trade_counter+=1\n",
    "        for counter in range(s2f_impacts.shape[1]//2):\n",
    "            true_price=get_true_price(order_book_comp[day,counter])   # true price at start of the intertval, as in pdf\n",
    "            time_tuple=index_to_time(time_to_skip+interval*(counter+1))\n",
    "            buys_weights=[]\n",
    "            sells_weights=[]\n",
    "            while time_tuple>trades_time_comp[day][trade_counter][2]:\n",
    "                if true_price<trades_time_comp[day][trade_counter][0]:\n",
    "                    buys_weights.append(trades_time_comp[day][trade_counter][1])\n",
    "                else:\n",
    "                    sells_weights.append(trades_time_comp[day][trade_counter][1])               \n",
    "                trade_counter+=1\n",
    "            try:\n",
    "                buys_vol=np.sum(buys_weights)\n",
    "                # when buying we sweep asks\n",
    "                buys_s2f_price=get_sweep_to_fill_price_raising_error(order_book_comp[day,counter], buys_vol, true_price, sweep_buys=False)  # order book at start of the intertval, as in pdf\n",
    "                s2f_impacts[day,2*counter]=buys_s2f_price-true_price\n",
    "            except ValueError:\n",
    "                buys_s2f_price=true_price\n",
    "                buys_vol=0\n",
    "                empty_buys+=1\n",
    "                s2f_impacts[day,2*counter]=math.nan\n",
    "            try:\n",
    "                sells_vol=np.sum(sells_weights)\n",
    "                # when selling we sweep buys\n",
    "                sells_s2f_price=get_sweep_to_fill_price_raising_error(order_book_comp[day,counter], sells_vol, true_price, sweep_buys=True)\n",
    "                if use_abs:\n",
    "                    s2f_impacts[day,2*counter +1]=true_price-sells_s2f_price\n",
    "                else:\n",
    "                    s2f_impacts[day,2*counter +1]=sells_s2f_price-true_price \n",
    "            except ValueError:\n",
    "                sells_s2f_price=true_price\n",
    "                sells_vol=0\n",
    "                empty_sells+=1\n",
    "                s2f_impacts[day,2*counter +1]=math.nan\n",
    "         #   if sells_vol>10000 or buys_vol>10000: #discard super high volumes,\n",
    "          #      continue \n",
    "                           \n",
    "            order_sizes[day,2*counter]=buys_vol\n",
    "            order_sizes[day,2*counter +1]=sells_vol\n",
    "  #  print('{}% of intervals were SELL empty'.format(100*empty_sells/(10*2*timestamps)))\n",
    "   # print('{}% of intervals were BUY empty'.format(100*empty_buys/(10*2*timestamps)))    \n",
    "    return s2f_impacts, order_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prices on the start of interval\n",
    "def get_true_price_comp(comp_id=1, interval=1, time_to_skip=0): #interval in minutes\n",
    "    true_price_comp=np.empty(shape=(10,(510-time_to_skip)//interval))\n",
    "    timestamps=(510-time_to_skip)//interval\n",
    "    for i in range(10): #we have data from 10 days, 2 work weeks\n",
    "        for j in range(timestamps):\n",
    "            true_price_comp[i,j]=get_true_price(data[comp_id, 510*i+time_to_skip+j*interval])\n",
    "    return true_price_comp\n",
    "\n",
    "def get_mid_price_comp(comp_id=1, interval=1, time_to_skip=0): #interval in minutes\n",
    "    mid_price_comp=np.empty(shape=(10,(510-time_to_skip)//interval))\n",
    "    timestamps=(510-time_to_skip)//interval\n",
    "    for i in range(10): #we have data from 10 days, 2 work weeks\n",
    "        for j in range(timestamps):\n",
    "            mid_price_comp[i,j]=get_mid_price(data[comp_id, 510*i+time_to_skip+j*interval])\n",
    "    return mid_price_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_change_comp(comp_id=1, interval=1, time_to_skip=0, use_true_price=True): #interval in minutes\n",
    "    if use_true_price:\n",
    "        prices=np.asarray([get_true_price(data[comp_id][i]) for i in range (5100)])\n",
    "    else:\n",
    "        prices=np.asarray([get_mid_price(data[comp_id][i]) for i in range (5100)])\n",
    "    \n",
    "    timestamps=(510-time_to_skip)//interval\n",
    "    price_diff=np.empty(shape=(10,timestamps))\n",
    "    for i in range(10):\n",
    "        for t in range(1,timestamps):\n",
    "            pom=i*510 + time_to_skip + t\n",
    "            price_diff[i,j]=prices[pom]-prices[pom-interval]\n",
    "    return price_diff\n",
    "    #inbalance_averageprice={}\n",
    "    #for i in range(len(price_diff)):\n",
    "    #    if order_inbalance_10_days[i] in inbalance_averageprice.keys():\n",
    "    #        inbalance_averageprice[order_inbalance_10_days[i]].append(price_diff[i])\n",
    "    #    else:\n",
    "    #        inbalance_averageprice[order_inbalance_10_days[i]]=[price_diff[i]]\n",
    "    #for k in inbalance_averageprice.keys():\n",
    "    #    inbalance_averageprice[k]=np.average(np.asarray(inbalance_averageprice[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_change_given_prices(prices): ### zero on start of the day\n",
    "    if len(prices.shape)!=2:\n",
    "        raise ValueError('bad shape')\n",
    "    price_change=np.zeros(shape=prices.shape)\n",
    "    for day in range(prices.shape[0]):\n",
    "        for i in range(1, prices.shape[1]):\n",
    "            price_change[day,i]=prices[day, i]-prices[day, i-1]\n",
    "    return price_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trading_volume_and_price_volatility(company_id, interval = 5, time_to_skip = 0):\n",
    "    how_many_days = trades[company_id].shape[0]\n",
    "    num_of_interval_buck = (510-time_to_skip)//interval\n",
    "    trading_volume_in_buckets = np.zeros(shape = (10, num_of_interval_buck))\n",
    "    price_volatility_in_buckets = np.zeros(shape = (10, num_of_interval_buck))\n",
    "    start_time=(8,time_to_skip,0)\n",
    "    end_time=(16,29,0)\n",
    "    for i in range(how_many_days): #for every day\n",
    "        min_prices_in_buckets = np.ones(num_of_interval_buck) * 1e7\n",
    "        max_prices_in_buckets = np.zeros(num_of_interval_buck)\n",
    "        for trade in trades[company_id][i]:\n",
    "            trade_time = trade[2]\n",
    "            if trade_time<start_time and trade_time>end_time:\n",
    "                continue\n",
    "            which_bucket =np.dot(np.asarray(trade_time)-np.asarray(start_time), [60,1,0])//interval\n",
    "            if(which_bucket>=num_of_interval_buck):\n",
    "                which_bucket=num_of_interval_buck-1\n",
    "            #print(\"XD\", company_id, i, trade, which_bucket)\n",
    "            min_prices_in_buckets[which_bucket] = min(float(min_prices_in_buckets[which_bucket]), float(trade[0]))\n",
    "            max_prices_in_buckets[which_bucket] = max(float(max_prices_in_buckets[which_bucket]), float(trade[0]))\n",
    "            trading_volume_in_buckets[i][which_bucket] += trade[1]\n",
    "        price_volatility_in_buckets[i] = max_prices_in_buckets - min_prices_in_buckets\n",
    "    return trading_volume_in_buckets, price_volatility_in_buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HEATMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 480)\n",
      "(10, 480)\n",
      "(10, 480)\n",
      "(10, 480)\n",
      "(10, 480)\n",
      "(10, 480)\n",
      "(10, 480)\n",
      "(10, 480)\n",
      "(10, 480)\n",
      "(10, 480)\n",
      "(10, 480)\n",
      "(10, 480) (10, 480) (10, 480)\n",
      "(10, 480)\n"
     ]
    }
   ],
   "source": [
    "comp_id = 3\n",
    "interval=1\n",
    "time_to_skip=30\n",
    "\n",
    "mid_price = get_mid_price_comp(comp_id, interval, time_to_skip)\n",
    "print(mid_price.shape)\n",
    "true_price = get_true_price_comp(comp_id, interval, time_to_skip)\n",
    "print(true_price.shape)\n",
    "order_inbalance = get_order_inbalance_comp(comp_id, interval, time_to_skip)\n",
    "#order_inbalance = order_inbalance.reshape(10,-1)\n",
    "print(order_inbalance.shape)\n",
    "vwaps, order_sizes = get_vwap_and_ordersizes_comp(comp_id, interval, time_to_skip)\n",
    "vwaps_buy = vwaps[:,::2]\n",
    "vwaps_sell = vwaps[:,1::2]\n",
    "print(vwaps_buy.shape)\n",
    "print(vwaps_sell.shape)\n",
    "s2f_impact, order_sizes = get_s2f_impact_and_ordersizes_comp(comp_id, interval, time_to_skip)\n",
    "s2f_impact_buy = s2f_impact[:,::2]\n",
    "s2f_impact_sell = s2f_impact[:,1::2]\n",
    "print(s2f_impact_buy.shape)\n",
    "print(s2f_impact_sell.shape)\n",
    "order_sizes_buy = order_sizes[:,::2]\n",
    "order_sizes_sell = order_sizes[:,1::2]\n",
    "print(order_sizes_buy.shape)\n",
    "print(order_sizes_sell.shape)\n",
    "trading_volumes, price_volatilities = get_trading_volume_and_price_volatility(comp_id, interval, time_to_skip)\n",
    "print(trading_volumes.shape)\n",
    "print(price_volatilities.shape)\n",
    "next_trade_time=get_next_trade_x_comp(comp_id, interval, time_to_skip, get_x='time')\n",
    "next_trade_size=get_next_trade_x_comp(comp_id, interval, time_to_skip, get_x='size')\n",
    "next_trade_price=get_next_trade_x_comp(comp_id, interval, time_to_skip, get_x='price')\n",
    "price_change=get_price_change_given_prices(true_price)\n",
    "print(next_trade_time.shape, next_trade_size.shape, next_trade_price.shape)\n",
    "print(price_change.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "                'mid_price': mid_price.flatten(), \n",
    "                'true_price': true_price.flatten(), \n",
    "                'order_inbalance': order_inbalance.flatten(), \n",
    "                'vwaps_buy': vwaps_buy.flatten(), \n",
    "                'vwaps_sell': vwaps_sell.flatten(), \n",
    "                's2f_impact_buy': s2f_impact_buy.flatten(), \n",
    "                's2f_impact_sell': s2f_impact_sell.flatten(), \n",
    "                'trading_volumes': trading_volumes.flatten(), \n",
    "                'price_volatilities': price_volatilities.flatten(),\n",
    "                'order_sizes_buy': order_sizes_buy.flatten(), \n",
    "                'order_sizes_sell': order_sizes_sell.flatten(),\n",
    "                'next_trade_time': next_trade_time.flatten(),\n",
    "                'next_trade_size': next_trade_size.flatten(),\n",
    "                'next_trade_price': next_trade_price.flatten(),\n",
    "                'price change': price_change.flatten()\n",
    "                })\n",
    "\n",
    "figure(figsize=(8, 6), dpi=80)\n",
    "ax = sns.heatmap(df.corr(method='kendall'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions_to_call = {\n",
    "    'mid_price'                              : get_mid_price_comp,\n",
    "    'true_price'                             : get_true_price_comp,\n",
    "    'order_inbalance'                        : get_order_inbalance_comp,\n",
    "    'vwaps_buy'                              : get_vwap_and_ordersizes_comp,\n",
    "    'vwaps_sell'                             : get_vwap_and_ordersizes_comp,\n",
    "    'vwaps_order_sizes_buy'                  : get_vwap_and_ordersizes_comp,\n",
    "    'vwaps_order_sizes_sell'                 : get_vwap_and_ordersizes_comp,\n",
    "    's2f_impact_buy'                         : get_s2f_impact_and_ordersizes_comp,\n",
    "    's2f_impact_sell'                        : get_s2f_impact_and_ordersizes_comp,\n",
    "    's2f_order_sizes_buy'                    : get_s2f_impact_and_ordersizes_comp,\n",
    "    's2f_order_sizes_sell'                   : get_s2f_impact_and_ordersizes_comp,\n",
    "    'trading_volumes'                        : get_trading_volume_and_price_volatility,\n",
    "    'price_volatilities'                     : get_trading_volume_and_price_volatility,\n",
    "    'next_trade_time'                        : get_next_trade_x_comp,\n",
    "    'next_trade_size'                        : get_next_trade_x_comp,\n",
    "    'next_trade_price'                       : get_next_trade_x_comp,\n",
    "    'price_change'                           : get_price_change_given_prices\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_smoothing(records, past):      #records - twodimensional array (days, nr_of_bucket), past - how many buckets we look in the past\n",
    "  #  rolled_records = np.roll(records, past, axis = 1)\n",
    "   # rolled_records = rolled_records[:,past:]\n",
    "    rolled_records=records[:,:-past] # does the same as above \n",
    "    result = np.zeros(shape = rolled_records.shape)\n",
    "    for day in range(rolled_records.shape[0]):\n",
    "        for buck in range(rolled_records.shape[1]):\n",
    "            count_elem = 0.0\n",
    "            sum_elem = 0.0\n",
    "            # loop for changing nans to zeros, np.sum(arr) returns nan if nan is in the arr\n",
    "            for elem in records[day][buck:buck+past]:\n",
    "                if not math.isnan(elem):\n",
    "                    sum_elem+=elem\n",
    "                    count_elem+=1\n",
    "            if count_elem>0:\n",
    "                result[day][buck] = sum_elem/count_elem\n",
    "            else:\n",
    "                result[day][buck] = 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_still_down(x, epsilon = 10e-7):\n",
    "    if x>epsilon:\n",
    "        return 1\n",
    "    elif x<-epsilon:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "def test_high(x, epsilon = 0.01):\n",
    "    if x>epsilon:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def test_down(x, epsilon = 0.01):\n",
    "    if x<epsilon:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def up_down_bool(x):\n",
    "    if x>0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "#np.vectorize(up_still_down)(price_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_to_test_max_bool(true_prices, period_of_getting_max, interval_in_data, threshold=10e-7):\n",
    "    next_indices = period_of_getting_max//interval_in_data\n",
    "    num_of_days = true_prices.shape[0]\n",
    "    num_of_averaged_minutes = true_prices.shape[1]\n",
    "    res = np.empty(true_prices.shape)\n",
    "    for i in range(num_of_days):\n",
    "        for j in range(num_of_averaged_minutes):\n",
    "            max_val=np.max(true_prices[i][j:j+next_indices])\n",
    "            if (max_val-true_prices[i,j])/true_prices[i,j]>=threshold: # price swing >= than threshold % of price\n",
    "                res[i][j] = True\n",
    "            else:\n",
    "                res[i,j]=False\n",
    "    return res\n",
    "def get_y_to_test_min_bool(true_prices, period_of_getting_min, interval_in_data, threshold=10e-7):\n",
    "    next_indices = period_of_getting_min//interval_in_data\n",
    "    num_of_days = true_prices.shape[0]\n",
    "    num_of_averaged_minutes = true_prices.shape[1]\n",
    "    res = np.empty(true_prices.shape)\n",
    "    for i in range(num_of_days):\n",
    "        for j in range(num_of_averaged_minutes):\n",
    "            min_val=np.min(true_prices[i][j:j+next_indices])\n",
    "            if (min_val-true_prices[i,j])/true_prices[i,j]<=-threshold: # price swing >= than threshold % of price\n",
    "                res[i][j] = True\n",
    "            else:\n",
    "                res[i,j]=False\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X(comp_id=1, \n",
    "                    interval=5, \n",
    "                    time_to_skip=0, \n",
    "                    time_back=1, \n",
    "                    names=[], \n",
    "                   ): # use up_and_down or not \n",
    "    ## NEED TO ADD y_name PARAMETER AND USE IT!!!\n",
    "    X = np.empty(shape=(-10*time_back+10*((510-time_to_skip)//interval), len(names)))\n",
    "    #average_smoothing reduces shape \"time_back\" times per day\n",
    "    index=0\n",
    "    s2f_called=False\n",
    "    vwap_called=False\n",
    "    volvol_called=False #volume and price volatility\n",
    "    s2f_imp=np.empty(shape=(10, (510-time_to_skip)//interval))\n",
    "    s2f_ord=np.empty(shape=(10, (510-time_to_skip)//interval))\n",
    "    vwap=np.empty(shape=(10, (510-time_to_skip)//interval))\n",
    "    vwap_ord=np.empty(shape=(10, (510-time_to_skip)//interval))\n",
    "    volume=np.empty(shape=(10, (510-time_to_skip)//interval))\n",
    "    volatility=np.empty(shape=(10, (510-time_to_skip)//interval))\n",
    "    for name in names:\n",
    "        if name in ['mid_price', 'true_price', 'order_inbalance']:\n",
    "            arr = functions_to_call[name](comp_id, interval, time_to_skip)\n",
    "        elif re.search(\"vwap\", name):\n",
    "            if not vwap_called:\n",
    "                vwap, vwap_ord=functions_to_call[name](comp_id, interval, time_to_skip)\n",
    "                vwap_called=True\n",
    "            if name in ['vwaps_buy']:\n",
    "                arr = vwap[:,::2]\n",
    "            elif name in ['vwaps_sell']:\n",
    "                arr = vwap[:,1::2]\n",
    "            elif name in ['vwaps_order_sizes_buy']:\n",
    "                arr = vwap_ord[:,::2]\n",
    "            elif name in ['vwaps_order_sizes_sell']:\n",
    "                arr = vwap_ord[:,1::2]\n",
    "        elif re.search(\"s2f\", name):\n",
    "            if not s2f_called:\n",
    "                s2f_imp, s2f_ord=functions_to_call[name](comp_id, interval, time_to_skip)\n",
    "                s2f_called=True\n",
    "            if name in ['s2f_impact_buy']:\n",
    "                arr = s2f_imp[:,::2]\n",
    "            elif name in ['s2f_impact_sell']:\n",
    "                arr = s2f_imp[:,1::2]\n",
    "            elif name in ['s2f_order_sizes_buy']:\n",
    "                arr = s2f_ord[:,::2]\n",
    "            elif name in ['s2f_order_sizes_sell']:\n",
    "                arr = s2f_ord[:,1::2]  \n",
    "        elif name in ['trading_volumes', 'price_volatilities']:\n",
    "            if not volvol_called:\n",
    "                volume, volatility=functions_to_call[name](comp_id, interval, time_to_skip)\n",
    "                volvol_called=True\n",
    "            if name == 'trading_volumes':\n",
    "                arr = volume\n",
    "            elif name == 'price_volatilities':\n",
    "                arr = volatility\n",
    "        elif name == 'next_trade_time':\n",
    "            arr = functions_to_call[name](comp_id, interval, time_to_skip, get_x='time')\n",
    "        elif name == 'next_trade_size':\n",
    "            arr = functions_to_call[name](comp_id, interval, time_to_skip, get_x='size')\n",
    "        elif name == 'next_trade_price':\n",
    "            arr = functions_to_call[name](comp_id, interval, time_to_skip, get_x='price')\n",
    "        X[:,index]=average_smoothing(arr, time_back).flatten()\n",
    "        index+=1\n",
    "    return X\n",
    "\n",
    "def get_y(comp_id=1, \n",
    "        interval=5, \n",
    "        time_to_skip=0, \n",
    "        time_back=1, \n",
    "        y_name='true_price', \n",
    "        check='change',\n",
    "        swing_interval=30,\n",
    "         threshold=1e-2):\n",
    "    y = functions_to_call[y_name](comp_id, interval, time_to_skip)\n",
    "   #??? y = average_smoothing(functions_to_call[y_name](comp_id, interval, time_to_skip), time_back)???\n",
    "    if check=='change':\n",
    "        y=functions_to_call['price_change'](y)    \n",
    "    elif check=='swing_max':\n",
    "        y=get_y_to_test_max_bool(y, swing_interval, interval, threshold)\n",
    "    elif check=='swing_min':\n",
    "        y=get_y_to_test_min_bool(y, swing_interval, interval, threshold)\n",
    "    else:\n",
    "        raise ValueError('bad check argument')\n",
    "    y = y[:,time_back:].flatten()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y_raw(comp_id=1, \n",
    "                    interval=5, \n",
    "                    time_to_skip=30, \n",
    "                    names=[], \n",
    "                    y_name='true_price',\n",
    "                   check_change=False): # use up_and_down or not \n",
    "    X = np.empty(shape=(len(names), 10, (510-time_to_skip)//interval))  # parameter, days, timestamps\n",
    "    index=0\n",
    "    s2f_called=False\n",
    "    vwap_called=False\n",
    "    volvol_called=False #volume and price volatility\n",
    "    s2f_imp=np.empty(shape=(10, (510-time_to_skip)//interval))\n",
    "    s2f_ord=np.empty(shape=(10, (510-time_to_skip)//interval))\n",
    "    vwap=np.empty(shape=(10, (510-time_to_skip)//interval))\n",
    "    vwap_ord=np.empty(shape=(10, (510-time_to_skip)//interval))\n",
    "    volume=np.empty(shape=(10, (510-time_to_skip)//interval))\n",
    "    volatility=np.empty(shape=(10, (510-time_to_skip)//interval))\n",
    "    for name in names:\n",
    "        if name in ['mid_price', 'true_price', 'order_inbalance']:\n",
    "            arr = functions_to_call[name](comp_id, interval, time_to_skip)\n",
    "        elif name in ['trading_volumes', 'price_volatilities']:\n",
    "            if not volvol_called:\n",
    "                volume, volatility=functions_to_call[name](comp_id, interval, time_to_skip)\n",
    "                volvol_called=True\n",
    "            if name == 'trading_volumes':\n",
    "                arr = volume\n",
    "            elif name == 'price_volatilities':\n",
    "                arr = volatility\n",
    "        elif name == 'next_trade_time':\n",
    "            arr = functions_to_call[name](comp_id, interval, time_to_skip, get_x='time')\n",
    "        elif name == 'next_trade_size':\n",
    "            arr = functions_to_call[name](comp_id, interval, time_to_skip, get_x='size')\n",
    "        elif name == 'next_trade_price':\n",
    "            arr = functions_to_call[name](comp_id, interval, time_to_skip, get_x='price')   \n",
    "        elif re.search(\"vwap\", name):\n",
    "            if not vwap_called:\n",
    "                vwap, vwap_ord=functions_to_call[name](comp_id, interval, time_to_skip)\n",
    "                vwap_called=True\n",
    "            if name in ['vwaps_buy']:\n",
    "                arr = vwap[:,::2]\n",
    "            elif name in ['vwaps_sell']:\n",
    "                arr = vwap[:,1::2]\n",
    "            elif name in ['vwaps_order_sizes_buy']:\n",
    "                arr = vwap_ord[:,::2]\n",
    "            elif name in ['vwaps_order_sizes_sell']:\n",
    "                arr = vwap_ord[:,1::2]\n",
    "        elif re.search(\"s2f\", name):\n",
    "            if not s2f_called:\n",
    "                s2f_imp, s2f_ord=functions_to_call[name](comp_id, interval, time_to_skip)\n",
    "                s2f_called=True\n",
    "            if name in ['s2f_impact_buy']:\n",
    "                arr = s2f_imp[:,::2]\n",
    "            elif name in ['s2f_impact_sell']:\n",
    "                arr = s2f_imp[:,1::2]\n",
    "            elif name in ['s2f_order_sizes_buy']:\n",
    "                arr = s2f_ord[:,::2]\n",
    "            elif name in ['s2f_order_sizes_sell']:\n",
    "                arr = s2f_ord[:,1::2]            \n",
    "        else:\n",
    "            raise ValueError('parameter not found')\n",
    "        X[index]=arr\n",
    "        index+=1\n",
    "    y = functions_to_call[y_name](comp_id, interval, time_to_skip)\n",
    "    if check_change:\n",
    "        y=functions_to_call['price_change'](y)    \n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nTODO\\n        #USE REGEX TO CHECK IF STATEMENT\\n        elif name in ['vwaps_buy', 's2f_impact_buy',   \\n                      'vwaps_sell', 's2f_impact_sell', \\n                      'vwaps_order_sizes_buy', 's2f_order_sizes_buy',\\n                      'vwaps_order_sizes_sell', 's2f_order_sizes_sell']:\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "TODO\n",
    "        #USE REGEX TO CHECK IF STATEMENT\n",
    "        elif name in ['vwaps_buy', 's2f_impact_buy',   \n",
    "                      'vwaps_sell', 's2f_impact_sell', \n",
    "                      'vwaps_order_sizes_buy', 's2f_order_sizes_buy',\n",
    "                      'vwaps_order_sizes_sell', 's2f_order_sizes_sell']:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y_averaged(X_raw, y_raw, time_back):\n",
    "    X_shape=X_raw.shape # parameters, days, timestamps\n",
    "    X = np.empty(shape=(-X_shape[1]*time_back+X_shape[1]*X_shape[2], X_shape[0]))## we want features as columns, samples as rows\n",
    "    y=y_raw[:,time_back:].flatten()\n",
    "    for i in range(X_shape[0]):\n",
    "        X[:,i]=average_smoothing(X_raw[i], time_back).flatten()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "param_dict_logreg={}\n",
    "for n in names:\n",
    "    param_dict_logreg[n]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regr(X, y, split_percent, epsilon=1e-6, comp_id=1, \n",
    "                               use_scaling=True, \n",
    "                               check_up_down=True, \n",
    "                               local_names=names,\n",
    "                               track_params=False):\n",
    "    if check_up_down:\n",
    "        y=np.vectorize(up_still_down)(y,epsilon*average_comp_price[comp_id])#currently we hold price change in y\n",
    "    split=int(y.size*split_percent)\n",
    "    if use_scaling:\n",
    "        clf=make_pipeline(preprocessing.MaxAbsScaler(), LogisticRegression(max_iter=1000)).fit(X[:split], y[:split])\n",
    "      #  print(clf.named_steps)\n",
    "        if track_params:\n",
    "            for i in range(len(local_names)):\n",
    "                param_dict_logreg[local_names[i]].append( clf.named_steps['logisticregression'].coef_[0,i])\n",
    "        else:\n",
    "            print(\"Coefficient impact:\")\n",
    "            for i in range(len(local_names)):\n",
    "                print(local_names[i], \" \", clf.named_steps['logisticregression'].coef_[0,i])\n",
    "    else:\n",
    "        clf = LogisticRegression(max_iter=1000).fit(X[:split], y[:split])\n",
    "        if track_params:\n",
    "            for i in range(len(local_names)):\n",
    "                param_dict_logreg[local_names[i]].append( clf.coef_[0,i])  \n",
    "        else:\n",
    "            print(\"Coefficient impact:\")\n",
    "            for i in range(len(local_names)):\n",
    "                print(local_names[i], \" \", clf.coef_[0,i])\n",
    "    y_predicted=clf.predict(X[split:])\n",
    "    #print(\"mse: \", mse(y[split:], y_predicted))\n",
    "    #print(\"logistic regr score: \", clf.score(X[split:], y[split:]))\n",
    "    return clf.score(X[split:], y[split:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regr_cross_val(X_train, y_train, X_test, y_test, \n",
    "                               use_scaling=True, \n",
    "                               local_names=names,\n",
    "                               track_params=False):\n",
    "    if use_scaling:\n",
    "        clf=make_pipeline(preprocessing.MaxAbsScaler(), LogisticRegression(max_iter=1000)).fit(X_train, y_train)\n",
    "      #  print(clf.named_steps)\n",
    "        if track_params:\n",
    "            for i in range(len(local_names)):\n",
    "                param_dict_logreg[local_names[i]].append( clf.named_steps['logisticregression'].coef_[0,i])\n",
    "        else:\n",
    "            print(\"Coefficient impact:\")\n",
    "            for i in range(len(local_names)):\n",
    "                print(local_names[i], \" \", clf.named_steps['logisticregression'].coef_[0,i])\n",
    "    else:\n",
    "        clf = LogisticRegression(max_iter=1000).fit(X_train, y_train)\n",
    "        if track_params:\n",
    "            for i in range(len(local_names)):\n",
    "                param_dict_logreg[local_names[i]].append( clf.coef_[0,i])  \n",
    "        else:\n",
    "            print(\"Coefficient impact:\")\n",
    "            for i in range(len(local_names)):\n",
    "                print(local_names[i], \" \", clf.coef_[0,i])\n",
    "    y_predicted=clf.predict(X_test)\n",
    "    print(\"Number of positive class in training dataset =\", np.sum(y_train==1))\n",
    "    print(\"Number of negative class in training dataset =\", np.sum(y_train==0))\n",
    "    print(\"Number of positive class in testing dataset =\", np.sum(y_test==1))\n",
    "    print(\"Number of negative class in testing dataset =\", np.sum(y_test==0))\n",
    "    print(\"Percent of correct classification:\")\n",
    "    print(np.sum(y_predicted == y_test)/len(y_predicted))\n",
    "    print(\"Confusion matrix:\")\n",
    "    conf_mat = confusion_matrix(y_test, y_predicted, labels = [1, 0])\n",
    "    print(conf_mat)\n",
    "    if np.unique(y_test).size>1:\n",
    "        print(\"Precision:\")\n",
    "        precision = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[0][1])\n",
    "        print(precision)\n",
    "        print(\"Recall:\")\n",
    "        recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
    "        print(recall)\n",
    "        return clf.score(X_test, y_test), precision, recall\n",
    "    else:\n",
    "        return clf.score(X_test, y_test), math.nan, math.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(X, y, split_percent, epsilon, comp_id,\n",
    "                               use_scaling=False, \n",
    "                               check_up_down=True, \n",
    "                               local_names=names,\n",
    "                               track_params=False):\n",
    "    if check_up_down:\n",
    "        y=np.vectorize(up_still_down)(y,epsilon*average_comp_price[comp_id])#currently we hold price change in y\n",
    "    split=int(y.size*split_percent)\n",
    "    if use_scaling:\n",
    "        clf=make_pipeline(preprocessing.MaxAbsScaler(), DecisionTreeClassifier()).fit(X[:split], y[:split])\n",
    "       # print(clf.named_steps)\n",
    "        if track_params:\n",
    "            for i in range(len(local_names)):\n",
    "                param_dict_logreg[local_names[i]].append( clf.named_steps['decisiontreeclassifier'].feature_importances_[i])\n",
    "        else:\n",
    "            print(\"Coefficient impact:\")\n",
    "            for i in range(len(local_names)):\n",
    "                print(local_names[i], \" \", clf.named_steps['decisiontreeclassifier'].feature_importances_[i])\n",
    "    else:\n",
    "        clf = DecisionTreeClassifier().fit(X[:split], y[:split])\n",
    "        if track_params:\n",
    "            for i in range(len(local_names)):\n",
    "                param_dict_logreg[local_names[i]].append( clf.feature_importances_[i])  \n",
    "        else:\n",
    "            print(\"Coefficient impact:\")\n",
    "          #  print(clf.feature_importances_)\n",
    "            for i in range(len(local_names)):\n",
    "                print(local_names[i], \" \", clf.feature_importances_[i])\n",
    "    y_predicted=clf.predict(X[split:])\n",
    "    #print(\"mse: \", mse(y[split:], y_predicted))\n",
    "    #print(\"decision tree score: \", clf.score(X[split:], y[split:]))\n",
    "    return clf.score(X[split:], y[split:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_comp_price=np.zeros(len(list_of_companies_number))\n",
    "for i in range(average_comp_price.size):\n",
    "    average_comp_price[i]=np.average(get_true_price_comp(comp_id=i, interval=1, time_to_skip=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_id = 3\n",
    "interval=5\n",
    "time_to_skip=30\n",
    "time_back=1\n",
    "split_percent = 0.8\n",
    "epsilon=0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "851.5752484506002\n",
      "decision_tree\n",
      "Coefficient impact:\n",
      "order_inbalance   0.18069727532057314\n",
      "vwaps_buy   0.07347567246133037\n",
      "vwaps_sell   0.04897213668002377\n",
      "s2f_impact_buy   0.03925212692967271\n",
      "s2f_impact_sell   0.0325384996334222\n",
      "trading_volumes   0.06304642000072377\n",
      "price_volatilities   0.01642309371665008\n",
      "vwaps_order_sizes_buy   0.014209815386705545\n",
      "vwaps_order_sizes_sell   0.035329828081254615\n",
      "s2f_order_sizes_buy   0.055473745628866845\n",
      "s2f_order_sizes_sell   0.0273328743065737\n",
      "next_trade_time   0.10027299276310923\n",
      "next_trade_size   0.14757193861257356\n",
      "next_trade_price   0.1654035804785206\n",
      "score:  0.5263157894736842\n",
      "log reg\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.7062669469926882\n",
      "vwaps_buy   -1.0035278915244832\n",
      "vwaps_sell   1.347472003494649\n",
      "s2f_impact_buy   -0.06193011754906547\n",
      "s2f_impact_sell   0.23461187211592183\n",
      "trading_volumes   0.20590750194726634\n",
      "price_volatilities   -0.3065772153289346\n",
      "vwaps_order_sizes_buy   0.02539491263371483\n",
      "vwaps_order_sizes_sell   0.6518797542006699\n",
      "s2f_order_sizes_buy   0.19138895894549027\n",
      "s2f_order_sizes_sell   -0.16873767704239306\n",
      "next_trade_time   -0.3278650258709835\n",
      "next_trade_size   0.038972615929296656\n",
      "next_trade_price   1.2706852878377495\n",
      "score:  0.5894736842105263\n"
     ]
    }
   ],
   "source": [
    "print(average_comp_price[comp_id])\n",
    "X=get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "y=get_y(comp_id, interval, time_to_skip, time_back, y_name='true_price', check='change')\n",
    "print(\"decision_tree\")\n",
    "print(\"score: \",decision_tree(X, np.copy(y),split_percent, epsilon, comp_id, use_scaling=True, local_names=names))\n",
    "print(\"log reg\")\n",
    "print(\"score: \",logistic_regr(X, np.copy(y),split_percent, epsilon, comp_id, use_scaling=True, local_names=names))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_cross_val(X_train, y_train, X_test, y_test, use_scaling=True):\n",
    "    neg_class_count = np.sum(y_train==0)\n",
    "    pos_class_count = np.sum(y_train==1)\n",
    "    if use_scaling:\n",
    "        clf=make_pipeline(preprocessing.MaxAbsScaler(), xgb.XGBClassifier(max_depth=5, scale_pos_weight=neg_class_count/pos_class_count)).fit(X_train, y_train)\n",
    "    else:\n",
    "        clf = xgb.XGBClassifier().fit(X_train, y_train)\n",
    "    y_predicted=clf.predict(X_test)\n",
    "    print(\"Number of positive class in training dataset =\", np.sum(y_train==1))\n",
    "    print(\"Number of negative class in training dataset =\", np.sum(y_train==0))\n",
    "    print(\"Number of positive class in testing dataset =\", np.sum(y_test==1))\n",
    "    print(\"Number of negative class in testing dataset =\", np.sum(y_test==0))\n",
    "    print(\"Percent of correct classification:\")\n",
    "    print(np.sum(y_predicted == y_test)/len(y_predicted))\n",
    "    print(\"Confusion matrix:\")\n",
    "    conf_mat = confusion_matrix(y_test, y_predicted, labels = [1, 0])\n",
    "    print(conf_mat)\n",
    "    if np.unique(y_test).size>1:\n",
    "        print(\"Precision:\")\n",
    "        precision = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[0][1])\n",
    "        print(precision)\n",
    "        print(\"Recall:\")\n",
    "        recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
    "        print(recall)\n",
    "    #print(\"mse: \", mse(y[split:], y_predicted))\n",
    "    #print(\"logistic regr score: \", clf.score(X[split:], y[split:]))\n",
    "        return clf.score(X_test, y_test), precision, recall\n",
    "    else:\n",
    "        return clf.score(X_test, y_test), math.nan, math.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X, y, model, num_of_day = 10, use_scaling = True):\n",
    "    num_of_samples_in_day = X.shape[0]//num_of_day\n",
    "    plot_indicators = np.zeros(shape = (10, 3))\n",
    "    for day in range(num_of_day):\n",
    "        try:\n",
    "            X_train = np.concatenate((X[:day*num_of_samples_in_day], X[(day+1)*num_of_samples_in_day:]))\n",
    "            y_train = np.concatenate((y[:day*num_of_samples_in_day], y[(day+1)*num_of_samples_in_day:]))\n",
    "            X_test = X[day*num_of_samples_in_day:(day+1)*num_of_samples_in_day]\n",
    "            y_test = y[day*num_of_samples_in_day:(day+1)*num_of_samples_in_day]\n",
    "            if model == 'log_reg':\n",
    "                score, precision, recall = logistic_regr_cross_val(X_train, y_train, X_test, y_test, use_scaling = use_scaling, local_names=names,track_params=False)\n",
    "                plot_indicators[day][0] = score\n",
    "                plot_indicators[day][1] = precision\n",
    "                plot_indicators[day][2] = recall\n",
    "            elif model == 'xgb':\n",
    "                score, precision, recall = xgb_cross_val(X_train, y_train, X_test, y_test, use_scaling = use_scaling)\n",
    "                plot_indicators[day][0] = score\n",
    "                plot_indicators[day][1] = precision\n",
    "                plot_indicators[day][2] = recall\n",
    "        except ValueError as err:\n",
    "            plot_indicators[day][0] = math.nan\n",
    "            plot_indicators[day][1] = math.nan\n",
    "            plot_indicators[day][2] = math.nan\n",
    "            print(err)\n",
    "    return plot_indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testy modeli na wybranym thresholdzie i porównanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bez skalowania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przyklad 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold =  0.001\n",
      "Coefficient impact:\n",
      "order_inbalance   2.2670055297665657e-07\n",
      "vwaps_buy   2.2422046924630513e-06\n",
      "vwaps_sell   7.1669859467916774e-06\n",
      "s2f_impact_buy   6.765772092271363e-07\n",
      "s2f_impact_sell   1.061609551462548e-06\n",
      "trading_volumes   -0.00015139091296873208\n",
      "price_volatilities   -9.657333994503926e-08\n",
      "vwaps_order_sizes_buy   0.0001361818404483448\n",
      "vwaps_order_sizes_sell   0.00015971152661422653\n",
      "s2f_order_sizes_buy   9.457530448788974e-05\n",
      "s2f_order_sizes_sell   4.9239356268652594e-05\n",
      "next_trade_time   9.736030926077503e-05\n",
      "next_trade_size   0.0005263568168857053\n",
      "next_trade_price   -4.842780482244597e-06\n",
      "Number of positive class in training dataset = 897\n",
      "Number of negative class in training dataset = 498\n",
      "Number of positive class in testing dataset = 104\n",
      "Number of negative class in testing dataset = 51\n",
      "Percent of correct classification:\n",
      "0.7161290322580646\n",
      "Confusion matrix:\n",
      "[[104   0]\n",
      " [ 44   7]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.7027027027027027\n",
      "Coefficient impact:\n",
      "order_inbalance   2.6858535529785483e-07\n",
      "vwaps_buy   2.332443718447945e-06\n",
      "vwaps_sell   8.409743430673949e-06\n",
      "s2f_impact_buy   5.629775556226923e-07\n",
      "s2f_impact_sell   9.734377997965249e-07\n",
      "trading_volumes   -0.0001537531677176565\n",
      "price_volatilities   -9.74653589183681e-08\n",
      "vwaps_order_sizes_buy   0.00013632375031338208\n",
      "vwaps_order_sizes_sell   0.0001603533115796403\n",
      "s2f_order_sizes_buy   0.00011580038727445808\n",
      "s2f_order_sizes_sell   4.583482945097654e-05\n",
      "next_trade_time   0.00010485207072310672\n",
      "next_trade_size   0.0005175455567859445\n",
      "next_trade_price   -6.077115223633531e-06\n",
      "Number of positive class in training dataset = 901\n",
      "Number of negative class in training dataset = 494\n",
      "Number of positive class in testing dataset = 100\n",
      "Number of negative class in testing dataset = 55\n",
      "Percent of correct classification:\n",
      "0.6903225806451613\n",
      "Confusion matrix:\n",
      "[[100   0]\n",
      " [ 48   7]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.6756756756756757\n",
      "Coefficient impact:\n",
      "order_inbalance   2.887356519429793e-07\n",
      "vwaps_buy   1.6404134362219284e-06\n",
      "vwaps_sell   5.832365102229167e-06\n",
      "s2f_impact_buy   7.177965213865061e-07\n",
      "s2f_impact_sell   1.1664482785192252e-06\n",
      "trading_volumes   -0.00022352455838654258\n",
      "price_volatilities   -1.1268678049347801e-07\n",
      "vwaps_order_sizes_buy   0.00020499631284056095\n",
      "vwaps_order_sizes_sell   0.00026088212799652716\n",
      "s2f_order_sizes_buy   0.00010601344933098278\n",
      "s2f_order_sizes_sell   -9.693572034353574e-06\n",
      "next_trade_time   0.00011838876621440976\n",
      "next_trade_size   0.0006712400911926737\n",
      "next_trade_price   -3.914852337322181e-06\n",
      "Number of positive class in training dataset = 905\n",
      "Number of negative class in training dataset = 490\n",
      "Number of positive class in testing dataset = 96\n",
      "Number of negative class in testing dataset = 59\n",
      "Percent of correct classification:\n",
      "0.6258064516129033\n",
      "Confusion matrix:\n",
      "[[92  4]\n",
      " [54  5]]\n",
      "Precision:\n",
      "0.9583333333333334\n",
      "Recall:\n",
      "0.6301369863013698\n",
      "Coefficient impact:\n",
      "order_inbalance   3.6952064193833446e-07\n",
      "vwaps_buy   1.541572107712684e-06\n",
      "vwaps_sell   5.98668840407501e-06\n",
      "s2f_impact_buy   8.396638447141451e-07\n",
      "s2f_impact_sell   1.0976847064444114e-06\n",
      "trading_volumes   -0.0001709817802419332\n",
      "price_volatilities   -7.792202669537457e-08\n",
      "vwaps_order_sizes_buy   0.00014546563928523543\n",
      "vwaps_order_sizes_sell   0.00017703056571674982\n",
      "s2f_order_sizes_buy   0.00010920514146257536\n",
      "s2f_order_sizes_sell   5.3829072583412604e-05\n",
      "next_trade_time   9.599401776315929e-05\n",
      "next_trade_size   0.0006143367574351696\n",
      "next_trade_price   -4.464264790479991e-06\n",
      "Number of positive class in training dataset = 900\n",
      "Number of negative class in training dataset = 495\n",
      "Number of positive class in testing dataset = 101\n",
      "Number of negative class in testing dataset = 54\n",
      "Percent of correct classification:\n",
      "0.6516129032258065\n",
      "Confusion matrix:\n",
      "[[98  3]\n",
      " [51  3]]\n",
      "Precision:\n",
      "0.9702970297029703\n",
      "Recall:\n",
      "0.6577181208053692\n",
      "Coefficient impact:\n",
      "order_inbalance   1.2160448868547436e-07\n",
      "vwaps_buy   6.825565712679848e-08\n",
      "vwaps_sell   7.5411462512487675e-06\n",
      "s2f_impact_buy   7.999997238676809e-07\n",
      "s2f_impact_sell   1.2974189495416571e-06\n",
      "trading_volumes   -0.00014179415387990604\n",
      "price_volatilities   -1.1987156906093886e-07\n",
      "vwaps_order_sizes_buy   9.937001954236186e-05\n",
      "vwaps_order_sizes_sell   0.00014999014612096788\n",
      "s2f_order_sizes_buy   0.0001096445327254208\n",
      "s2f_order_sizes_sell   6.0464674956477674e-05\n",
      "next_trade_time   0.0001025453953272231\n",
      "next_trade_size   0.00041922381821954836\n",
      "next_trade_price   -7.388047982171954e-06\n",
      "Number of positive class in training dataset = 879\n",
      "Number of negative class in training dataset = 516\n",
      "Number of positive class in testing dataset = 122\n",
      "Number of negative class in testing dataset = 33\n",
      "Percent of correct classification:\n",
      "0.7935483870967742\n",
      "Confusion matrix:\n",
      "[[110  12]\n",
      " [ 20  13]]\n",
      "Precision:\n",
      "0.9016393442622951\n",
      "Recall:\n",
      "0.8461538461538461\n",
      "Coefficient impact:\n",
      "order_inbalance   4.01398650428796e-07\n",
      "vwaps_buy   5.180137525798476e-07\n",
      "vwaps_sell   6.233421606634158e-06\n",
      "s2f_impact_buy   7.004486862106072e-07\n",
      "s2f_impact_sell   1.1584603986462719e-06\n",
      "trading_volumes   -0.0001701537766214944\n",
      "price_volatilities   -1.3751989965899283e-07\n",
      "vwaps_order_sizes_buy   0.0001527448142582711\n",
      "vwaps_order_sizes_sell   0.00018061281210290687\n",
      "s2f_order_sizes_buy   0.00012145370857564005\n",
      "s2f_order_sizes_sell   5.960556272580637e-05\n",
      "next_trade_time   0.00012488597201930934\n",
      "next_trade_size   0.0003749435967945641\n",
      "next_trade_price   -5.630079867426996e-06\n",
      "Number of positive class in training dataset = 912\n",
      "Number of negative class in training dataset = 483\n",
      "Number of positive class in testing dataset = 89\n",
      "Number of negative class in testing dataset = 66\n",
      "Percent of correct classification:\n",
      "0.6129032258064516\n",
      "Confusion matrix:\n",
      "[[88  1]\n",
      " [59  7]]\n",
      "Precision:\n",
      "0.9887640449438202\n",
      "Recall:\n",
      "0.5986394557823129\n",
      "Coefficient impact:\n",
      "order_inbalance   3.4495622316682584e-07\n",
      "vwaps_buy   -5.06266703726693e-07\n",
      "vwaps_sell   7.783725677264026e-06\n",
      "s2f_impact_buy   7.968472351914011e-07\n",
      "s2f_impact_sell   9.773881552470787e-07\n",
      "trading_volumes   -0.0001837866264587344\n",
      "price_volatilities   -1.693326982221392e-07\n",
      "vwaps_order_sizes_buy   0.00019435843397331564\n",
      "vwaps_order_sizes_sell   0.0001920707893930317\n",
      "s2f_order_sizes_buy   7.257676704094516e-05\n",
      "s2f_order_sizes_sell   4.3557930283783705e-05\n",
      "next_trade_time   0.00010009715642795819\n",
      "next_trade_size   0.0005994284633987372\n",
      "next_trade_price   -8.140305114960332e-06\n",
      "Number of positive class in training dataset = 913\n",
      "Number of negative class in training dataset = 482\n",
      "Number of positive class in testing dataset = 88\n",
      "Number of negative class in testing dataset = 67\n",
      "Percent of correct classification:\n",
      "0.6129032258064516\n",
      "Confusion matrix:\n",
      "[[87  1]\n",
      " [59  8]]\n",
      "Precision:\n",
      "0.9886363636363636\n",
      "Recall:\n",
      "0.5958904109589042\n",
      "Coefficient impact:\n",
      "order_inbalance   1.979364885716598e-05\n",
      "vwaps_buy   3.0493578577222537e-05\n",
      "vwaps_sell   0.0008363125894825575\n",
      "s2f_impact_buy   5.1367548203581655e-05\n",
      "s2f_impact_sell   0.00011099404320495737\n",
      "trading_volumes   -0.0001587343707497216\n",
      "price_volatilities   3.318118771077956e-07\n",
      "vwaps_order_sizes_buy   0.0001427916412491808\n",
      "vwaps_order_sizes_sell   0.00016540571714309657\n",
      "s2f_order_sizes_buy   5.5484086140007446e-05\n",
      "s2f_order_sizes_sell   5.1464950107639625e-05\n",
      "next_trade_time   0.009387621229146098\n",
      "next_trade_size   0.00022683896508474496\n",
      "next_trade_price   -0.0007823893474907561\n",
      "Number of positive class in training dataset = 892\n",
      "Number of negative class in training dataset = 503\n",
      "Number of positive class in testing dataset = 109\n",
      "Number of negative class in testing dataset = 46\n",
      "Percent of correct classification:\n",
      "0.6838709677419355\n",
      "Confusion matrix:\n",
      "[[104   5]\n",
      " [ 44   2]]\n",
      "Precision:\n",
      "0.9541284403669725\n",
      "Recall:\n",
      "0.7027027027027027\n",
      "Coefficient impact:\n",
      "order_inbalance   2.3050001971211722e-07\n",
      "vwaps_buy   1.7052225415943909e-06\n",
      "vwaps_sell   6.40782012620815e-06\n",
      "s2f_impact_buy   7.729216815706627e-07\n",
      "s2f_impact_sell   1.2723386178964403e-06\n",
      "trading_volumes   -0.00016223471395198199\n",
      "price_volatilities   -1.3787299209212662e-07\n",
      "vwaps_order_sizes_buy   0.00014441776431735546\n",
      "vwaps_order_sizes_sell   0.00017232254410747092\n",
      "s2f_order_sizes_buy   0.00011207171100265469\n",
      "s2f_order_sizes_sell   5.042299443125092e-05\n",
      "next_trade_time   0.00010700206553619298\n",
      "next_trade_size   0.0005701518355256581\n",
      "next_trade_price   -4.686597392246462e-06\n",
      "Number of positive class in training dataset = 916\n",
      "Number of negative class in training dataset = 479\n",
      "Number of positive class in testing dataset = 85\n",
      "Number of negative class in testing dataset = 70\n",
      "Percent of correct classification:\n",
      "0.5935483870967742\n",
      "Confusion matrix:\n",
      "[[85  0]\n",
      " [63  7]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.5743243243243243\n",
      "Coefficient impact:\n",
      "order_inbalance   3.5785612749008266e-07\n",
      "vwaps_buy   2.1636425399943758e-06\n",
      "vwaps_sell   1.2008212397253645e-05\n",
      "s2f_impact_buy   1.064671663780228e-06\n",
      "s2f_impact_sell   1.9594590455601154e-06\n",
      "trading_volumes   -0.00023323145087184618\n",
      "price_volatilities   -1.1711864597152532e-07\n",
      "vwaps_order_sizes_buy   0.0002243086921875586\n",
      "vwaps_order_sizes_sell   0.0002412458769085679\n",
      "s2f_order_sizes_buy   0.00010423998306958399\n",
      "s2f_order_sizes_sell   8.590693770655303e-05\n",
      "next_trade_time   0.00014919335451731624\n",
      "next_trade_size   0.0002695307472574782\n",
      "next_trade_price   -9.774729765158662e-06\n",
      "Number of positive class in training dataset = 894\n",
      "Number of negative class in training dataset = 501\n",
      "Number of positive class in testing dataset = 107\n",
      "Number of negative class in testing dataset = 48\n",
      "Percent of correct classification:\n",
      "0.6451612903225806\n",
      "Confusion matrix:\n",
      "[[99  8]\n",
      " [47  1]]\n",
      "Precision:\n",
      "0.9252336448598131\n",
      "Recall:\n",
      "0.678082191780822\n",
      "Average model accuracy: 0.6625806451612903\n",
      "Average precision: 0.968703220110557\n",
      "Average recall: 0.6662026417188031\n"
     ]
    }
   ],
   "source": [
    "comp_id = 1\n",
    "interval=3\n",
    "time_to_skip=30\n",
    "time_back=5\n",
    "y_name='true_price'\n",
    "swing_interval = 60\n",
    "check = 'swing_max'\n",
    "use_scaling = False\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.001\n",
    "print(\"Threshold = \", threshold)\n",
    "X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "#X,y=get_X_y_classic(comp_id, interval, time_to_skip, time_back, period_of_getting_data_to_test, names, y_name, test_min_max, threshold)\n",
    "res_per_day = cross_validation(X, y, 'log_reg',use_scaling = use_scaling)\n",
    "print(\"Average model accuracy:\", np.sum(res_per_day[:,0])/res_per_day.shape[0])\n",
    "print(\"Average precision:\", np.sum(res_per_day[:,1])/res_per_day.shape[0])\n",
    "print(\"Average recall:\", np.sum(res_per_day[:,2])/res_per_day.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przyklad 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold =  0.001\n",
      "Coefficient impact:\n",
      "order_inbalance   -1.4099418058536497e-08\n",
      "vwaps_buy   1.3963623302725177e-07\n",
      "vwaps_sell   1.7511198175808276e-07\n",
      "s2f_impact_buy   -2.216842087996057e-09\n",
      "s2f_impact_sell   -1.2688406739331389e-08\n",
      "trading_volumes   -5.096933560364703e-05\n",
      "price_volatilities   1.5818639339798153e-07\n",
      "vwaps_order_sizes_buy   4.5019097559422675e-05\n",
      "vwaps_order_sizes_sell   5.665903846922285e-05\n",
      "s2f_order_sizes_buy   8.67814909245832e-06\n",
      "s2f_order_sizes_sell   3.336055922710732e-05\n",
      "next_trade_time   -1.207768641290915e-06\n",
      "next_trade_size   4.667616525982503e-05\n",
      "next_trade_price   -2.6014610359210467e-08\n",
      "Number of positive class in training dataset = 762\n",
      "Number of negative class in training dataset = 633\n",
      "Number of positive class in testing dataset = 113\n",
      "Number of negative class in testing dataset = 42\n",
      "Percent of correct classification:\n",
      "0.6967741935483871\n",
      "Confusion matrix:\n",
      "[[99 14]\n",
      " [33  9]]\n",
      "Precision:\n",
      "0.8761061946902655\n",
      "Recall:\n",
      "0.75\n",
      "Coefficient impact:\n",
      "order_inbalance   1.2269274670267337e-09\n",
      "vwaps_buy   1.7964557537510485e-07\n",
      "vwaps_sell   1.4170787907148426e-07\n",
      "s2f_impact_buy   4.492419785716797e-09\n",
      "s2f_impact_sell   -1.1922805788264272e-08\n",
      "trading_volumes   -4.6114240961794754e-05\n",
      "price_volatilities   1.2394548605440318e-07\n",
      "vwaps_order_sizes_buy   4.288474555040277e-05\n",
      "vwaps_order_sizes_sell   4.9267642671480934e-05\n",
      "s2f_order_sizes_buy   2.766382201518631e-05\n",
      "s2f_order_sizes_sell   5.02040304447754e-05\n",
      "next_trade_time   3.3384819812098835e-07\n",
      "next_trade_size   4.621119966681411e-05\n",
      "next_trade_price   4.440953111045338e-08\n",
      "Number of positive class in training dataset = 828\n",
      "Number of negative class in training dataset = 567\n",
      "Number of positive class in testing dataset = 47\n",
      "Number of negative class in testing dataset = 108\n",
      "Percent of correct classification:\n",
      "0.36129032258064514\n",
      "Confusion matrix:\n",
      "[[47  0]\n",
      " [99  9]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.3219178082191781\n",
      "Coefficient impact:\n",
      "order_inbalance   -7.156445500039093e-09\n",
      "vwaps_buy   2.0341621349041874e-07\n",
      "vwaps_sell   1.8292028625286284e-07\n",
      "s2f_impact_buy   -6.546806385907187e-09\n",
      "s2f_impact_sell   -1.4259345729265471e-08\n",
      "trading_volumes   -4.407971960633213e-05\n",
      "price_volatilities   1.8559112593152617e-07\n",
      "vwaps_order_sizes_buy   3.182007706546338e-05\n",
      "vwaps_order_sizes_sell   4.719203476289401e-05\n",
      "s2f_order_sizes_buy   1.5532830885184982e-05\n",
      "s2f_order_sizes_sell   3.616772611274824e-05\n",
      "next_trade_time   -5.159735925242938e-07\n",
      "next_trade_size   4.841478087386014e-05\n",
      "next_trade_price   3.1996914257556274e-08\n",
      "Number of positive class in training dataset = 759\n",
      "Number of negative class in training dataset = 636\n",
      "Number of positive class in testing dataset = 116\n",
      "Number of negative class in testing dataset = 39\n",
      "Percent of correct classification:\n",
      "0.5612903225806452\n",
      "Confusion matrix:\n",
      "[[75 41]\n",
      " [27 12]]\n",
      "Precision:\n",
      "0.646551724137931\n",
      "Recall:\n",
      "0.7352941176470589\n",
      "Coefficient impact:\n",
      "order_inbalance   -1.3081758951609283e-09\n",
      "vwaps_buy   8.525752482660895e-08\n",
      "vwaps_sell   4.3180798898419316e-08\n",
      "s2f_impact_buy   -7.386357808580942e-10\n",
      "s2f_impact_sell   -3.5633632703393317e-09\n",
      "trading_volumes   -3.247804784720447e-05\n",
      "price_volatilities   2.2066937329364388e-07\n",
      "vwaps_order_sizes_buy   2.5031135301161965e-05\n",
      "vwaps_order_sizes_sell   3.5469048172033334e-05\n",
      "s2f_order_sizes_buy   1.7737802701652448e-05\n",
      "s2f_order_sizes_sell   3.7338216882119584e-05\n",
      "next_trade_time   -6.660831000548268e-08\n",
      "next_trade_size   1.140459046005617e-05\n",
      "next_trade_price   4.3729601856074584e-08\n",
      "Number of positive class in training dataset = 771\n",
      "Number of negative class in training dataset = 624\n",
      "Number of positive class in testing dataset = 104\n",
      "Number of negative class in testing dataset = 51\n",
      "Percent of correct classification:\n",
      "0.6193548387096774\n",
      "Confusion matrix:\n",
      "[[81 23]\n",
      " [36 15]]\n",
      "Precision:\n",
      "0.7788461538461539\n",
      "Recall:\n",
      "0.6923076923076923\n",
      "Coefficient impact:\n",
      "order_inbalance   -1.6449431871855956e-09\n",
      "vwaps_buy   2.353261008703582e-07\n",
      "vwaps_sell   1.817970898061599e-07\n",
      "s2f_impact_buy   -1.8930952880248295e-09\n",
      "s2f_impact_sell   -1.1323113534760321e-08\n",
      "trading_volumes   -2.5461195658526926e-05\n",
      "price_volatilities   1.4222057963222057e-07\n",
      "vwaps_order_sizes_buy   1.9469040712822686e-05\n",
      "vwaps_order_sizes_sell   2.7995201187628703e-05\n",
      "s2f_order_sizes_buy   -8.838428092699342e-06\n",
      "s2f_order_sizes_sell   2.8934944490581168e-05\n",
      "next_trade_time   -4.581557801274533e-07\n",
      "next_trade_size   7.993524754349617e-05\n",
      "next_trade_price   5.973967580496401e-08\n",
      "Number of positive class in training dataset = 756\n",
      "Number of negative class in training dataset = 639\n",
      "Number of positive class in testing dataset = 119\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "0.4129032258064516\n",
      "Confusion matrix:\n",
      "[[39 80]\n",
      " [11 25]]\n",
      "Precision:\n",
      "0.3277310924369748\n",
      "Recall:\n",
      "0.78\n",
      "Coefficient impact:\n",
      "order_inbalance   9.258893545196367e-10\n",
      "vwaps_buy   1.2405830803853245e-07\n",
      "vwaps_sell   1.2563782252348962e-07\n",
      "s2f_impact_buy   6.675616025519403e-10\n",
      "s2f_impact_sell   -7.263559058858556e-09\n",
      "trading_volumes   -5.6383569351732046e-05\n",
      "price_volatilities   8.993675027606328e-08\n",
      "vwaps_order_sizes_buy   4.771744189851145e-05\n",
      "vwaps_order_sizes_sell   5.604535990345624e-05\n",
      "s2f_order_sizes_buy   3.138447931718997e-05\n",
      "s2f_order_sizes_sell   4.160588520422076e-05\n",
      "next_trade_time   3.111465368596689e-07\n",
      "next_trade_size   5.073177201586128e-05\n",
      "next_trade_price   3.981392236869435e-09\n",
      "Number of positive class in training dataset = 815\n",
      "Number of negative class in training dataset = 580\n",
      "Number of positive class in testing dataset = 60\n",
      "Number of negative class in testing dataset = 95\n",
      "Percent of correct classification:\n",
      "0.432258064516129\n",
      "Confusion matrix:\n",
      "[[57  3]\n",
      " [85 10]]\n",
      "Precision:\n",
      "0.95\n",
      "Recall:\n",
      "0.4014084507042254\n",
      "Coefficient impact:\n",
      "order_inbalance   -7.309028460605442e-09\n",
      "vwaps_buy   2.320407590786379e-07\n",
      "vwaps_sell   1.9269535397124115e-07\n",
      "s2f_impact_buy   -3.686071237398222e-09\n",
      "s2f_impact_sell   -1.8316058246942462e-08\n",
      "trading_volumes   -3.7156856392797004e-05\n",
      "price_volatilities   1.826498886935551e-07\n",
      "vwaps_order_sizes_buy   2.9036985972064184e-05\n",
      "vwaps_order_sizes_sell   4.3586080570398564e-05\n",
      "s2f_order_sizes_buy   2.2033827355184855e-05\n",
      "s2f_order_sizes_sell   3.7771559031477415e-05\n",
      "next_trade_time   -5.127152359952928e-07\n",
      "next_trade_size   0.00013193553622158053\n",
      "next_trade_price   4.954083873541459e-08\n",
      "Number of positive class in training dataset = 811\n",
      "Number of negative class in training dataset = 584\n",
      "Number of positive class in testing dataset = 64\n",
      "Number of negative class in testing dataset = 91\n",
      "Percent of correct classification:\n",
      "0.45806451612903226\n",
      "Confusion matrix:\n",
      "[[63  1]\n",
      " [83  8]]\n",
      "Precision:\n",
      "0.984375\n",
      "Recall:\n",
      "0.4315068493150685\n",
      "Coefficient impact:\n",
      "order_inbalance   -2.1687696244283392e-09\n",
      "vwaps_buy   1.988035696732969e-07\n",
      "vwaps_sell   1.7380146908009048e-07\n",
      "s2f_impact_buy   7.613755056361022e-13\n",
      "s2f_impact_sell   -9.277730579243792e-09\n",
      "trading_volumes   -3.5757395010901406e-05\n",
      "price_volatilities   1.2816974049625476e-07\n",
      "vwaps_order_sizes_buy   2.7455238943432983e-05\n",
      "vwaps_order_sizes_sell   3.989630895355952e-05\n",
      "s2f_order_sizes_buy   1.8457288083573154e-05\n",
      "s2f_order_sizes_sell   4.3337772153694495e-05\n",
      "next_trade_time   9.187443770898755e-07\n",
      "next_trade_size   6.85624780245897e-05\n",
      "next_trade_price   3.49690263728914e-08\n",
      "Number of positive class in training dataset = 811\n",
      "Number of negative class in training dataset = 584\n",
      "Number of positive class in testing dataset = 64\n",
      "Number of negative class in testing dataset = 91\n",
      "Percent of correct classification:\n",
      "0.49032258064516127\n",
      "Confusion matrix:\n",
      "[[53 11]\n",
      " [68 23]]\n",
      "Precision:\n",
      "0.828125\n",
      "Recall:\n",
      "0.4380165289256198\n",
      "Coefficient impact:\n",
      "order_inbalance   8.140809838491664e-09\n",
      "vwaps_buy   1.4213525507432322e-07\n",
      "vwaps_sell   1.6382172835030267e-07\n",
      "s2f_impact_buy   -4.161314354336274e-09\n",
      "s2f_impact_sell   -1.3599970921612764e-08\n",
      "trading_volumes   -3.078847232893929e-05\n",
      "price_volatilities   1.7013555672971262e-07\n",
      "vwaps_order_sizes_buy   1.7136020390920526e-05\n",
      "vwaps_order_sizes_sell   3.9419713899476396e-05\n",
      "s2f_order_sizes_buy   1.8212042170277332e-05\n",
      "s2f_order_sizes_sell   2.1815126945573333e-05\n",
      "next_trade_time   -2.6190345989214464e-07\n",
      "next_trade_size   6.356415710093543e-05\n",
      "next_trade_price   -8.04740417341261e-09\n",
      "Number of positive class in training dataset = 769\n",
      "Number of negative class in training dataset = 626\n",
      "Number of positive class in testing dataset = 106\n",
      "Number of negative class in testing dataset = 49\n",
      "Percent of correct classification:\n",
      "0.6\n",
      "Confusion matrix:\n",
      "[[72 34]\n",
      " [28 21]]\n",
      "Precision:\n",
      "0.6792452830188679\n",
      "Recall:\n",
      "0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient impact:\n",
      "order_inbalance   -5.588472763288516e-09\n",
      "vwaps_buy   2.0861157411449792e-07\n",
      "vwaps_sell   1.6928676587496168e-07\n",
      "s2f_impact_buy   -1.5736539530216647e-10\n",
      "s2f_impact_sell   -1.113616512370514e-08\n",
      "trading_volumes   -5.1431080201343826e-05\n",
      "price_volatilities   1.1306927136336873e-07\n",
      "vwaps_order_sizes_buy   4.4439971186471466e-05\n",
      "vwaps_order_sizes_sell   5.5173151739732116e-05\n",
      "s2f_order_sizes_buy   2.428280622891867e-05\n",
      "s2f_order_sizes_sell   3.0063001862468757e-05\n",
      "next_trade_time   -4.1559339605908694e-08\n",
      "next_trade_size   4.626114739031993e-05\n",
      "next_trade_price   5.0797259683068566e-08\n",
      "Number of positive class in training dataset = 793\n",
      "Number of negative class in training dataset = 602\n",
      "Number of positive class in testing dataset = 82\n",
      "Number of negative class in testing dataset = 73\n",
      "Percent of correct classification:\n",
      "0.535483870967742\n",
      "Confusion matrix:\n",
      "[[77  5]\n",
      " [67  6]]\n",
      "Precision:\n",
      "0.9390243902439024\n",
      "Recall:\n",
      "0.5347222222222222\n",
      "Average model accuracy: 0.516774193548387\n",
      "Average precision: 0.8010004838374096\n",
      "Average recall: 0.5805173669341065\n"
     ]
    }
   ],
   "source": [
    "comp_id = 7\n",
    "interval=3\n",
    "time_to_skip=30\n",
    "time_back=5\n",
    "y_name='true_price'\n",
    "swing_interval = 60\n",
    "check = 'swing_max'\n",
    "use_scaling = False\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.001\n",
    "print(\"Threshold = \", threshold)\n",
    "X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "#X,y=get_X_y_classic(comp_id, interval, time_to_skip, time_back, period_of_getting_data_to_test, names, y_name, test_min_max, threshold)\n",
    "res_per_day = cross_validation(X, y, 'log_reg',use_scaling = use_scaling)\n",
    "print(\"Average model accuracy:\", np.sum(res_per_day[:,0])/res_per_day.shape[0])\n",
    "print(\"Average precision:\", np.sum(res_per_day[:,1])/res_per_day.shape[0])\n",
    "print(\"Average recall:\", np.sum(res_per_day[:,2])/res_per_day.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean of all companies for max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n",
      "Coefficient impact:\n",
      "order_inbalance   -3.994784093735728e-07\n",
      "vwaps_buy   7.098647681309484e-06\n",
      "vwaps_sell   4.053749070971804e-06\n",
      "s2f_impact_buy   -5.508299401910682e-07\n",
      "s2f_impact_sell   5.332084911474661e-07\n",
      "trading_volumes   -0.0014226359277972618\n",
      "price_volatilities   -1.2911998192704714e-07\n",
      "vwaps_order_sizes_buy   0.0015304625937405962\n",
      "vwaps_order_sizes_sell   0.0014245203380922821\n",
      "s2f_order_sizes_buy   -1.6165670862336405e-05\n",
      "s2f_order_sizes_sell   0.0002052790360586519\n",
      "next_trade_time   -6.30826329529386e-05\n",
      "next_trade_size   0.00015657431662303043\n",
      "next_trade_price   2.4979328533914583e-06\n",
      "Number of positive class in training dataset = 843\n",
      "Number of negative class in training dataset = 552\n",
      "Number of positive class in testing dataset = 92\n",
      "Number of negative class in testing dataset = 63\n",
      "Percent of correct classification:\n",
      "0.6516129032258065\n",
      "Confusion matrix:\n",
      "[[92  0]\n",
      " [54  9]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.6301369863013698\n",
      "Coefficient impact:\n",
      "order_inbalance   -5.144778606561565e-07\n",
      "vwaps_buy   -1.994301221599015e-06\n",
      "vwaps_sell   3.664950255511772e-06\n",
      "s2f_impact_buy   6.894679773317954e-07\n",
      "s2f_impact_sell   2.034447637060055e-06\n",
      "trading_volumes   -0.00176698748000523\n",
      "price_volatilities   -1.3839310234810742e-07\n",
      "vwaps_order_sizes_buy   0.001915687461159023\n",
      "vwaps_order_sizes_sell   0.001776806125782449\n",
      "s2f_order_sizes_buy   -6.559797174054638e-05\n",
      "s2f_order_sizes_sell   0.0001998103864240906\n",
      "next_trade_time   -4.1761837992070357e-05\n",
      "next_trade_size   4.644021838098136e-05\n",
      "next_trade_price   -6.460593499570973e-06\n",
      "Number of positive class in training dataset = 832\n",
      "Number of negative class in training dataset = 563\n",
      "Number of positive class in testing dataset = 103\n",
      "Number of negative class in testing dataset = 52\n",
      "Percent of correct classification:\n",
      "0.6967741935483871\n",
      "Confusion matrix:\n",
      "[[101   2]\n",
      " [ 45   7]]\n",
      "Precision:\n",
      "0.9805825242718447\n",
      "Recall:\n",
      "0.6917808219178082\n",
      "Coefficient impact:\n",
      "order_inbalance   -1.0264561824177556e-07\n",
      "vwaps_buy   -9.745864602479545e-07\n",
      "vwaps_sell   1.843810502786129e-06\n",
      "s2f_impact_buy   6.622520280524213e-07\n",
      "s2f_impact_sell   1.3696582438945363e-06\n",
      "trading_volumes   -0.0010948764027170097\n",
      "price_volatilities   -1.5675315311833648e-07\n",
      "vwaps_order_sizes_buy   0.0011836176168274774\n",
      "vwaps_order_sizes_sell   -0.00012539034719884651\n",
      "s2f_order_sizes_buy   -6.156597002455055e-05\n",
      "s2f_order_sizes_sell   0.0015084571988798444\n",
      "next_trade_time   4.863419149093467e-05\n",
      "next_trade_size   0.00011503399548637979\n",
      "next_trade_price   -2.6787403309068532e-06\n",
      "Number of positive class in training dataset = 844\n",
      "Number of negative class in training dataset = 551\n",
      "Number of positive class in testing dataset = 91\n",
      "Number of negative class in testing dataset = 64\n",
      "Percent of correct classification:\n",
      "0.49032258064516127\n",
      "Confusion matrix:\n",
      "[[69 22]\n",
      " [57  7]]\n",
      "Precision:\n",
      "0.7582417582417582\n",
      "Recall:\n",
      "0.5476190476190477\n",
      "Coefficient impact:\n",
      "order_inbalance   -2.7287285332591303e-07\n",
      "vwaps_buy   -7.08551476659169e-06\n",
      "vwaps_sell   -9.68658957407325e-06\n",
      "s2f_impact_buy   7.788232252464957e-08\n",
      "s2f_impact_sell   1.6325660542079239e-06\n",
      "trading_volumes   -0.0015306696897273448\n",
      "price_volatilities   -1.2430210291825597e-07\n",
      "vwaps_order_sizes_buy   0.0016505388718073815\n",
      "vwaps_order_sizes_sell   0.0015619624011908692\n",
      "s2f_order_sizes_buy   5.4339197079543036e-05\n",
      "s2f_order_sizes_sell   0.0002348605793298424\n",
      "next_trade_time   2.0543644126018e-05\n",
      "next_trade_size   -8.661710852722674e-05\n",
      "next_trade_price   2.666768308844751e-06\n",
      "Number of positive class in training dataset = 853\n",
      "Number of negative class in training dataset = 542\n",
      "Number of positive class in testing dataset = 82\n",
      "Number of negative class in testing dataset = 73\n",
      "Percent of correct classification:\n",
      "0.567741935483871\n",
      "Confusion matrix:\n",
      "[[82  0]\n",
      " [67  6]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.5503355704697986\n",
      "Coefficient impact:\n",
      "order_inbalance   -8.650965536818183e-07\n",
      "vwaps_buy   -6.412797507876352e-06\n",
      "vwaps_sell   1.0105576523204252e-05\n",
      "s2f_impact_buy   1.0918626008938593e-07\n",
      "s2f_impact_sell   1.83781064699487e-06\n",
      "trading_volumes   -0.001492870120731153\n",
      "price_volatilities   -1.3078109315087174e-07\n",
      "vwaps_order_sizes_buy   0.0016334974271323892\n",
      "vwaps_order_sizes_sell   0.0015163230785024977\n",
      "s2f_order_sizes_buy   -6.0220709945549515e-05\n",
      "s2f_order_sizes_sell   0.00011985595765295533\n",
      "next_trade_time   5.265864388007255e-05\n",
      "next_trade_size   0.0001215013192778166\n",
      "next_trade_price   -1.6858144274723536e-05\n",
      "Number of positive class in training dataset = 821\n",
      "Number of negative class in training dataset = 574\n",
      "Number of positive class in testing dataset = 114\n",
      "Number of negative class in testing dataset = 41\n",
      "Percent of correct classification:\n",
      "0.7806451612903226\n",
      "Confusion matrix:\n",
      "[[113   1]\n",
      " [ 33   8]]\n",
      "Precision:\n",
      "0.9912280701754386\n",
      "Recall:\n",
      "0.773972602739726\n",
      "Coefficient impact:\n",
      "order_inbalance   -4.889853943242639e-07\n",
      "vwaps_buy   -6.468474220636271e-07\n",
      "vwaps_sell   4.367249923311831e-06\n",
      "s2f_impact_buy   -2.9068557036865117e-07\n",
      "s2f_impact_sell   4.343889618682238e-07\n",
      "trading_volumes   -0.0015300289827800606\n",
      "price_volatilities   -1.2638794289724838e-07\n",
      "vwaps_order_sizes_buy   0.001670541554304246\n",
      "vwaps_order_sizes_sell   0.0015401894738526537\n",
      "s2f_order_sizes_buy   -3.317622514339893e-05\n",
      "s2f_order_sizes_sell   0.00017366353231018593\n",
      "next_trade_time   -4.345458829381502e-05\n",
      "next_trade_size   0.00017324159369495632\n",
      "next_trade_price   -5.332804215430759e-06\n",
      "Number of positive class in training dataset = 835\n",
      "Number of negative class in training dataset = 560\n",
      "Number of positive class in testing dataset = 100\n",
      "Number of negative class in testing dataset = 55\n",
      "Percent of correct classification:\n",
      "0.6645161290322581\n",
      "Confusion matrix:\n",
      "[[97  3]\n",
      " [49  6]]\n",
      "Precision:\n",
      "0.97\n",
      "Recall:\n",
      "0.6643835616438356\n",
      "Coefficient impact:\n",
      "order_inbalance   -7.714840839660623e-07\n",
      "vwaps_buy   -4.6406591231293076e-07\n",
      "vwaps_sell   8.674424608911947e-06\n",
      "s2f_impact_buy   -1.032071998554384e-06\n",
      "s2f_impact_sell   1.0342289374962751e-06\n",
      "trading_volumes   -0.0015516236691489626\n",
      "price_volatilities   -1.2992681552506282e-07\n",
      "vwaps_order_sizes_buy   0.0019581967628818976\n",
      "vwaps_order_sizes_sell   0.0015526963445149167\n",
      "s2f_order_sizes_buy   -0.00039344657919002725\n",
      "s2f_order_sizes_sell   0.00020740579172100993\n",
      "next_trade_time   5.075867191859303e-07\n",
      "next_trade_size   0.00022641832486394064\n",
      "next_trade_price   -1.0298190366807425e-05\n",
      "Number of positive class in training dataset = 815\n",
      "Number of negative class in training dataset = 580\n",
      "Number of positive class in testing dataset = 120\n",
      "Number of negative class in testing dataset = 35\n",
      "Percent of correct classification:\n",
      "0.7548387096774194\n",
      "Confusion matrix:\n",
      "[[114   6]\n",
      " [ 32   3]]\n",
      "Precision:\n",
      "0.95\n",
      "Recall:\n",
      "0.7808219178082192\n",
      "Coefficient impact:\n",
      "order_inbalance   -2.2876668430542374e-07\n",
      "vwaps_buy   -2.3560965376591515e-06\n",
      "vwaps_sell   2.6726945949003008e-05\n",
      "s2f_impact_buy   -1.3955647950668e-06\n",
      "s2f_impact_sell   4.837292453421653e-07\n",
      "trading_volumes   -0.0013384727890334064\n",
      "price_volatilities   -1.8276555728167336e-07\n",
      "vwaps_order_sizes_buy   0.0014507017622566764\n",
      "vwaps_order_sizes_sell   0.0013365592446002892\n",
      "s2f_order_sizes_buy   -5.777121061775232e-05\n",
      "s2f_order_sizes_sell   0.00030116637166206013\n",
      "next_trade_time   5.4382042145587945e-05\n",
      "next_trade_size   0.00019864099332894884\n",
      "next_trade_price   -2.887271218291437e-05\n",
      "Number of positive class in training dataset = 884\n",
      "Number of negative class in training dataset = 511\n",
      "Number of positive class in testing dataset = 51\n",
      "Number of negative class in testing dataset = 104\n",
      "Percent of correct classification:\n",
      "0.3870967741935484\n",
      "Confusion matrix:\n",
      "[[51  0]\n",
      " [95  9]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.3493150684931507\n",
      "Coefficient impact:\n",
      "order_inbalance   -3.5478504251416205e-07\n",
      "vwaps_buy   7.655803974396159e-06\n",
      "vwaps_sell   -2.953776953996777e-06\n",
      "s2f_impact_buy   8.577203318783627e-07\n",
      "s2f_impact_sell   7.012136625550074e-07\n",
      "trading_volumes   -0.0014539608389420467\n",
      "price_volatilities   -1.3347532534157608e-07\n",
      "vwaps_order_sizes_buy   0.0015821462693467632\n",
      "vwaps_order_sizes_sell   0.0015423251988238103\n",
      "s2f_order_sizes_buy   -3.5676005007923914e-05\n",
      "s2f_order_sizes_sell   8.972133725810449e-05\n",
      "next_trade_time   4.872836192215489e-05\n",
      "next_trade_size   0.00028979854439383195\n",
      "next_trade_price   1.070001209827255e-05\n",
      "Number of positive class in training dataset = 854\n",
      "Number of negative class in training dataset = 541\n",
      "Number of positive class in testing dataset = 81\n",
      "Number of negative class in testing dataset = 74\n",
      "Percent of correct classification:\n",
      "0.5741935483870968\n",
      "Confusion matrix:\n",
      "[[81  0]\n",
      " [66  8]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.5510204081632653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient impact:\n",
      "order_inbalance   -4.1706341300244273e-07\n",
      "vwaps_buy   7.377691289455924e-07\n",
      "vwaps_sell   3.4024059677086917e-06\n",
      "s2f_impact_buy   1.0351628705810634e-07\n",
      "s2f_impact_sell   -1.9835420857593774e-07\n",
      "trading_volumes   -0.0013065335478801726\n",
      "price_volatilities   -1.695361850071916e-07\n",
      "vwaps_order_sizes_buy   0.0014361264814370873\n",
      "vwaps_order_sizes_sell   0.0013473404949122076\n",
      "s2f_order_sizes_buy   -4.0368966033716736e-05\n",
      "s2f_order_sizes_sell   0.00014750910538653515\n",
      "next_trade_time   -5.5579156997058865e-05\n",
      "next_trade_size   -8.205636363199289e-05\n",
      "next_trade_price   -2.785930937679051e-06\n",
      "Number of positive class in training dataset = 834\n",
      "Number of negative class in training dataset = 561\n",
      "Number of positive class in testing dataset = 101\n",
      "Number of negative class in testing dataset = 54\n",
      "Percent of correct classification:\n",
      "0.7032258064516129\n",
      "Confusion matrix:\n",
      "[[101   0]\n",
      " [ 46   8]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.6870748299319728\n"
     ]
    }
   ],
   "source": [
    "interval=3\n",
    "time_to_skip=30\n",
    "time_back=5\n",
    "y_name='true_price'\n",
    "swing_interval = 60\n",
    "check = 'swing_max'\n",
    "use_scaling = False\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.001\n",
    "sum_of_acc = 0.0\n",
    "sum_of_prec = 0.0\n",
    "sum_of_recall = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, 'log_reg',use_scaling = use_scaling)\n",
    "    sum_of_acc+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: 0.6033365917236887\n",
      "Average precision with scaling: 0.8679321471897529\n",
      "Average recall with scaling: 0.6211568510673052\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy with scaling:\",sum_of_acc/99)\n",
    "print(\"Average precision with scaling:\",sum_of_prec/99)\n",
    "print(\"Average recall with scaling:\",sum_of_recall/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean of all companies for min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n",
      "Coefficient impact:\n",
      "order_inbalance   -1.8828591217146127e-06\n",
      "vwaps_buy   7.750098784825253e-05\n",
      "vwaps_sell   1.9195794835002095e-05\n",
      "s2f_impact_buy   1.630705180952474e-05\n",
      "s2f_impact_sell   5.566725081827462e-06\n",
      "trading_volumes   -0.0002970850321358251\n",
      "price_volatilities   -3.7289466459989946e-09\n",
      "vwaps_order_sizes_buy   0.0001613053463385081\n",
      "vwaps_order_sizes_sell   0.00016423986753041068\n",
      "s2f_order_sizes_buy   5.2840451793058134e-05\n",
      "s2f_order_sizes_sell   8.961440309866106e-05\n",
      "next_trade_time   0.0009360994605470765\n",
      "next_trade_size   0.002625491109233562\n",
      "next_trade_price   5.851931052256638e-05\n",
      "Number of positive class in training dataset = 897\n",
      "Number of negative class in training dataset = 498\n",
      "Number of positive class in testing dataset = 88\n",
      "Number of negative class in testing dataset = 67\n",
      "Percent of correct classification:\n",
      "0.5483870967741935\n",
      "Confusion matrix:\n",
      "[[81  7]\n",
      " [63  4]]\n",
      "Precision:\n",
      "0.9204545454545454\n",
      "Recall:\n",
      "0.5625\n",
      "Coefficient impact:\n",
      "order_inbalance   -2.4167425608750014e-07\n",
      "vwaps_buy   1.2225962831078098e-05\n",
      "vwaps_sell   4.904584798116194e-06\n",
      "s2f_impact_buy   1.488311129316491e-06\n",
      "s2f_impact_sell   9.622510576921978e-07\n",
      "trading_volumes   -0.00025622111270562825\n",
      "price_volatilities   -1.2281881770039154e-07\n",
      "vwaps_order_sizes_buy   0.00017514429100731855\n",
      "vwaps_order_sizes_sell   4.783361848631115e-05\n",
      "s2f_order_sizes_buy   0.00011131825985834076\n",
      "s2f_order_sizes_sell   0.00034859804744289216\n",
      "next_trade_time   0.0001489516312228521\n",
      "next_trade_size   0.00047348809044688554\n",
      "next_trade_price   7.069677154845013e-06\n",
      "Number of positive class in training dataset = 885\n",
      "Number of negative class in training dataset = 510\n",
      "Number of positive class in testing dataset = 100\n",
      "Number of negative class in testing dataset = 55\n",
      "Percent of correct classification:\n",
      "0.6387096774193548\n",
      "Confusion matrix:\n",
      "[[95  5]\n",
      " [51  4]]\n",
      "Precision:\n",
      "0.95\n",
      "Recall:\n",
      "0.6506849315068494\n",
      "Coefficient impact:\n",
      "order_inbalance   -3.957635384407204e-07\n",
      "vwaps_buy   5.3563132276578744e-05\n",
      "vwaps_sell   1.2205972157247538e-05\n",
      "s2f_impact_buy   7.248144265849688e-06\n",
      "s2f_impact_sell   1.4417657106355403e-06\n",
      "trading_volumes   -0.0003927483628453776\n",
      "price_volatilities   -4.641023112726761e-08\n",
      "vwaps_order_sizes_buy   0.0002882667613866101\n",
      "vwaps_order_sizes_sell   0.000627619561906407\n",
      "s2f_order_sizes_buy   0.0001573376527667687\n",
      "s2f_order_sizes_sell   -0.0003063309262759238\n",
      "next_trade_time   0.00034788405688298944\n",
      "next_trade_size   0.0014734394738031128\n",
      "next_trade_price   4.156260026337347e-05\n",
      "Number of positive class in training dataset = 873\n",
      "Number of negative class in training dataset = 522\n",
      "Number of positive class in testing dataset = 112\n",
      "Number of negative class in testing dataset = 43\n",
      "Percent of correct classification:\n",
      "0.7419354838709677\n",
      "Confusion matrix:\n",
      "[[109   3]\n",
      " [ 37   6]]\n",
      "Precision:\n",
      "0.9732142857142857\n",
      "Recall:\n",
      "0.7465753424657534\n",
      "Coefficient impact:\n",
      "order_inbalance   -1.368631792903119e-06\n",
      "vwaps_buy   8.400227800572212e-05\n",
      "vwaps_sell   1.6765877279718653e-05\n",
      "s2f_impact_buy   1.4511097078907722e-05\n",
      "s2f_impact_sell   4.281926422733833e-06\n",
      "trading_volumes   -0.00026877948784771684\n",
      "price_volatilities   4.895486157465891e-08\n",
      "vwaps_order_sizes_buy   0.00011684469673048172\n",
      "vwaps_order_sizes_sell   0.0001972147024566093\n",
      "s2f_order_sizes_buy   0.00013033163080462132\n",
      "s2f_order_sizes_sell   -7.570094676562156e-06\n",
      "next_trade_time   0.0008682760308036742\n",
      "next_trade_size   0.002835105583473607\n",
      "next_trade_price   6.567326066138617e-05\n",
      "Number of positive class in training dataset = 889\n",
      "Number of negative class in training dataset = 506\n",
      "Number of positive class in testing dataset = 96\n",
      "Number of negative class in testing dataset = 59\n",
      "Percent of correct classification:\n",
      "0.6645161290322581\n",
      "Confusion matrix:\n",
      "[[96  0]\n",
      " [52  7]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.6486486486486487\n",
      "Coefficient impact:\n",
      "order_inbalance   -5.924895368105376e-08\n",
      "vwaps_buy   1.1971701735988983e-05\n",
      "vwaps_sell   8.83115351167216e-07\n",
      "s2f_impact_buy   1.7455677288451528e-06\n",
      "s2f_impact_sell   3.66996825066215e-07\n",
      "trading_volumes   -0.0001736305044728629\n",
      "price_volatilities   -1.2370474148661505e-07\n",
      "vwaps_order_sizes_buy   9.934963376872629e-05\n",
      "vwaps_order_sizes_sell   -3.9606128113318016e-05\n",
      "s2f_order_sizes_buy   9.961020889470242e-05\n",
      "s2f_order_sizes_sell   0.0004622631462511602\n",
      "next_trade_time   7.872630041381126e-05\n",
      "next_trade_size   0.00038452391505729405\n",
      "next_trade_price   1.1078448648985267e-05\n",
      "Number of positive class in training dataset = 913\n",
      "Number of negative class in training dataset = 482\n",
      "Number of positive class in testing dataset = 72\n",
      "Number of negative class in testing dataset = 83\n",
      "Percent of correct classification:\n",
      "0.5096774193548387\n",
      "Confusion matrix:\n",
      "[[72  0]\n",
      " [76  7]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.4864864864864865\n",
      "Coefficient impact:\n",
      "order_inbalance   -8.573391578759826e-07\n",
      "vwaps_buy   7.029967168408758e-05\n",
      "vwaps_sell   1.4564574506498257e-05\n",
      "s2f_impact_buy   1.1363700791839636e-05\n",
      "s2f_impact_sell   4.02621468083773e-06\n",
      "trading_volumes   -0.00043064921954310246\n",
      "price_volatilities   -1.6492133932579972e-08\n",
      "vwaps_order_sizes_buy   0.00032359370723943987\n",
      "vwaps_order_sizes_sell   0.00035310137328572474\n",
      "s2f_order_sizes_buy   4.4920512184719194e-05\n",
      "s2f_order_sizes_sell   4.773131807817184e-05\n",
      "next_trade_time   0.000541494294172841\n",
      "next_trade_size   0.0021737854018374107\n",
      "next_trade_price   5.5804752349249865e-05\n",
      "Number of positive class in training dataset = 879\n",
      "Number of negative class in training dataset = 516\n",
      "Number of positive class in testing dataset = 106\n",
      "Number of negative class in testing dataset = 49\n",
      "Percent of correct classification:\n",
      "0.6645161290322581\n",
      "Confusion matrix:\n",
      "[[99  7]\n",
      " [45  4]]\n",
      "Precision:\n",
      "0.9339622641509434\n",
      "Recall:\n",
      "0.6875\n",
      "Coefficient impact:\n",
      "order_inbalance   -1.25313419866331e-06\n",
      "vwaps_buy   7.370071934878245e-05\n",
      "vwaps_sell   1.7330280469801296e-05\n",
      "s2f_impact_buy   1.418340266592143e-05\n",
      "s2f_impact_sell   5.456110566377348e-06\n",
      "trading_volumes   -0.0001733022015829408\n",
      "price_volatilities   1.870542657777609e-09\n",
      "vwaps_order_sizes_buy   -0.00019775830503717214\n",
      "vwaps_order_sizes_sell   2.9783088549777366e-05\n",
      "s2f_order_sizes_buy   0.00033013648299742637\n",
      "s2f_order_sizes_sell   0.00011014456718008244\n",
      "next_trade_time   0.0006983387908894343\n",
      "next_trade_size   0.0025664002735868463\n",
      "next_trade_price   5.81919008437396e-05\n",
      "Number of positive class in training dataset = 900\n",
      "Number of negative class in training dataset = 495\n",
      "Number of positive class in testing dataset = 85\n",
      "Number of negative class in testing dataset = 70\n",
      "Percent of correct classification:\n",
      "0.567741935483871\n",
      "Confusion matrix:\n",
      "[[78  7]\n",
      " [60 10]]\n",
      "Precision:\n",
      "0.9176470588235294\n",
      "Recall:\n",
      "0.5652173913043478\n",
      "Coefficient impact:\n",
      "order_inbalance   -1.0213390091441517e-06\n",
      "vwaps_buy   5.704303132645806e-05\n",
      "vwaps_sell   -7.024813507319775e-06\n",
      "s2f_impact_buy   8.84663471774701e-06\n",
      "s2f_impact_sell   2.0470228541674725e-06\n",
      "trading_volumes   -0.0004779783796403093\n",
      "price_volatilities   -3.932706840581917e-08\n",
      "vwaps_order_sizes_buy   0.00037388558012478904\n",
      "vwaps_order_sizes_sell   0.00036774029855777656\n",
      "s2f_order_sizes_buy   0.00011715529439822153\n",
      "s2f_order_sizes_sell   7.88744182190561e-05\n",
      "next_trade_time   0.0003368407875159366\n",
      "next_trade_size   0.001558172506257306\n",
      "next_trade_price   6.405348292767598e-05\n",
      "Number of positive class in training dataset = 858\n",
      "Number of negative class in training dataset = 537\n",
      "Number of positive class in testing dataset = 127\n",
      "Number of negative class in testing dataset = 28\n",
      "Percent of correct classification:\n",
      "0.7741935483870968\n",
      "Confusion matrix:\n",
      "[[118   9]\n",
      " [ 26   2]]\n",
      "Precision:\n",
      "0.9291338582677166\n",
      "Recall:\n",
      "0.8194444444444444\n",
      "Coefficient impact:\n",
      "order_inbalance   -1.469535000906078e-06\n",
      "vwaps_buy   6.11846933256753e-05\n",
      "vwaps_sell   2.8751553650849985e-05\n",
      "s2f_impact_buy   1.0549853405540102e-05\n",
      "s2f_impact_sell   4.410387948688572e-06\n",
      "trading_volumes   -0.0005935916464903787\n",
      "price_volatilities   6.3477307164608795e-09\n",
      "vwaps_order_sizes_buy   0.00048671433226200547\n",
      "vwaps_order_sizes_sell   0.0004301210667358663\n",
      "s2f_order_sizes_buy   2.2770956490771512e-05\n",
      "s2f_order_sizes_sell   0.0001394903697770065\n",
      "next_trade_time   0.0005457676075584032\n",
      "next_trade_size   0.0028789054803232948\n",
      "next_trade_price   3.0669207112130235e-05\n",
      "Number of positive class in training dataset = 881\n",
      "Number of negative class in training dataset = 514\n",
      "Number of positive class in testing dataset = 104\n",
      "Number of negative class in testing dataset = 51\n",
      "Percent of correct classification:\n",
      "0.632258064516129\n",
      "Confusion matrix:\n",
      "[[95  9]\n",
      " [48  3]]\n",
      "Precision:\n",
      "0.9134615384615384\n",
      "Recall:\n",
      "0.6643356643356644\n",
      "Coefficient impact:\n",
      "order_inbalance   -5.803028985244528e-07\n",
      "vwaps_buy   9.356281303223478e-05\n",
      "vwaps_sell   2.4660426166189192e-05\n",
      "s2f_impact_buy   1.4766969930866791e-05\n",
      "s2f_impact_sell   5.028347360258838e-06\n",
      "trading_volumes   -0.0002593309976814304\n",
      "price_volatilities   2.3087339632786896e-09\n",
      "vwaps_order_sizes_buy   0.0001395064986665898\n",
      "vwaps_order_sizes_sell   0.00011316705007408756\n",
      "s2f_order_sizes_buy   5.228686997039878e-05\n",
      "s2f_order_sizes_sell   0.00012565017093221095\n",
      "next_trade_time   0.0009237618313392453\n",
      "next_trade_size   0.0024391181925310108\n",
      "next_trade_price   6.989928130840936e-05\n",
      "Number of positive class in training dataset = 890\n",
      "Number of negative class in training dataset = 505\n",
      "Number of positive class in testing dataset = 95\n",
      "Number of negative class in testing dataset = 60\n",
      "Percent of correct classification:\n",
      "0.6193548387096774\n",
      "Confusion matrix:\n",
      "[[94  1]\n",
      " [58  2]]\n",
      "Precision:\n",
      "0.9894736842105263\n",
      "Recall:\n",
      "0.618421052631579\n"
     ]
    }
   ],
   "source": [
    "interval=3\n",
    "time_to_skip=30\n",
    "time_back=5\n",
    "y_name='true_price'\n",
    "swing_interval = 60\n",
    "check = 'swing_min'\n",
    "use_scaling = False\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.001\n",
    "sum_of_acc = 0.0\n",
    "sum_of_prec = 0.0\n",
    "sum_of_recall = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, 'log_reg',use_scaling = use_scaling)\n",
    "    sum_of_acc+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: 0.576454871293581\n",
      "Average precision with scaling: 0.8199232778923681\n",
      "Average recall with scaling: nan\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy with scaling:\",sum_of_acc/99)\n",
    "print(\"Average precision with scaling:\",sum_of_prec/99)\n",
    "print(\"Average recall with scaling:\",sum_of_recall/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ze skalowaniem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przyklad 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold =  0.001\n",
      "Coefficient impact:\n",
      "order_inbalance   0.4890604970328552\n",
      "vwaps_buy   0.44939581313920995\n",
      "vwaps_sell   0.8326933838588187\n",
      "s2f_impact_buy   0.8222000195703376\n",
      "s2f_impact_sell   1.0130464399879642\n",
      "trading_volumes   -1.6802226300167704\n",
      "price_volatilities   0.5267784922843417\n",
      "vwaps_order_sizes_buy   -0.8113233323001273\n",
      "vwaps_order_sizes_sell   0.7891015577624829\n",
      "s2f_order_sizes_buy   -0.347581718396614\n",
      "s2f_order_sizes_sell   -1.2280689273486873\n",
      "next_trade_time   1.028525295521642\n",
      "next_trade_size   0.46890008360939794\n",
      "next_trade_price   -0.0060772297661219245\n",
      "Number of positive class in training dataset = 897\n",
      "Number of negative class in training dataset = 498\n",
      "Number of positive class in testing dataset = 104\n",
      "Number of negative class in testing dataset = 51\n",
      "Percent of correct classification:\n",
      "0.6387096774193548\n",
      "Confusion matrix:\n",
      "[[96  8]\n",
      " [48  3]]\n",
      "Precision:\n",
      "0.9230769230769231\n",
      "Recall:\n",
      "0.6666666666666666\n",
      "Coefficient impact:\n",
      "order_inbalance   0.5181524465217651\n",
      "vwaps_buy   0.37624465028281495\n",
      "vwaps_sell   0.794524263904426\n",
      "s2f_impact_buy   0.5515712166372355\n",
      "s2f_impact_sell   0.6586439093208742\n",
      "trading_volumes   -1.8625129610038738\n",
      "price_volatilities   0.5517466556664841\n",
      "vwaps_order_sizes_buy   -0.7928393888404341\n",
      "vwaps_order_sizes_sell   0.7907653271115989\n",
      "s2f_order_sizes_buy   0.13970907430405824\n",
      "s2f_order_sizes_sell   -1.21737095983369\n",
      "next_trade_time   1.0894149260522537\n",
      "next_trade_size   0.2800920481041966\n",
      "next_trade_price   -0.12661524200131688\n",
      "Number of positive class in training dataset = 901\n",
      "Number of negative class in training dataset = 494\n",
      "Number of positive class in testing dataset = 100\n",
      "Number of negative class in testing dataset = 55\n",
      "Percent of correct classification:\n",
      "0.6451612903225806\n",
      "Confusion matrix:\n",
      "[[100   0]\n",
      " [ 55   0]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.6451612903225806\n",
      "Coefficient impact:\n",
      "order_inbalance   0.5122952728999295\n",
      "vwaps_buy   0.04703084880151159\n",
      "vwaps_sell   0.44546353716170617\n",
      "s2f_impact_buy   0.62794014664147\n",
      "s2f_impact_sell   0.8546743420730148\n",
      "trading_volumes   -2.5653313160473474\n",
      "price_volatilities   0.5444297432294799\n",
      "vwaps_order_sizes_buy   -0.6137453181292559\n",
      "vwaps_order_sizes_sell   0.3459382967250108\n",
      "s2f_order_sizes_buy   -0.2798866311595597\n",
      "s2f_order_sizes_sell   -1.6390002246905109\n",
      "next_trade_time   0.9112189748947922\n",
      "next_trade_size   0.5365077957809626\n",
      "next_trade_price   0.04684019822910495\n",
      "Number of positive class in training dataset = 905\n",
      "Number of negative class in training dataset = 490\n",
      "Number of positive class in testing dataset = 96\n",
      "Number of negative class in testing dataset = 59\n",
      "Percent of correct classification:\n",
      "0.6\n",
      "Confusion matrix:\n",
      "[[88  8]\n",
      " [54  5]]\n",
      "Precision:\n",
      "0.9166666666666666\n",
      "Recall:\n",
      "0.6197183098591549\n",
      "Coefficient impact:\n",
      "order_inbalance   0.665907294683264\n",
      "vwaps_buy   0.1873682148498605\n",
      "vwaps_sell   0.654023809778568\n",
      "s2f_impact_buy   0.9624531672707741\n",
      "s2f_impact_sell   0.8478886156770012\n",
      "trading_volumes   -2.0563091952939487\n",
      "price_volatilities   0.5547149962899289\n",
      "vwaps_order_sizes_buy   -0.9858248805138622\n",
      "vwaps_order_sizes_sell   0.9325482093719192\n",
      "s2f_order_sizes_buy   -0.13134196197356876\n",
      "s2f_order_sizes_sell   -1.1264824252246899\n",
      "next_trade_time   0.8898007981476527\n",
      "next_trade_size   0.6208595758147375\n",
      "next_trade_price   -0.1658011562824512\n",
      "Number of positive class in training dataset = 900\n",
      "Number of negative class in training dataset = 495\n",
      "Number of positive class in testing dataset = 101\n",
      "Number of negative class in testing dataset = 54\n",
      "Percent of correct classification:\n",
      "0.6516129032258065\n",
      "Confusion matrix:\n",
      "[[101   0]\n",
      " [ 54   0]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.6516129032258065\n",
      "Coefficient impact:\n",
      "order_inbalance   0.103544853679446\n",
      "vwaps_buy   0.21052014452887083\n",
      "vwaps_sell   0.7775256701768798\n",
      "s2f_impact_buy   1.1406507963409\n",
      "s2f_impact_sell   0.9854302280891799\n",
      "trading_volumes   -1.998862139465306\n",
      "price_volatilities   0.606664922098577\n",
      "vwaps_order_sizes_buy   -1.3632162051786285\n",
      "vwaps_order_sizes_sell   0.8999559370877405\n",
      "s2f_order_sizes_buy   -0.3811410606784638\n",
      "s2f_order_sizes_sell   -1.0889607964574664\n",
      "next_trade_time   1.316247943265268\n",
      "next_trade_size   0.17387830258655418\n",
      "next_trade_price   -0.2540819668491739\n",
      "Number of positive class in training dataset = 879\n",
      "Number of negative class in training dataset = 516\n",
      "Number of positive class in testing dataset = 122\n",
      "Number of negative class in testing dataset = 33\n",
      "Percent of correct classification:\n",
      "0.7161290322580646\n",
      "Confusion matrix:\n",
      "[[94 28]\n",
      " [16 17]]\n",
      "Precision:\n",
      "0.7704918032786885\n",
      "Recall:\n",
      "0.8545454545454545\n",
      "Coefficient impact:\n",
      "order_inbalance   0.8836344525380461\n",
      "vwaps_buy   0.008380056826516165\n",
      "vwaps_sell   0.5295544316754202\n",
      "s2f_impact_buy   0.6164231934992305\n",
      "s2f_impact_sell   0.8304405864309566\n",
      "trading_volumes   -1.843067437553248\n",
      "price_volatilities   0.7994846266600475\n",
      "vwaps_order_sizes_buy   -0.9247447616945009\n",
      "vwaps_order_sizes_sell   0.8784032573109241\n",
      "s2f_order_sizes_buy   0.03375947663805151\n",
      "s2f_order_sizes_sell   -1.1609084635338978\n",
      "next_trade_time   1.8067169744323746\n",
      "next_trade_size   -0.2655346782993499\n",
      "next_trade_price   -0.17195784374916437\n",
      "Number of positive class in training dataset = 912\n",
      "Number of negative class in training dataset = 483\n",
      "Number of positive class in testing dataset = 89\n",
      "Number of negative class in testing dataset = 66\n",
      "Percent of correct classification:\n",
      "0.5741935483870968\n",
      "Confusion matrix:\n",
      "[[89  0]\n",
      " [66  0]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.5741935483870968\n",
      "Coefficient impact:\n",
      "order_inbalance   0.7147602717305945\n",
      "vwaps_buy   0.041374864795423606\n",
      "vwaps_sell   0.8714521068743126\n",
      "s2f_impact_buy   1.4313121930692794\n",
      "s2f_impact_sell   0.707514743979865\n",
      "trading_volumes   -1.4461629569852317\n",
      "price_volatilities   0.20366801180547886\n",
      "vwaps_order_sizes_buy   -0.09217194001314379\n",
      "vwaps_order_sizes_sell   0.7424538746759437\n",
      "s2f_order_sizes_buy   -0.2729771761308022\n",
      "s2f_order_sizes_sell   -1.2642733592075828\n",
      "next_trade_time   1.1448049135338532\n",
      "next_trade_size   0.723126067116788\n",
      "next_trade_price   -0.3507658821317699\n",
      "Number of positive class in training dataset = 913\n",
      "Number of negative class in training dataset = 482\n",
      "Number of positive class in testing dataset = 88\n",
      "Number of negative class in testing dataset = 67\n",
      "Percent of correct classification:\n",
      "0.5741935483870968\n",
      "Confusion matrix:\n",
      "[[82  6]\n",
      " [60  7]]\n",
      "Precision:\n",
      "0.9318181818181818\n",
      "Recall:\n",
      "0.5774647887323944\n",
      "Coefficient impact:\n",
      "order_inbalance   0.3956741129320056\n",
      "vwaps_buy   0.34499665768591226\n",
      "vwaps_sell   0.893933611115551\n",
      "s2f_impact_buy   0.605052089879162\n",
      "s2f_impact_sell   0.929390736332546\n",
      "trading_volumes   -1.9284465840138318\n",
      "price_volatilities   0.8553473856858349\n",
      "vwaps_order_sizes_buy   -0.5971990762525248\n",
      "vwaps_order_sizes_sell   0.8669106162213107\n",
      "s2f_order_sizes_buy   0.01986695861170854\n",
      "s2f_order_sizes_sell   -0.7911641678414936\n",
      "next_trade_time   1.202666508645179\n",
      "next_trade_size   0.46945416539489343\n",
      "next_trade_price   -0.04984995234213308\n",
      "Number of positive class in training dataset = 892\n",
      "Number of negative class in training dataset = 503\n",
      "Number of positive class in testing dataset = 109\n",
      "Number of negative class in testing dataset = 46\n",
      "Percent of correct classification:\n",
      "0.6967741935483871\n",
      "Confusion matrix:\n",
      "[[107   2]\n",
      " [ 45   1]]\n",
      "Precision:\n",
      "0.981651376146789\n",
      "Recall:\n",
      "0.7039473684210527\n",
      "Coefficient impact:\n",
      "order_inbalance   0.41074918015392803\n",
      "vwaps_buy   0.2503474025202558\n",
      "vwaps_sell   0.5750298521929083\n",
      "s2f_impact_buy   0.7124435002008777\n",
      "s2f_impact_sell   0.9563711027075862\n",
      "trading_volumes   -1.8791958400767992\n",
      "price_volatilities   0.3470862818967442\n",
      "vwaps_order_sizes_buy   -0.8796693055706065\n",
      "vwaps_order_sizes_sell   0.9908628556970785\n",
      "s2f_order_sizes_buy   -0.05929529977380378\n",
      "s2f_order_sizes_sell   -1.3101156624795123\n",
      "next_trade_time   0.9237816599823644\n",
      "next_trade_size   0.3308558580921564\n",
      "next_trade_price   -0.06840603842981476\n",
      "Number of positive class in training dataset = 916\n",
      "Number of negative class in training dataset = 479\n",
      "Number of positive class in testing dataset = 85\n",
      "Number of negative class in testing dataset = 70\n",
      "Percent of correct classification:\n",
      "0.5483870967741935\n",
      "Confusion matrix:\n",
      "[[85  0]\n",
      " [70  0]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.5483870967741935\n",
      "Coefficient impact:\n",
      "order_inbalance   0.4712737122437305\n",
      "vwaps_buy   0.45368182128701223\n",
      "vwaps_sell   0.8874244035530766\n",
      "s2f_impact_buy   0.8104564194973726\n",
      "s2f_impact_sell   1.0560213484684662\n",
      "trading_volumes   -2.022496459766327\n",
      "price_volatilities   0.3497356253956273\n",
      "vwaps_order_sizes_buy   -0.48906514586309197\n",
      "vwaps_order_sizes_sell   0.9345338787081601\n",
      "s2f_order_sizes_buy   -0.13988362388485243\n",
      "s2f_order_sizes_sell   -1.034048836436007\n",
      "next_trade_time   0.9110260969713088\n",
      "next_trade_size   -0.2841219044488104\n",
      "next_trade_price   -0.05518292798725567\n",
      "Number of positive class in training dataset = 894\n",
      "Number of negative class in training dataset = 501\n",
      "Number of positive class in testing dataset = 107\n",
      "Number of negative class in testing dataset = 48\n",
      "Percent of correct classification:\n",
      "0.6709677419354839\n",
      "Confusion matrix:\n",
      "[[104   3]\n",
      " [ 48   0]]\n",
      "Precision:\n",
      "0.9719626168224299\n",
      "Recall:\n",
      "0.6842105263157895\n",
      "Average model accuracy: 0.6316129032258064\n",
      "Average precision: 0.9495667567809678\n",
      "Average recall: 0.652590795325019\n"
     ]
    }
   ],
   "source": [
    "comp_id = 1\n",
    "interval=3\n",
    "time_to_skip=30\n",
    "time_back=5\n",
    "y_name='true_price'\n",
    "swing_interval = 60\n",
    "check = 'swing_max'\n",
    "use_scaling = True\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.001\n",
    "print(\"Threshold = \", threshold)\n",
    "X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "#X,y=get_X_y_classic(comp_id, interval, time_to_skip, time_back, period_of_getting_data_to_test, names, y_name, test_min_max, threshold)\n",
    "res_per_day = cross_validation(X, y, 'log_reg',use_scaling = use_scaling)\n",
    "print(\"Average model accuracy:\", np.sum(res_per_day[:,0])/res_per_day.shape[0])\n",
    "print(\"Average precision:\", np.sum(res_per_day[:,1])/res_per_day.shape[0])\n",
    "print(\"Average recall:\", np.sum(res_per_day[:,2])/res_per_day.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przyklad 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold =  0.001\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.2541731541047534\n",
      "vwaps_buy   0.551566111973438\n",
      "vwaps_sell   1.6822625608017596\n",
      "s2f_impact_buy   -0.1379636929640886\n",
      "s2f_impact_sell   -1.1808795539449917\n",
      "trading_volumes   -1.9620348176411044\n",
      "price_volatilities   0.2325294995916844\n",
      "vwaps_order_sizes_buy   -0.33917109148997976\n",
      "vwaps_order_sizes_sell   0.6224633839331417\n",
      "s2f_order_sizes_buy   -0.6248050935216554\n",
      "s2f_order_sizes_sell   0.506623883792839\n",
      "next_trade_time   -1.9043734260775722\n",
      "next_trade_size   1.0364394102607772\n",
      "next_trade_price   -0.27897693650868083\n",
      "Number of positive class in training dataset = 762\n",
      "Number of negative class in training dataset = 633\n",
      "Number of positive class in testing dataset = 113\n",
      "Number of negative class in testing dataset = 42\n",
      "Percent of correct classification:\n",
      "0.7225806451612903\n",
      "Confusion matrix:\n",
      "[[105   8]\n",
      " [ 35   7]]\n",
      "Precision:\n",
      "0.9292035398230089\n",
      "Recall:\n",
      "0.75\n",
      "Coefficient impact:\n",
      "order_inbalance   0.11990174766141067\n",
      "vwaps_buy   0.34099627688463224\n",
      "vwaps_sell   1.3242082508764377\n",
      "s2f_impact_buy   0.061856836793107335\n",
      "s2f_impact_sell   -1.3731143719754269\n",
      "trading_volumes   -1.8103896104955335\n",
      "price_volatilities   0.34007986201352797\n",
      "vwaps_order_sizes_buy   -0.1297912393407393\n",
      "vwaps_order_sizes_sell   0.5853332370025642\n",
      "s2f_order_sizes_buy   -0.6826271704418232\n",
      "s2f_order_sizes_sell   0.7923482453700782\n",
      "next_trade_time   -1.6360286098458132\n",
      "next_trade_size   0.8838950100424982\n",
      "next_trade_price   -0.2915881036803223\n",
      "Number of positive class in training dataset = 828\n",
      "Number of negative class in training dataset = 567\n",
      "Number of positive class in testing dataset = 47\n",
      "Number of negative class in testing dataset = 108\n",
      "Percent of correct classification:\n",
      "0.49032258064516127\n",
      "Confusion matrix:\n",
      "[[41  6]\n",
      " [73 35]]\n",
      "Precision:\n",
      "0.8723404255319149\n",
      "Recall:\n",
      "0.35964912280701755\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.15881028752308957\n",
      "vwaps_buy   0.6594342933168267\n",
      "vwaps_sell   1.7508142966118976\n",
      "s2f_impact_buy   -0.530425991057093\n",
      "s2f_impact_sell   -1.3796181777782044\n",
      "trading_volumes   -1.9932063538310687\n",
      "price_volatilities   0.4077084663092379\n",
      "vwaps_order_sizes_buy   -0.6320100375376401\n",
      "vwaps_order_sizes_sell   0.6318413487669009\n",
      "s2f_order_sizes_buy   -0.45130863582665154\n",
      "s2f_order_sizes_sell   0.6321713184632678\n",
      "next_trade_time   -1.7258790120510872\n",
      "next_trade_size   0.9489460657616127\n",
      "next_trade_price   -0.10954388510899328\n",
      "Number of positive class in training dataset = 759\n",
      "Number of negative class in training dataset = 636\n",
      "Number of positive class in testing dataset = 116\n",
      "Number of negative class in testing dataset = 39\n",
      "Percent of correct classification:\n",
      "0.5806451612903226\n",
      "Confusion matrix:\n",
      "[[78 38]\n",
      " [27 12]]\n",
      "Precision:\n",
      "0.6724137931034483\n",
      "Recall:\n",
      "0.7428571428571429\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.19278500173458812\n",
      "vwaps_buy   0.47555057628609715\n",
      "vwaps_sell   1.0848609396011433\n",
      "s2f_impact_buy   -0.6146794577675391\n",
      "s2f_impact_sell   -1.1529998832022055\n",
      "trading_volumes   -1.8052444251684403\n",
      "price_volatilities   0.4486487610219488\n",
      "vwaps_order_sizes_buy   -0.5397554341184033\n",
      "vwaps_order_sizes_sell   0.4324257643431631\n",
      "s2f_order_sizes_buy   -0.5210379856053106\n",
      "s2f_order_sizes_sell   0.46418559834189926\n",
      "next_trade_time   -2.0463326251764613\n",
      "next_trade_size   0.44633769473690127\n",
      "next_trade_price   0.22083651451044864\n",
      "Number of positive class in training dataset = 771\n",
      "Number of negative class in training dataset = 624\n",
      "Number of positive class in testing dataset = 104\n",
      "Number of negative class in testing dataset = 51\n",
      "Percent of correct classification:\n",
      "0.6451612903225806\n",
      "Confusion matrix:\n",
      "[[89 15]\n",
      " [40 11]]\n",
      "Precision:\n",
      "0.8557692307692307\n",
      "Recall:\n",
      "0.689922480620155\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.09029476711781573\n",
      "vwaps_buy   0.9925269128569031\n",
      "vwaps_sell   1.798991606910027\n",
      "s2f_impact_buy   -0.5202053022217603\n",
      "s2f_impact_sell   -1.3372644719835425\n",
      "trading_volumes   -1.5571155230769\n",
      "price_volatilities   0.049224759977327184\n",
      "vwaps_order_sizes_buy   -0.494636879396148\n",
      "vwaps_order_sizes_sell   0.1326483068153999\n",
      "s2f_order_sizes_buy   -1.5099043546097075\n",
      "s2f_order_sizes_sell   0.00622680531172997\n",
      "next_trade_time   -2.3476886956126073\n",
      "next_trade_size   1.4535901487292409\n",
      "next_trade_price   -0.1912393789852915\n",
      "Number of positive class in training dataset = 756\n",
      "Number of negative class in training dataset = 639\n",
      "Number of positive class in testing dataset = 119\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "0.3870967741935484\n",
      "Confusion matrix:\n",
      "[[34 85]\n",
      " [10 26]]\n",
      "Precision:\n",
      "0.2857142857142857\n",
      "Recall:\n",
      "0.7727272727272727\n",
      "Coefficient impact:\n",
      "order_inbalance   0.1887868495365338\n",
      "vwaps_buy   0.2445338191894332\n",
      "vwaps_sell   1.4403031605331427\n",
      "s2f_impact_buy   -0.3072302766781272\n",
      "s2f_impact_sell   -1.5778079491800652\n",
      "trading_volumes   -1.9453236087891672\n",
      "price_volatilities   -0.0034980408456099167\n",
      "vwaps_order_sizes_buy   -0.5364401167848046\n",
      "vwaps_order_sizes_sell   0.10386567975237992\n",
      "s2f_order_sizes_buy   -0.5957676981941961\n",
      "s2f_order_sizes_sell   0.26244054735794775\n",
      "next_trade_time   -2.141521357443859\n",
      "next_trade_size   1.0059621106983614\n",
      "next_trade_price   -0.42866471478089385\n",
      "Number of positive class in training dataset = 815\n",
      "Number of negative class in training dataset = 580\n",
      "Number of positive class in testing dataset = 60\n",
      "Number of negative class in testing dataset = 95\n",
      "Percent of correct classification:\n",
      "0.45161290322580644\n",
      "Confusion matrix:\n",
      "[[54  6]\n",
      " [79 16]]\n",
      "Precision:\n",
      "0.9\n",
      "Recall:\n",
      "0.40601503759398494\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.1696852539304173\n",
      "vwaps_buy   0.44808975179676686\n",
      "vwaps_sell   1.375239673427754\n",
      "s2f_impact_buy   -0.41242086812772294\n",
      "s2f_impact_sell   -1.2869587664738549\n",
      "trading_volumes   -1.7790742951687684\n",
      "price_volatilities   0.30282091904538005\n",
      "vwaps_order_sizes_buy   0.12442604129413262\n",
      "vwaps_order_sizes_sell   0.7751828266135786\n",
      "s2f_order_sizes_buy   -0.2639905064568147\n",
      "s2f_order_sizes_sell   0.6920630766092273\n",
      "next_trade_time   -1.8867288767242887\n",
      "next_trade_size   1.5458269320416513\n",
      "next_trade_price   -0.18174918839330298\n",
      "Number of positive class in training dataset = 811\n",
      "Number of negative class in training dataset = 584\n",
      "Number of positive class in testing dataset = 64\n",
      "Number of negative class in testing dataset = 91\n",
      "Percent of correct classification:\n",
      "0.5612903225806452\n",
      "Confusion matrix:\n",
      "[[52 12]\n",
      " [56 35]]\n",
      "Precision:\n",
      "0.8125\n",
      "Recall:\n",
      "0.48148148148148145\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.03900769022899002\n",
      "vwaps_buy   0.6872824282506486\n",
      "vwaps_sell   1.9680366734104868\n",
      "s2f_impact_buy   -0.4313525238265698\n",
      "s2f_impact_sell   -1.1963928978326313\n",
      "trading_volumes   -1.722056824846152\n",
      "price_volatilities   0.23705515557365273\n",
      "vwaps_order_sizes_buy   -0.6084833402264992\n",
      "vwaps_order_sizes_sell   0.5365409729854194\n",
      "s2f_order_sizes_buy   -0.5887118193939479\n",
      "s2f_order_sizes_sell   0.27105388365241734\n",
      "next_trade_time   -1.3288304176838093\n",
      "next_trade_size   1.1341090930211655\n",
      "next_trade_price   -0.376639413119461\n",
      "Number of positive class in training dataset = 811\n",
      "Number of negative class in training dataset = 584\n",
      "Number of positive class in testing dataset = 64\n",
      "Number of negative class in testing dataset = 91\n",
      "Percent of correct classification:\n",
      "0.535483870967742\n",
      "Confusion matrix:\n",
      "[[48 16]\n",
      " [56 35]]\n",
      "Precision:\n",
      "0.75\n",
      "Recall:\n",
      "0.46153846153846156\n",
      "Coefficient impact:\n",
      "order_inbalance   0.3429929299121256\n",
      "vwaps_buy   0.18159428687367285\n",
      "vwaps_sell   1.4391976790225802\n",
      "s2f_impact_buy   -0.4970945185604546\n",
      "s2f_impact_sell   -1.4248953053383073\n",
      "trading_volumes   -1.323029225343006\n",
      "price_volatilities   0.36852305094322213\n",
      "vwaps_order_sizes_buy   -1.012961902469595\n",
      "vwaps_order_sizes_sell   0.7190862437417108\n",
      "s2f_order_sizes_buy   -0.46152716781607095\n",
      "s2f_order_sizes_sell   0.25630423983812867\n",
      "next_trade_time   -2.0295223008232735\n",
      "next_trade_size   1.106104130045948\n",
      "next_trade_price   -0.19050012328947138\n",
      "Number of positive class in training dataset = 769\n",
      "Number of negative class in training dataset = 626\n",
      "Number of positive class in testing dataset = 106\n",
      "Number of negative class in testing dataset = 49\n",
      "Percent of correct classification:\n",
      "0.6193548387096774\n",
      "Confusion matrix:\n",
      "[[78 28]\n",
      " [31 18]]\n",
      "Precision:\n",
      "0.7358490566037735\n",
      "Recall:\n",
      "0.7155963302752294\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.33723242940472514\n",
      "vwaps_buy   0.24230618901444653\n",
      "vwaps_sell   1.318706253426323\n",
      "s2f_impact_buy   -0.4980498571573254\n",
      "s2f_impact_sell   -1.3945660164010893\n",
      "trading_volumes   -2.0983328718092995\n",
      "price_volatilities   0.03660210983198184\n",
      "vwaps_order_sizes_buy   -0.44779473900072025\n",
      "vwaps_order_sizes_sell   0.4566461990881641\n",
      "s2f_order_sizes_buy   -0.6460396159445502\n",
      "s2f_order_sizes_sell   0.25585261795293845\n",
      "next_trade_time   -2.1769021335452066\n",
      "next_trade_size   0.899722178831968\n",
      "next_trade_price   -0.13484165643394297\n",
      "Number of positive class in training dataset = 793\n",
      "Number of negative class in training dataset = 602\n",
      "Number of positive class in testing dataset = 82\n",
      "Number of negative class in testing dataset = 73\n",
      "Percent of correct classification:\n",
      "0.6\n",
      "Confusion matrix:\n",
      "[[78  4]\n",
      " [58 15]]\n",
      "Precision:\n",
      "0.9512195121951219\n",
      "Recall:\n",
      "0.5735294117647058\n",
      "Average model accuracy: 0.5593548387096774\n",
      "Average precision: 0.7765009843740784\n",
      "Average recall: 0.5953316741665451\n"
     ]
    }
   ],
   "source": [
    "comp_id = 7\n",
    "interval=3\n",
    "time_to_skip=30\n",
    "time_back=5\n",
    "y_name='true_price'\n",
    "swing_interval = 60\n",
    "check = 'swing_max'\n",
    "use_scaling = True\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.001\n",
    "print(\"Threshold = \", threshold)\n",
    "X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "#X,y=get_X_y_classic(comp_id, interval, time_to_skip, time_back, period_of_getting_data_to_test, names, y_name, test_min_max, threshold)\n",
    "res_per_day = cross_validation(X, y, 'log_reg',use_scaling = use_scaling)\n",
    "print(\"Average model accuracy:\", np.sum(res_per_day[:,0])/res_per_day.shape[0])\n",
    "print(\"Average precision:\", np.sum(res_per_day[:,1])/res_per_day.shape[0])\n",
    "print(\"Average recall:\", np.sum(res_per_day[:,2])/res_per_day.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean on all companies for max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.3379242990737714\n",
      "vwaps_buy   0.25465838336692836\n",
      "vwaps_sell   -0.10517218293644627\n",
      "s2f_impact_buy   -0.5221934668153186\n",
      "s2f_impact_sell   0.2547325780293074\n",
      "trading_volumes   -0.7122622633269972\n",
      "price_volatilities   -1.2755563161056485\n",
      "vwaps_order_sizes_buy   1.3521778261952238\n",
      "vwaps_order_sizes_sell   -0.2156293417813287\n",
      "s2f_order_sizes_buy   -0.16894265837466044\n",
      "s2f_order_sizes_sell   0.8374979837029971\n",
      "next_trade_time   -0.9127677475590381\n",
      "next_trade_size   -0.06107983022567644\n",
      "next_trade_price   0.14591477390769467\n",
      "Number of positive class in training dataset = 843\n",
      "Number of negative class in training dataset = 552\n",
      "Number of positive class in testing dataset = 92\n",
      "Number of negative class in testing dataset = 63\n",
      "Percent of correct classification:\n",
      "0.6129032258064516\n",
      "Confusion matrix:\n",
      "[[83  9]\n",
      " [51 12]]\n",
      "Precision:\n",
      "0.9021739130434783\n",
      "Recall:\n",
      "0.6194029850746269\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.32439660210710586\n",
      "vwaps_buy   -0.1442503398164633\n",
      "vwaps_sell   -0.3628344744689609\n",
      "s2f_impact_buy   -0.0930441743574092\n",
      "s2f_impact_sell   0.37557116609713975\n",
      "trading_volumes   -0.6953598270261621\n",
      "price_volatilities   -1.2874249908980635\n",
      "vwaps_order_sizes_buy   1.422885111456536\n",
      "vwaps_order_sizes_sell   -0.28086719164858626\n",
      "s2f_order_sizes_buy   -0.3797534290121826\n",
      "s2f_order_sizes_sell   0.4916622505262534\n",
      "next_trade_time   -0.8016200936665175\n",
      "next_trade_size   -0.3741383760378527\n",
      "next_trade_price   -0.1163777603184542\n",
      "Number of positive class in training dataset = 832\n",
      "Number of negative class in training dataset = 563\n",
      "Number of positive class in testing dataset = 103\n",
      "Number of negative class in testing dataset = 52\n",
      "Percent of correct classification:\n",
      "0.6709677419354839\n",
      "Confusion matrix:\n",
      "[[103   0]\n",
      " [ 51   1]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.6688311688311688\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.1650370426464145\n",
      "vwaps_buy   -0.5594534717447878\n",
      "vwaps_sell   -0.4480240621862629\n",
      "s2f_impact_buy   -0.10033116378744487\n",
      "s2f_impact_sell   0.28302880003169967\n",
      "trading_volumes   -1.1849230919838465\n",
      "price_volatilities   -0.8850152176704635\n",
      "vwaps_order_sizes_buy   1.31818486110239\n",
      "vwaps_order_sizes_sell   -1.905276239657181\n",
      "s2f_order_sizes_buy   -0.8794115693495966\n",
      "s2f_order_sizes_sell   2.238967597087414\n",
      "next_trade_time   -0.3110043635962466\n",
      "next_trade_size   -0.3996043182788737\n",
      "next_trade_price   0.10300142058253295\n",
      "Number of positive class in training dataset = 844\n",
      "Number of negative class in training dataset = 551\n",
      "Number of positive class in testing dataset = 91\n",
      "Number of negative class in testing dataset = 64\n",
      "Percent of correct classification:\n",
      "0.3741935483870968\n",
      "Confusion matrix:\n",
      "[[50 41]\n",
      " [56  8]]\n",
      "Precision:\n",
      "0.5494505494505495\n",
      "Recall:\n",
      "0.4716981132075472\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.20455368186730755\n",
      "vwaps_buy   -0.6655325311181509\n",
      "vwaps_sell   -0.9797207936366483\n",
      "s2f_impact_buy   -0.4088259411326972\n",
      "s2f_impact_sell   0.5748594995650533\n",
      "trading_volumes   -0.5673894104955766\n",
      "price_volatilities   -0.8789296582087428\n",
      "vwaps_order_sizes_buy   1.3302467298819987\n",
      "vwaps_order_sizes_sell   0.3706473131601044\n",
      "s2f_order_sizes_buy   0.4301968605356505\n",
      "s2f_order_sizes_sell   0.7636205818656486\n",
      "next_trade_time   -0.09094498811167566\n",
      "next_trade_size   -0.3799595260809744\n",
      "next_trade_price   0.2585273418554447\n",
      "Number of positive class in training dataset = 853\n",
      "Number of negative class in training dataset = 542\n",
      "Number of positive class in testing dataset = 82\n",
      "Number of negative class in testing dataset = 73\n",
      "Percent of correct classification:\n",
      "0.4774193548387097\n",
      "Confusion matrix:\n",
      "[[74  8]\n",
      " [73  0]]\n",
      "Precision:\n",
      "0.9024390243902439\n",
      "Recall:\n",
      "0.5034013605442177\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.6770649193065652\n",
      "vwaps_buy   -0.2001688110626453\n",
      "vwaps_sell   -0.13618204125949523\n",
      "s2f_impact_buy   -0.06748041713917373\n",
      "s2f_impact_sell   0.31880889960359\n",
      "trading_volumes   -0.6501702284454525\n",
      "price_volatilities   -0.8835454693505826\n",
      "vwaps_order_sizes_buy   1.5674188865750687\n",
      "vwaps_order_sizes_sell   -0.4155398061023567\n",
      "s2f_order_sizes_buy   -0.032692828211890644\n",
      "s2f_order_sizes_sell   -0.1071361730166629\n",
      "next_trade_time   -0.051573959425123266\n",
      "next_trade_size   -0.18309016602620581\n",
      "next_trade_price   -0.2957285499936907\n",
      "Number of positive class in training dataset = 821\n",
      "Number of negative class in training dataset = 574\n",
      "Number of positive class in testing dataset = 114\n",
      "Number of negative class in testing dataset = 41\n",
      "Percent of correct classification:\n",
      "0.6064516129032258\n",
      "Confusion matrix:\n",
      "[[86 28]\n",
      " [33  8]]\n",
      "Precision:\n",
      "0.7543859649122807\n",
      "Recall:\n",
      "0.7226890756302521\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.40668045551321647\n",
      "vwaps_buy   -0.11567947051401509\n",
      "vwaps_sell   -0.18187562331865778\n",
      "s2f_impact_buy   -0.31599359138354627\n",
      "s2f_impact_sell   0.012603625724680309\n",
      "trading_volumes   -0.8441775578837566\n",
      "price_volatilities   -1.2251441947127721\n",
      "vwaps_order_sizes_buy   1.5023064067975456\n",
      "vwaps_order_sizes_sell   -0.14478655095464138\n",
      "s2f_order_sizes_buy   0.0665493547149771\n",
      "s2f_order_sizes_sell   0.8141013147290819\n",
      "next_trade_time   -0.6894432562487633\n",
      "next_trade_size   0.07534080822119904\n",
      "next_trade_price   -0.06066029771405498\n",
      "Number of positive class in training dataset = 835\n",
      "Number of negative class in training dataset = 560\n",
      "Number of positive class in testing dataset = 100\n",
      "Number of negative class in testing dataset = 55\n",
      "Percent of correct classification:\n",
      "0.6451612903225806\n",
      "Confusion matrix:\n",
      "[[99  1]\n",
      " [54  1]]\n",
      "Precision:\n",
      "0.99\n",
      "Recall:\n",
      "0.6470588235294118\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.41307078882722115\n",
      "vwaps_buy   0.2354600531044284\n",
      "vwaps_sell   -0.044030280515782214\n",
      "s2f_impact_buy   -0.27060985204129245\n",
      "s2f_impact_sell   0.34063040194432276\n",
      "trading_volumes   -1.7083867839042945\n",
      "price_volatilities   -1.0356563809135757\n",
      "vwaps_order_sizes_buy   1.6552852313196602\n",
      "vwaps_order_sizes_sell   0.7400756410086842\n",
      "s2f_order_sizes_buy   -0.3281118570271405\n",
      "s2f_order_sizes_sell   1.177981556827364\n",
      "next_trade_time   -0.06154479940436716\n",
      "next_trade_size   0.2266167282523526\n",
      "next_trade_price   -0.06694302743852383\n",
      "Number of positive class in training dataset = 815\n",
      "Number of negative class in training dataset = 580\n",
      "Number of positive class in testing dataset = 120\n",
      "Number of negative class in testing dataset = 35\n",
      "Percent of correct classification:\n",
      "0.632258064516129\n",
      "Confusion matrix:\n",
      "[[93 27]\n",
      " [30  5]]\n",
      "Precision:\n",
      "0.775\n",
      "Recall:\n",
      "0.7560975609756098\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.09013471128020233\n",
      "vwaps_buy   0.0640929033130152\n",
      "vwaps_sell   1.1165309802336272\n",
      "s2f_impact_buy   -0.32320511301704224\n",
      "s2f_impact_sell   -0.6223057810573058\n",
      "trading_volumes   -0.7294695327056748\n",
      "price_volatilities   -1.2988783903169216\n",
      "vwaps_order_sizes_buy   1.3804544414051165\n",
      "vwaps_order_sizes_sell   -0.17746454736822298\n",
      "s2f_order_sizes_buy   -0.10223265209328693\n",
      "s2f_order_sizes_sell   0.9134389612281526\n",
      "next_trade_time   -0.33983178834121613\n",
      "next_trade_size   -0.36648863656223296\n",
      "next_trade_price   -0.6879096331495631\n",
      "Number of positive class in training dataset = 884\n",
      "Number of negative class in training dataset = 511\n",
      "Number of positive class in testing dataset = 51\n",
      "Number of negative class in testing dataset = 104\n",
      "Percent of correct classification:\n",
      "0.3225806451612903\n",
      "Confusion matrix:\n",
      "[[ 50   1]\n",
      " [104   0]]\n",
      "Precision:\n",
      "0.9803921568627451\n",
      "Recall:\n",
      "0.3246753246753247\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.3312867914348537\n",
      "vwaps_buy   -0.02398358243783358\n",
      "vwaps_sell   -0.3410938648235981\n",
      "s2f_impact_buy   -0.39062259510857184\n",
      "s2f_impact_sell   0.2085918643017075\n",
      "trading_volumes   -0.6392720071089224\n",
      "price_volatilities   -0.9144275827351586\n",
      "vwaps_order_sizes_buy   1.2952094961717173\n",
      "vwaps_order_sizes_sell   0.30379738373622284\n",
      "s2f_order_sizes_buy   -0.5393070889152887\n",
      "s2f_order_sizes_sell   0.5140029872266647\n",
      "next_trade_time   -0.23550174709294916\n",
      "next_trade_size   -0.001162801735643633\n",
      "next_trade_price   0.3586651621684944\n",
      "Number of positive class in training dataset = 854\n",
      "Number of negative class in training dataset = 541\n",
      "Number of positive class in testing dataset = 81\n",
      "Number of negative class in testing dataset = 74\n",
      "Percent of correct classification:\n",
      "0.5225806451612903\n",
      "Confusion matrix:\n",
      "[[81  0]\n",
      " [74  0]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.5225806451612903\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.39052259805725276\n",
      "vwaps_buy   -0.07092767357408299\n",
      "vwaps_sell   -0.01325486599499468\n",
      "s2f_impact_buy   -0.074096611975453\n",
      "s2f_impact_sell   -0.1288099375351814\n",
      "trading_volumes   -0.6998332065746747\n",
      "price_volatilities   -1.5270353788098636\n",
      "vwaps_order_sizes_buy   1.451863164769542\n",
      "vwaps_order_sizes_sell   0.12898677620923532\n",
      "s2f_order_sizes_buy   -0.27315228079233544\n",
      "s2f_order_sizes_sell   0.871802295881641\n",
      "next_trade_time   -0.6481302756253504\n",
      "next_trade_size   -0.41948823221838205\n",
      "next_trade_price   -0.061737158282416084\n",
      "Number of positive class in training dataset = 834\n",
      "Number of negative class in training dataset = 561\n",
      "Number of positive class in testing dataset = 101\n",
      "Number of negative class in testing dataset = 54\n",
      "Percent of correct classification:\n",
      "0.6645161290322581\n",
      "Confusion matrix:\n",
      "[[101   0]\n",
      " [ 52   2]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.6601307189542484\n"
     ]
    }
   ],
   "source": [
    "interval=3\n",
    "time_to_skip=30\n",
    "time_back=5\n",
    "y_name='true_price'\n",
    "swing_interval = 60\n",
    "check = 'swing_max'\n",
    "use_scaling = True\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.001\n",
    "sum_of_acc = 0.0\n",
    "sum_of_prec = 0.0\n",
    "sum_of_recall = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, 'log_reg',use_scaling = use_scaling)\n",
    "    sum_of_acc+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: 0.5811404366243078\n",
      "Average precision with scaling: 0.8092263291885733\n",
      "Average recall with scaling: 0.6135316805377142\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy with scaling:\",sum_of_acc/99)\n",
    "print(\"Average precision with scaling:\",sum_of_prec/99)\n",
    "print(\"Average recall with scaling:\",sum_of_recall/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean of all companies for min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.5468525348671358\n",
      "vwaps_buy   0.12704512641815027\n",
      "vwaps_sell   -0.08421403742747179\n",
      "s2f_impact_buy   0.23283600119893608\n",
      "s2f_impact_sell   -0.22549726627482067\n",
      "trading_volumes   -2.3890803572651307\n",
      "price_volatilities   0.5738522196498339\n",
      "vwaps_order_sizes_buy   -1.1383750913470028\n",
      "vwaps_order_sizes_sell   -0.8856484100541321\n",
      "s2f_order_sizes_buy   -1.9737851531624724\n",
      "s2f_order_sizes_sell   -0.3612228222411876\n",
      "next_trade_time   -0.4215708194887742\n",
      "next_trade_size   -0.015441517743864187\n",
      "next_trade_price   0.3900642274328904\n",
      "Number of positive class in training dataset = 897\n",
      "Number of negative class in training dataset = 498\n",
      "Number of positive class in testing dataset = 88\n",
      "Number of negative class in testing dataset = 67\n",
      "Percent of correct classification:\n",
      "0.5806451612903226\n",
      "Confusion matrix:\n",
      "[[87  1]\n",
      " [64  3]]\n",
      "Precision:\n",
      "0.9886363636363636\n",
      "Recall:\n",
      "0.5761589403973509\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.7005528359454797\n",
      "vwaps_buy   0.7002807881356952\n",
      "vwaps_sell   -0.06945153620380133\n",
      "s2f_impact_buy   -0.49262129111296826\n",
      "s2f_impact_sell   -0.009772575225624809\n",
      "trading_volumes   -2.239103150035946\n",
      "price_volatilities   0.4569569461017767\n",
      "vwaps_order_sizes_buy   -1.0197935691629956\n",
      "vwaps_order_sizes_sell   -0.9800462035502271\n",
      "s2f_order_sizes_buy   -1.454784601620724\n",
      "s2f_order_sizes_sell   -0.3069513155315222\n",
      "next_trade_time   0.012125370849060079\n",
      "next_trade_size   -0.06656882884668097\n",
      "next_trade_price   0.431208175001884\n",
      "Number of positive class in training dataset = 885\n",
      "Number of negative class in training dataset = 510\n",
      "Number of positive class in testing dataset = 100\n",
      "Number of negative class in testing dataset = 55\n",
      "Percent of correct classification:\n",
      "0.6451612903225806\n",
      "Confusion matrix:\n",
      "[[98  2]\n",
      " [53  2]]\n",
      "Precision:\n",
      "0.98\n",
      "Recall:\n",
      "0.6490066225165563\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.34253088247816416\n",
      "vwaps_buy   0.6126474895636188\n",
      "vwaps_sell   0.16720233050382063\n",
      "s2f_impact_buy   0.06193087824114907\n",
      "s2f_impact_sell   -0.24493331429118526\n",
      "trading_volumes   -1.9003248670972688\n",
      "price_volatilities   0.1391039208924675\n",
      "vwaps_order_sizes_buy   -0.9606062216497102\n",
      "vwaps_order_sizes_sell   0.048758572585242854\n",
      "s2f_order_sizes_buy   -1.4351457113960517\n",
      "s2f_order_sizes_sell   -0.8345324493431753\n",
      "next_trade_time   -0.9604603126433917\n",
      "next_trade_size   0.02989737421459792\n",
      "next_trade_price   0.3670806711740042\n",
      "Number of positive class in training dataset = 873\n",
      "Number of negative class in training dataset = 522\n",
      "Number of positive class in testing dataset = 112\n",
      "Number of negative class in testing dataset = 43\n",
      "Percent of correct classification:\n",
      "0.7741935483870968\n",
      "Confusion matrix:\n",
      "[[109   3]\n",
      " [ 32  11]]\n",
      "Precision:\n",
      "0.9732142857142857\n",
      "Recall:\n",
      "0.7730496453900709\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.5717858493093492\n",
      "vwaps_buy   0.540225162532301\n",
      "vwaps_sell   -0.07820301562117253\n",
      "s2f_impact_buy   0.05902436077282235\n",
      "s2f_impact_sell   -0.1250122073391492\n",
      "trading_volumes   -2.188349737458451\n",
      "price_volatilities   0.8065670210269668\n",
      "vwaps_order_sizes_buy   -1.1869248849641427\n",
      "vwaps_order_sizes_sell   -0.42471762306833316\n",
      "s2f_order_sizes_buy   -1.5166031118880163\n",
      "s2f_order_sizes_sell   -0.6111240418273716\n",
      "next_trade_time   -0.5006510048037371\n",
      "next_trade_size   0.2970478255988011\n",
      "next_trade_price   0.3885895835247779\n",
      "Number of positive class in training dataset = 889\n",
      "Number of negative class in training dataset = 506\n",
      "Number of positive class in testing dataset = 96\n",
      "Number of negative class in testing dataset = 59\n",
      "Percent of correct classification:\n",
      "0.6709677419354839\n",
      "Confusion matrix:\n",
      "[[84 12]\n",
      " [39 20]]\n",
      "Precision:\n",
      "0.875\n",
      "Recall:\n",
      "0.6829268292682927\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.16421063056760113\n",
      "vwaps_buy   1.020024815767214\n",
      "vwaps_sell   0.05935883628022668\n",
      "s2f_impact_buy   -0.13387854676665564\n",
      "s2f_impact_sell   -0.29087101437943824\n",
      "trading_volumes   -2.219476503353756\n",
      "price_volatilities   -0.10838880073495284\n",
      "vwaps_order_sizes_buy   -1.1903374250500156\n",
      "vwaps_order_sizes_sell   -0.691237267435012\n",
      "s2f_order_sizes_buy   -2.752659578954376\n",
      "s2f_order_sizes_sell   0.5706523691914179\n",
      "next_trade_time   -1.2379007601823184\n",
      "next_trade_size   0.17869219274388912\n",
      "next_trade_price   0.8787323953806754\n",
      "Number of positive class in training dataset = 913\n",
      "Number of negative class in training dataset = 482\n",
      "Number of positive class in testing dataset = 72\n",
      "Number of negative class in testing dataset = 83\n",
      "Percent of correct classification:\n",
      "0.45806451612903226\n",
      "Confusion matrix:\n",
      "[[61 11]\n",
      " [73 10]]\n",
      "Precision:\n",
      "0.8472222222222222\n",
      "Recall:\n",
      "0.4552238805970149\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.5029643797740746\n",
      "vwaps_buy   1.0263188879393605\n",
      "vwaps_sell   0.3345068941246464\n",
      "s2f_impact_buy   0.32042231873836613\n",
      "s2f_impact_sell   0.1802395609265\n",
      "trading_volumes   -2.350885435465213\n",
      "price_volatilities   0.4089146737220896\n",
      "vwaps_order_sizes_buy   -1.1446217331240953\n",
      "vwaps_order_sizes_sell   -0.8230126732814947\n",
      "s2f_order_sizes_buy   -2.41639573084695\n",
      "s2f_order_sizes_sell   -0.3539044913257091\n",
      "next_trade_time   -0.7947591400409956\n",
      "next_trade_size   0.10930026186041751\n",
      "next_trade_price   0.5468756664149721\n",
      "Number of positive class in training dataset = 879\n",
      "Number of negative class in training dataset = 516\n",
      "Number of positive class in testing dataset = 106\n",
      "Number of negative class in testing dataset = 49\n",
      "Percent of correct classification:\n",
      "0.6774193548387096\n",
      "Confusion matrix:\n",
      "[[96 10]\n",
      " [40  9]]\n",
      "Precision:\n",
      "0.9056603773584906\n",
      "Recall:\n",
      "0.7058823529411765\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.5319632731062979\n",
      "vwaps_buy   0.49377385104170396\n",
      "vwaps_sell   0.11969991564404243\n",
      "s2f_impact_buy   0.05697247953167816\n",
      "s2f_impact_sell   -0.0542980046404043\n",
      "trading_volumes   -2.097916964387062\n",
      "price_volatilities   0.5248569927100607\n",
      "vwaps_order_sizes_buy   -1.1994381644603722\n",
      "vwaps_order_sizes_sell   -0.23504457500766518\n",
      "s2f_order_sizes_buy   -1.130906816080008\n",
      "s2f_order_sizes_sell   -0.21432727475286759\n",
      "next_trade_time   -1.2855761140370086\n",
      "next_trade_size   -0.09820303330676487\n",
      "next_trade_price   0.7315898972755572\n",
      "Number of positive class in training dataset = 900\n",
      "Number of negative class in training dataset = 495\n",
      "Number of positive class in testing dataset = 85\n",
      "Number of negative class in testing dataset = 70\n",
      "Percent of correct classification:\n",
      "0.5806451612903226\n",
      "Confusion matrix:\n",
      "[[77  8]\n",
      " [57 13]]\n",
      "Precision:\n",
      "0.9058823529411765\n",
      "Recall:\n",
      "0.5746268656716418\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.7295289813530592\n",
      "vwaps_buy   0.7391008977342113\n",
      "vwaps_sell   -0.28119066693722655\n",
      "s2f_impact_buy   0.13326368014480808\n",
      "s2f_impact_sell   0.3688605036159809\n",
      "trading_volumes   -2.383806136345091\n",
      "price_volatilities   0.17851693817874834\n",
      "vwaps_order_sizes_buy   -1.013928751569554\n",
      "vwaps_order_sizes_sell   -0.9623778310147371\n",
      "s2f_order_sizes_buy   -1.9016650075768424\n",
      "s2f_order_sizes_sell   -0.09911773841964795\n",
      "next_trade_time   -0.9601839305133931\n",
      "next_trade_size   0.15284861537799072\n",
      "next_trade_price   0.83048844749386\n",
      "Number of positive class in training dataset = 858\n",
      "Number of negative class in training dataset = 537\n",
      "Number of positive class in testing dataset = 127\n",
      "Number of negative class in testing dataset = 28\n",
      "Percent of correct classification:\n",
      "0.632258064516129\n",
      "Confusion matrix:\n",
      "[[87 40]\n",
      " [17 11]]\n",
      "Precision:\n",
      "0.6850393700787402\n",
      "Recall:\n",
      "0.8365384615384616\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.6872264829583173\n",
      "vwaps_buy   0.8740485878362521\n",
      "vwaps_sell   0.2825410673839717\n",
      "s2f_impact_buy   0.11420782380039039\n",
      "s2f_impact_sell   0.10384423706070176\n",
      "trading_volumes   -2.5369561427526097\n",
      "price_volatilities   0.2837750483571792\n",
      "vwaps_order_sizes_buy   -0.9922022395732888\n",
      "vwaps_order_sizes_sell   -1.5006219736802504\n",
      "s2f_order_sizes_buy   -1.8419611015529724\n",
      "s2f_order_sizes_sell   -0.04694911252500905\n",
      "next_trade_time   -0.9534341370875081\n",
      "next_trade_size   0.6625569246817817\n",
      "next_trade_price   0.2132107536637276\n",
      "Number of positive class in training dataset = 881\n",
      "Number of negative class in training dataset = 514\n",
      "Number of positive class in testing dataset = 104\n",
      "Number of negative class in testing dataset = 51\n",
      "Percent of correct classification:\n",
      "0.6516129032258065\n",
      "Confusion matrix:\n",
      "[[101   3]\n",
      " [ 51   0]]\n",
      "Precision:\n",
      "0.9711538461538461\n",
      "Recall:\n",
      "0.6644736842105263\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.32467894712056666\n",
      "vwaps_buy   0.7999524099446084\n",
      "vwaps_sell   0.3207790636078038\n",
      "s2f_impact_buy   0.15455069831657728\n",
      "s2f_impact_sell   0.27069516633154717\n",
      "trading_volumes   -2.3037692472574283\n",
      "price_volatilities   0.7499669847689494\n",
      "vwaps_order_sizes_buy   -1.1066063038613068\n",
      "vwaps_order_sizes_sell   -0.8457999927217198\n",
      "s2f_order_sizes_buy   -1.9119758416536607\n",
      "s2f_order_sizes_sell   -0.2999530987853525\n",
      "next_trade_time   -0.006425093266373158\n",
      "next_trade_size   -0.04498605950124914\n",
      "next_trade_price   0.528564038906815\n",
      "Number of positive class in training dataset = 890\n",
      "Number of negative class in training dataset = 505\n",
      "Number of positive class in testing dataset = 95\n",
      "Number of negative class in testing dataset = 60\n",
      "Percent of correct classification:\n",
      "0.6193548387096774\n",
      "Confusion matrix:\n",
      "[[94  1]\n",
      " [58  2]]\n",
      "Precision:\n",
      "0.9894736842105263\n",
      "Recall:\n",
      "0.618421052631579\n"
     ]
    }
   ],
   "source": [
    "interval=3\n",
    "time_to_skip=30\n",
    "time_back=5\n",
    "y_name='true_price'\n",
    "swing_interval = 60\n",
    "check = 'swing_min'\n",
    "use_scaling = True\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.001\n",
    "sum_of_acc = 0.0\n",
    "sum_of_prec = 0.0\n",
    "sum_of_recall = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, 'log_reg',use_scaling = use_scaling)\n",
    "    sum_of_acc+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: 0.569325513196481\n",
      "Average precision with scaling: 0.7845839444702495\n",
      "Average recall with scaling: 0.5990654364230847\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy with scaling:\",sum_of_acc/99)\n",
    "print(\"Average precision with scaling:\",sum_of_prec/99)\n",
    "print(\"Average recall with scaling:\",sum_of_recall/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max z kolejnej godziny patrząc na ostatnie 5 min grupując dane co 5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.4672878697448701\n",
      "vwaps_buy   0.8966301296092031\n",
      "vwaps_sell   0.7053781609837589\n",
      "s2f_impact_buy   -0.158235567427125\n",
      "s2f_impact_sell   1.3374698603103297\n",
      "trading_volumes   -0.29422272791005477\n",
      "price_volatilities   0.040952749755408246\n",
      "vwaps_order_sizes_buy   0.923149286470149\n",
      "vwaps_order_sizes_sell   -0.05295102281068556\n",
      "s2f_order_sizes_buy   0.907305276776831\n",
      "s2f_order_sizes_sell   0.1969168470154856\n",
      "next_trade_time   1.4344429623588995\n",
      "next_trade_size   -0.6593222411534223\n",
      "next_trade_price   0.37232872029311936\n",
      "Number of positive class in training dataset = 460\n",
      "Number of negative class in training dataset = 359\n",
      "Number of positive class in testing dataset = 53\n",
      "Number of negative class in testing dataset = 38\n",
      "Percent of correct classification:\n",
      "0.5384615384615384\n",
      "Confusion matrix:\n",
      "[[28 25]\n",
      " [17 21]]\n",
      "Precision:\n",
      "0.5283018867924528\n",
      "Recall:\n",
      "0.6222222222222222\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.4947985007410576\n",
      "vwaps_buy   1.1256531968322254\n",
      "vwaps_sell   0.769504619073933\n",
      "s2f_impact_buy   0.386203164184912\n",
      "s2f_impact_sell   1.1673092378257406\n",
      "trading_volumes   -0.2405375639336202\n",
      "price_volatilities   -0.3639813623633309\n",
      "vwaps_order_sizes_buy   0.9042640824310508\n",
      "vwaps_order_sizes_sell   0.01650842726487589\n",
      "s2f_order_sizes_buy   0.48527993520505297\n",
      "s2f_order_sizes_sell   0.21401876915614446\n",
      "next_trade_time   0.9445453907778382\n",
      "next_trade_size   -1.0371849787530134\n",
      "next_trade_price   0.18315633128139977\n",
      "Number of positive class in training dataset = 460\n",
      "Number of negative class in training dataset = 359\n",
      "Number of positive class in testing dataset = 53\n",
      "Number of negative class in testing dataset = 38\n",
      "Percent of correct classification:\n",
      "0.42857142857142855\n",
      "Confusion matrix:\n",
      "[[37 16]\n",
      " [36  2]]\n",
      "Precision:\n",
      "0.6981132075471698\n",
      "Recall:\n",
      "0.5068493150684932\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.46558361916736823\n",
      "vwaps_buy   0.6528621650285218\n",
      "vwaps_sell   0.6839119971304214\n",
      "s2f_impact_buy   -0.37808798164322355\n",
      "s2f_impact_sell   1.123717630894576\n",
      "trading_volumes   -0.8157596477711235\n",
      "price_volatilities   -0.531550389550544\n",
      "vwaps_order_sizes_buy   1.0015226920441858\n",
      "vwaps_order_sizes_sell   -1.5347379304543305\n",
      "s2f_order_sizes_buy   0.4377677861683655\n",
      "s2f_order_sizes_sell   1.4941115388761146\n",
      "next_trade_time   0.7576890971419086\n",
      "next_trade_size   -0.638310791466634\n",
      "next_trade_price   0.49772734314313666\n",
      "Number of positive class in training dataset = 465\n",
      "Number of negative class in training dataset = 354\n",
      "Number of positive class in testing dataset = 48\n",
      "Number of negative class in testing dataset = 43\n",
      "Percent of correct classification:\n",
      "0.3956043956043956\n",
      "Confusion matrix:\n",
      "[[35 13]\n",
      " [42  1]]\n",
      "Precision:\n",
      "0.7291666666666666\n",
      "Recall:\n",
      "0.45454545454545453\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.30257019420068293\n",
      "vwaps_buy   0.583283220746526\n",
      "vwaps_sell   0.4543113328754432\n",
      "s2f_impact_buy   0.0908119311545404\n",
      "s2f_impact_sell   1.1711512177852699\n",
      "trading_volumes   -0.09749428390770368\n",
      "price_volatilities   -0.1909370714427978\n",
      "vwaps_order_sizes_buy   1.0184008197970185\n",
      "vwaps_order_sizes_sell   0.42986901541500583\n",
      "s2f_order_sizes_buy   1.0191784086159459\n",
      "s2f_order_sizes_sell   0.22593675701816368\n",
      "next_trade_time   1.3002117731595466\n",
      "next_trade_size   -0.8296016573446342\n",
      "next_trade_price   0.3491214341346916\n",
      "Number of positive class in training dataset = 471\n",
      "Number of negative class in training dataset = 348\n",
      "Number of positive class in testing dataset = 42\n",
      "Number of negative class in testing dataset = 49\n",
      "Percent of correct classification:\n",
      "0.4065934065934066\n",
      "Confusion matrix:\n",
      "[[32 10]\n",
      " [44  5]]\n",
      "Precision:\n",
      "0.7619047619047619\n",
      "Recall:\n",
      "0.42105263157894735\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.7970748651946976\n",
      "vwaps_buy   0.3352975483303674\n",
      "vwaps_sell   0.6444427746003855\n",
      "s2f_impact_buy   0.08668750116911966\n",
      "s2f_impact_sell   0.7158736523594359\n",
      "trading_volumes   -0.24096740648572007\n",
      "price_volatilities   -0.18351445096726138\n",
      "vwaps_order_sizes_buy   1.2034066684711044\n",
      "vwaps_order_sizes_sell   -0.3509801668240079\n",
      "s2f_order_sizes_buy   0.8765278668292847\n",
      "s2f_order_sizes_sell   -0.2133727487517958\n",
      "next_trade_time   1.1208347794578128\n",
      "next_trade_size   -0.9728013942053323\n",
      "next_trade_price   -0.034113529658518535\n",
      "Number of positive class in training dataset = 448\n",
      "Number of negative class in training dataset = 371\n",
      "Number of positive class in testing dataset = 65\n",
      "Number of negative class in testing dataset = 26\n",
      "Percent of correct classification:\n",
      "0.4725274725274725\n",
      "Confusion matrix:\n",
      "[[42 23]\n",
      " [25  1]]\n",
      "Precision:\n",
      "0.6461538461538462\n",
      "Recall:\n",
      "0.6268656716417911\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.5368768121859726\n",
      "vwaps_buy   0.9396338855208775\n",
      "vwaps_sell   0.920323055241379\n",
      "s2f_impact_buy   0.0032509659127165098\n",
      "s2f_impact_sell   1.0513064366554876\n",
      "trading_volumes   -0.3506178396867817\n",
      "price_volatilities   -0.15916615261274014\n",
      "vwaps_order_sizes_buy   0.9597609429191241\n",
      "vwaps_order_sizes_sell   0.16354249817620622\n",
      "s2f_order_sizes_buy   0.8544665045374593\n",
      "s2f_order_sizes_sell   0.17729453392405758\n",
      "next_trade_time   1.3026337204262672\n",
      "next_trade_size   -0.6417329088010542\n",
      "next_trade_price   0.3821778635558541\n",
      "Number of positive class in training dataset = 459\n",
      "Number of negative class in training dataset = 360\n",
      "Number of positive class in testing dataset = 54\n",
      "Number of negative class in testing dataset = 37\n",
      "Percent of correct classification:\n",
      "0.5494505494505495\n",
      "Confusion matrix:\n",
      "[[36 18]\n",
      " [23 14]]\n",
      "Precision:\n",
      "0.6666666666666666\n",
      "Recall:\n",
      "0.6101694915254238\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.519235480661649\n",
      "vwaps_buy   1.2953742236478083\n",
      "vwaps_sell   0.8614071277003744\n",
      "s2f_impact_buy   0.04341575045106945\n",
      "s2f_impact_sell   1.2263978308038646\n",
      "trading_volumes   -1.233543584679087\n",
      "price_volatilities   -0.29465777003946675\n",
      "vwaps_order_sizes_buy   0.3348712505162356\n",
      "vwaps_order_sizes_sell   0.655556531613382\n",
      "s2f_order_sizes_buy   0.6262104612981244\n",
      "s2f_order_sizes_sell   0.44833378657830075\n",
      "next_trade_time   0.9988353921932227\n",
      "next_trade_size   -0.6328076180142452\n",
      "next_trade_price   0.358812629672977\n",
      "Number of positive class in training dataset = 446\n",
      "Number of negative class in training dataset = 373\n",
      "Number of positive class in testing dataset = 67\n",
      "Number of negative class in testing dataset = 24\n",
      "Percent of correct classification:\n",
      "0.4945054945054945\n",
      "Confusion matrix:\n",
      "[[33 34]\n",
      " [12 12]]\n",
      "Precision:\n",
      "0.4925373134328358\n",
      "Recall:\n",
      "0.7333333333333333\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.2668606181096136\n",
      "vwaps_buy   0.5918119625571795\n",
      "vwaps_sell   0.7689971373583909\n",
      "s2f_impact_buy   -0.24640087590866647\n",
      "s2f_impact_sell   0.8109798390224048\n",
      "trading_volumes   -0.33115962163119855\n",
      "price_volatilities   -0.557364252889253\n",
      "vwaps_order_sizes_buy   0.9447229150460084\n",
      "vwaps_order_sizes_sell   0.023996927151524596\n",
      "s2f_order_sizes_buy   0.5043511454462904\n",
      "s2f_order_sizes_sell   0.22470915540644662\n",
      "next_trade_time   0.766919068566592\n",
      "next_trade_size   -0.7161435381401383\n",
      "next_trade_price   0.22518446994486285\n",
      "Number of positive class in training dataset = 487\n",
      "Number of negative class in training dataset = 332\n",
      "Number of positive class in testing dataset = 26\n",
      "Number of negative class in testing dataset = 65\n",
      "Percent of correct classification:\n",
      "0.37362637362637363\n",
      "Confusion matrix:\n",
      "[[22  4]\n",
      " [53 12]]\n",
      "Precision:\n",
      "0.8461538461538461\n",
      "Recall:\n",
      "0.29333333333333333\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.4938382245721586\n",
      "vwaps_buy   0.3624864265453416\n",
      "vwaps_sell   0.26281248084350417\n",
      "s2f_impact_buy   0.1081802202272987\n",
      "s2f_impact_sell   1.1626789826203885\n",
      "trading_volumes   -0.17617427038053007\n",
      "price_volatilities   -0.25346956780119023\n",
      "vwaps_order_sizes_buy   0.8581929195572444\n",
      "vwaps_order_sizes_sell   0.5083647439341025\n",
      "s2f_order_sizes_buy   0.5147694098691554\n",
      "s2f_order_sizes_sell   0.11468096197084193\n",
      "next_trade_time   1.321291646002792\n",
      "next_trade_size   -0.9403082681773012\n",
      "next_trade_price   0.6737977723514238\n",
      "Number of positive class in training dataset = 465\n",
      "Number of negative class in training dataset = 354\n",
      "Number of positive class in testing dataset = 48\n",
      "Number of negative class in testing dataset = 43\n",
      "Percent of correct classification:\n",
      "0.4835164835164835\n",
      "Confusion matrix:\n",
      "[[36 12]\n",
      " [35  8]]\n",
      "Precision:\n",
      "0.75\n",
      "Recall:\n",
      "0.5070422535211268\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.49626762275289044\n",
      "vwaps_buy   0.6176118681994283\n",
      "vwaps_sell   0.851642301059643\n",
      "s2f_impact_buy   -0.19067352344759378\n",
      "s2f_impact_sell   0.48076922841171454\n",
      "trading_volumes   -0.2663981449243118\n",
      "price_volatilities   -0.10248177045621612\n",
      "vwaps_order_sizes_buy   1.0214900554258122\n",
      "vwaps_order_sizes_sell   0.10103932082020475\n",
      "s2f_order_sizes_buy   1.0102371693684462\n",
      "s2f_order_sizes_sell   0.4123774625814806\n",
      "next_trade_time   1.6851367852115853\n",
      "next_trade_size   -1.3264912736556267\n",
      "next_trade_price   0.315854658104933\n",
      "Number of positive class in training dataset = 456\n",
      "Number of negative class in training dataset = 363\n",
      "Number of positive class in testing dataset = 57\n",
      "Number of negative class in testing dataset = 34\n",
      "Percent of correct classification:\n",
      "0.45054945054945056\n",
      "Confusion matrix:\n",
      "[[36 21]\n",
      " [29  5]]\n",
      "Precision:\n",
      "0.631578947368421\n",
      "Recall:\n",
      "0.5538461538461539\n"
     ]
    }
   ],
   "source": [
    "interval=5\n",
    "time_to_skip=30\n",
    "time_back=5\n",
    "y_name='true_price'\n",
    "swing_interval = 60\n",
    "check = 'swing_max'\n",
    "use_scaling = True\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.001\n",
    "sum_of_acc = 0.0\n",
    "sum_of_prec = 0.0\n",
    "sum_of_recall = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, 'log_reg',use_scaling = use_scaling)\n",
    "    sum_of_acc+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: 0.5581529581529584\n",
      "Average precision with scaling: 0.7156920789483644\n",
      "Average recall with scaling: nan\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy with scaling:\",sum_of_acc/99)\n",
    "print(\"Average precision with scaling:\",sum_of_prec/99)\n",
    "print(\"Average recall with scaling:\",sum_of_recall/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max z kolejnej godziny patrząc na ostatnie 10 min grupując dane co 5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.7718502384641386\n",
      "vwaps_buy   0.8638054268524986\n",
      "vwaps_sell   0.7996202422782887\n",
      "s2f_impact_buy   -0.0669725088201469\n",
      "s2f_impact_sell   0.9070450489045362\n",
      "trading_volumes   0.38075843601030424\n",
      "price_volatilities   -0.33044422792033407\n",
      "vwaps_order_sizes_buy   1.2570562745495164\n",
      "vwaps_order_sizes_sell   0.39537556475833097\n",
      "s2f_order_sizes_buy   0.13611206404852094\n",
      "s2f_order_sizes_sell   -0.3153127463790334\n",
      "next_trade_time   1.6914112897099032\n",
      "next_trade_size   -0.15693919035615903\n",
      "next_trade_price   0.22557055422986202\n",
      "Number of positive class in training dataset = 435\n",
      "Number of negative class in training dataset = 339\n",
      "Number of positive class in testing dataset = 48\n",
      "Number of negative class in testing dataset = 38\n",
      "Percent of correct classification:\n",
      "0.5348837209302325\n",
      "Confusion matrix:\n",
      "[[23 25]\n",
      " [15 23]]\n",
      "Precision:\n",
      "0.4791666666666667\n",
      "Recall:\n",
      "0.6052631578947368\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.8938773690198325\n",
      "vwaps_buy   1.0530036991515273\n",
      "vwaps_sell   0.9900186913253113\n",
      "s2f_impact_buy   0.500420904626095\n",
      "s2f_impact_sell   0.6335472865111794\n",
      "trading_volumes   0.5075114806665796\n",
      "price_volatilities   -0.5031388296587748\n",
      "vwaps_order_sizes_buy   1.292826558701263\n",
      "vwaps_order_sizes_sell   0.34258346744643725\n",
      "s2f_order_sizes_buy   -0.04818721498680987\n",
      "s2f_order_sizes_sell   -0.24676372421826398\n",
      "next_trade_time   1.4790435411826537\n",
      "next_trade_size   -0.6981951686385927\n",
      "next_trade_price   0.03203894348881415\n",
      "Number of positive class in training dataset = 431\n",
      "Number of negative class in training dataset = 343\n",
      "Number of positive class in testing dataset = 52\n",
      "Number of negative class in testing dataset = 34\n",
      "Percent of correct classification:\n",
      "0.5465116279069767\n",
      "Confusion matrix:\n",
      "[[46  6]\n",
      " [33  1]]\n",
      "Precision:\n",
      "0.8846153846153846\n",
      "Recall:\n",
      "0.5822784810126582\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.7323644130767435\n",
      "vwaps_buy   0.5914003287347505\n",
      "vwaps_sell   0.6716581508072149\n",
      "s2f_impact_buy   -0.4752035034598993\n",
      "s2f_impact_sell   0.7784401806401633\n",
      "trading_volumes   -0.2790450606159276\n",
      "price_volatilities   -1.1154264662667737\n",
      "vwaps_order_sizes_buy   1.474759876933146\n",
      "vwaps_order_sizes_sell   -1.2708958305889673\n",
      "s2f_order_sizes_buy   0.09537834686704236\n",
      "s2f_order_sizes_sell   1.0970699604393637\n",
      "next_trade_time   0.8460537292560947\n",
      "next_trade_size   -0.37227629545146984\n",
      "next_trade_price   0.5085048381847279\n",
      "Number of positive class in training dataset = 438\n",
      "Number of negative class in training dataset = 336\n",
      "Number of positive class in testing dataset = 45\n",
      "Number of negative class in testing dataset = 41\n",
      "Percent of correct classification:\n",
      "0.4186046511627907\n",
      "Confusion matrix:\n",
      "[[36  9]\n",
      " [41  0]]\n",
      "Precision:\n",
      "0.8\n",
      "Recall:\n",
      "0.4675324675324675\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.7576399422796722\n",
      "vwaps_buy   0.605252510804729\n",
      "vwaps_sell   0.5806662194235509\n",
      "s2f_impact_buy   0.24421402370304113\n",
      "s2f_impact_sell   0.6556787494765236\n",
      "trading_volumes   0.6025850062214483\n",
      "price_volatilities   -0.5266720075651727\n",
      "vwaps_order_sizes_buy   1.2998157474006873\n",
      "vwaps_order_sizes_sell   0.8214858742898027\n",
      "s2f_order_sizes_buy   0.27103063588561743\n",
      "s2f_order_sizes_sell   -0.15762222009255347\n",
      "next_trade_time   1.7019718416016751\n",
      "next_trade_size   -0.3523978628956277\n",
      "next_trade_price   0.17043512778051415\n",
      "Number of positive class in training dataset = 444\n",
      "Number of negative class in training dataset = 330\n",
      "Number of positive class in testing dataset = 39\n",
      "Number of negative class in testing dataset = 47\n",
      "Percent of correct classification:\n",
      "0.45348837209302323\n",
      "Confusion matrix:\n",
      "[[26 13]\n",
      " [34 13]]\n",
      "Precision:\n",
      "0.6666666666666666\n",
      "Recall:\n",
      "0.43333333333333335\n",
      "Coefficient impact:\n",
      "order_inbalance   -1.0725159917565814\n",
      "vwaps_buy   0.14301571946597613\n",
      "vwaps_sell   0.6586094745793796\n",
      "s2f_impact_buy   0.24430154938962723\n",
      "s2f_impact_sell   0.5409355537384466\n",
      "trading_volumes   0.5453584281649481\n",
      "price_volatilities   -0.46118296552211635\n",
      "vwaps_order_sizes_buy   1.5812777187724085\n",
      "vwaps_order_sizes_sell   0.17892140099139084\n",
      "s2f_order_sizes_buy   0.3395084089751444\n",
      "s2f_order_sizes_sell   -0.9341201229286223\n",
      "next_trade_time   1.4499354858321565\n",
      "next_trade_size   -0.6832474657495015\n",
      "next_trade_price   -0.38207985496553354\n",
      "Number of positive class in training dataset = 422\n",
      "Number of negative class in training dataset = 352\n",
      "Number of positive class in testing dataset = 61\n",
      "Number of negative class in testing dataset = 25\n",
      "Percent of correct classification:\n",
      "0.37209302325581395\n",
      "Confusion matrix:\n",
      "[[18 43]\n",
      " [11 14]]\n",
      "Precision:\n",
      "0.29508196721311475\n",
      "Recall:\n",
      "0.6206896551724138\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.9564194731120297\n",
      "vwaps_buy   0.9237594743241743\n",
      "vwaps_sell   0.9728757298421041\n",
      "s2f_impact_buy   -0.055929791186300655\n",
      "s2f_impact_sell   0.5422978283503935\n",
      "trading_volumes   0.36773154993546703\n",
      "price_volatilities   -0.46559391451538323\n",
      "vwaps_order_sizes_buy   1.3051672947702189\n",
      "vwaps_order_sizes_sell   0.5209843002561363\n",
      "s2f_order_sizes_buy   0.014331210957301024\n",
      "s2f_order_sizes_sell   -0.41155239049005476\n",
      "next_trade_time   1.4719819914717127\n",
      "next_trade_size   -0.08669959192094902\n",
      "next_trade_price   0.23860498655788567\n",
      "Number of positive class in training dataset = 430\n",
      "Number of negative class in training dataset = 344\n",
      "Number of positive class in testing dataset = 53\n",
      "Number of negative class in testing dataset = 33\n",
      "Percent of correct classification:\n",
      "0.5697674418604651\n",
      "Confusion matrix:\n",
      "[[26 27]\n",
      " [10 23]]\n",
      "Precision:\n",
      "0.49056603773584906\n",
      "Recall:\n",
      "0.7222222222222222\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.7148503589651416\n",
      "vwaps_buy   1.223446121226594\n",
      "vwaps_sell   0.6768100671996734\n",
      "s2f_impact_buy   0.09165741269595688\n",
      "s2f_impact_sell   0.49643387907080394\n",
      "trading_volumes   -0.30533231831603574\n",
      "price_volatilities   -0.378984490633285\n",
      "vwaps_order_sizes_buy   0.5227281940278731\n",
      "vwaps_order_sizes_sell   0.8364573857570262\n",
      "s2f_order_sizes_buy   -0.1952948906582247\n",
      "s2f_order_sizes_sell   -0.1400032858155391\n",
      "next_trade_time   1.5719859916314982\n",
      "next_trade_size   -0.3456147452470275\n",
      "next_trade_price   0.05471231840688838\n",
      "Number of positive class in training dataset = 421\n",
      "Number of negative class in training dataset = 353\n",
      "Number of positive class in testing dataset = 62\n",
      "Number of negative class in testing dataset = 24\n",
      "Percent of correct classification:\n",
      "0.6627906976744186\n",
      "Confusion matrix:\n",
      "[[52 10]\n",
      " [19  5]]\n",
      "Precision:\n",
      "0.8387096774193549\n",
      "Recall:\n",
      "0.7323943661971831\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.5845386624615945\n",
      "vwaps_buy   0.5517412156710023\n",
      "vwaps_sell   0.9331527089154388\n",
      "s2f_impact_buy   -0.028004391396199983\n",
      "s2f_impact_sell   0.5672427913157677\n",
      "trading_volumes   0.4697531915521605\n",
      "price_volatilities   -1.1166539214963513\n",
      "vwaps_order_sizes_buy   1.3341369589593706\n",
      "vwaps_order_sizes_sell   0.44387940233288914\n",
      "s2f_order_sizes_buy   -0.26675594248583745\n",
      "s2f_order_sizes_sell   -0.3391478509458901\n",
      "next_trade_time   1.08519871976057\n",
      "next_trade_size   -0.4051250796575869\n",
      "next_trade_price   0.1930645648069322\n",
      "Number of positive class in training dataset = 460\n",
      "Number of negative class in training dataset = 314\n",
      "Number of positive class in testing dataset = 23\n",
      "Number of negative class in testing dataset = 63\n",
      "Percent of correct classification:\n",
      "0.38372093023255816\n",
      "Confusion matrix:\n",
      "[[16  7]\n",
      " [46 17]]\n",
      "Precision:\n",
      "0.6956521739130435\n",
      "Recall:\n",
      "0.25806451612903225\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.8421943629482423\n",
      "vwaps_buy   0.26638339405027056\n",
      "vwaps_sell   0.2714858202850593\n",
      "s2f_impact_buy   0.1446462437227508\n",
      "s2f_impact_sell   0.6202516062184962\n",
      "trading_volumes   0.5775447639076454\n",
      "price_volatilities   -0.5379156433287714\n",
      "vwaps_order_sizes_buy   1.1415508800947727\n",
      "vwaps_order_sizes_sell   0.9999194848662986\n",
      "s2f_order_sizes_buy   -0.2454937725221633\n",
      "s2f_order_sizes_sell   -0.3095253340255375\n",
      "next_trade_time   1.7668785192309149\n",
      "next_trade_size   0.06227680128948721\n",
      "next_trade_price   0.7126075274795218\n",
      "Number of positive class in training dataset = 435\n",
      "Number of negative class in training dataset = 339\n",
      "Number of positive class in testing dataset = 48\n",
      "Number of negative class in testing dataset = 38\n",
      "Percent of correct classification:\n",
      "0.36046511627906974\n",
      "Confusion matrix:\n",
      "[[29 19]\n",
      " [36  2]]\n",
      "Precision:\n",
      "0.6041666666666666\n",
      "Recall:\n",
      "0.4461538461538462\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.8340262046778645\n",
      "vwaps_buy   0.7031868140665345\n",
      "vwaps_sell   0.8527918360070121\n",
      "s2f_impact_buy   -0.3357666300996714\n",
      "s2f_impact_sell   0.5835122180973501\n",
      "trading_volumes   0.5476400625935612\n",
      "price_volatilities   -0.28326208288373056\n",
      "vwaps_order_sizes_buy   1.4449100934778383\n",
      "vwaps_order_sizes_sell   0.47894162773945287\n",
      "s2f_order_sizes_buy   0.4867854052978654\n",
      "s2f_order_sizes_sell   -0.3001894798122163\n",
      "next_trade_time   2.470567941627785\n",
      "next_trade_size   -0.9124053268552604\n",
      "next_trade_price   0.2841551858623159\n",
      "Number of positive class in training dataset = 431\n",
      "Number of negative class in training dataset = 343\n",
      "Number of positive class in testing dataset = 52\n",
      "Number of negative class in testing dataset = 34\n",
      "Percent of correct classification:\n",
      "0.32558139534883723\n",
      "Confusion matrix:\n",
      "[[19 33]\n",
      " [25  9]]\n",
      "Precision:\n",
      "0.36538461538461536\n",
      "Recall:\n",
      "0.4318181818181818\n"
     ]
    }
   ],
   "source": [
    "interval=5\n",
    "time_to_skip=30\n",
    "time_back=10\n",
    "y_name='true_price'\n",
    "swing_interval = 60\n",
    "check = 'swing_max'\n",
    "use_scaling = True\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.001\n",
    "sum_of_acc = 0.0\n",
    "sum_of_prec = 0.0\n",
    "sum_of_recall = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, 'log_reg',use_scaling = use_scaling)\n",
    "    sum_of_acc+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: 0.5735259572468874\n",
      "Average precision with scaling: 0.7610993561275949\n",
      "Average recall with scaling: nan\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy with scaling:\",sum_of_acc/99)\n",
    "print(\"Average precision with scaling:\",sum_of_prec/99)\n",
    "print(\"Average recall with scaling:\",sum_of_recall/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min z kolejnej godziny patrząc na ostatnie 5 min grupując dane co 5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.3863637129185308\n",
      "vwaps_buy   -0.3953920051559109\n",
      "vwaps_sell   -0.8815557654575911\n",
      "s2f_impact_buy   -0.09646282170842913\n",
      "s2f_impact_sell   -0.23508125015239809\n",
      "trading_volumes   -2.4579549776919176\n",
      "price_volatilities   -0.003568633751534547\n",
      "vwaps_order_sizes_buy   -0.9535787013953453\n",
      "vwaps_order_sizes_sell   -1.115020135585456\n",
      "s2f_order_sizes_buy   -1.0950071139451147\n",
      "s2f_order_sizes_sell   0.1278159834841371\n",
      "next_trade_time   -0.05536919477450856\n",
      "next_trade_size   0.41335132608550146\n",
      "next_trade_price   0.23133282524481516\n",
      "Number of positive class in training dataset = 487\n",
      "Number of negative class in training dataset = 332\n",
      "Number of positive class in testing dataset = 47\n",
      "Number of negative class in testing dataset = 44\n",
      "Percent of correct classification:\n",
      "0.5164835164835165\n",
      "Confusion matrix:\n",
      "[[46  1]\n",
      " [43  1]]\n",
      "Precision:\n",
      "0.9787234042553191\n",
      "Recall:\n",
      "0.5168539325842697\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.5588476700860253\n",
      "vwaps_buy   -0.14477900510871156\n",
      "vwaps_sell   -0.7812988536773927\n",
      "s2f_impact_buy   -0.33345033091987153\n",
      "s2f_impact_sell   -0.2507295825668049\n",
      "trading_volumes   -2.395504293645616\n",
      "price_volatilities   0.377581051209446\n",
      "vwaps_order_sizes_buy   -0.9734436165653236\n",
      "vwaps_order_sizes_sell   -1.1701468034730513\n",
      "s2f_order_sizes_buy   -0.8414246069725706\n",
      "s2f_order_sizes_sell   0.25404317805689464\n",
      "next_trade_time   0.6130879733495697\n",
      "next_trade_size   0.5310161893553474\n",
      "next_trade_price   0.26517346687088733\n",
      "Number of positive class in training dataset = 480\n",
      "Number of negative class in training dataset = 339\n",
      "Number of positive class in testing dataset = 54\n",
      "Number of negative class in testing dataset = 37\n",
      "Percent of correct classification:\n",
      "0.5934065934065934\n",
      "Confusion matrix:\n",
      "[[52  2]\n",
      " [35  2]]\n",
      "Precision:\n",
      "0.9629629629629629\n",
      "Recall:\n",
      "0.5977011494252874\n",
      "Coefficient impact:\n",
      "order_inbalance   0.07067390122578028\n",
      "vwaps_buy   -0.007144348105090545\n",
      "vwaps_sell   -0.7625331925284302\n",
      "s2f_impact_buy   0.30959877829381566\n",
      "s2f_impact_sell   -0.012703722797622528\n",
      "trading_volumes   -2.280050304774397\n",
      "price_volatilities   0.4979079921646826\n",
      "vwaps_order_sizes_buy   -0.9515943590372804\n",
      "vwaps_order_sizes_sell   -0.7556027499252566\n",
      "s2f_order_sizes_buy   -1.4961670537080511\n",
      "s2f_order_sizes_sell   -0.3908409381143154\n",
      "next_trade_time   0.48234314475886797\n",
      "next_trade_size   0.8741270390552233\n",
      "next_trade_price   0.07765289635136699\n",
      "Number of positive class in training dataset = 473\n",
      "Number of negative class in training dataset = 346\n",
      "Number of positive class in testing dataset = 61\n",
      "Number of negative class in testing dataset = 30\n",
      "Percent of correct classification:\n",
      "0.5494505494505495\n",
      "Confusion matrix:\n",
      "[[28 33]\n",
      " [ 8 22]]\n",
      "Precision:\n",
      "0.45901639344262296\n",
      "Recall:\n",
      "0.7777777777777778\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.5030558790338879\n",
      "vwaps_buy   -0.10188752004198642\n",
      "vwaps_sell   -1.3269384052843627\n",
      "s2f_impact_buy   -0.09295733376752598\n",
      "s2f_impact_sell   0.4061476314503796\n",
      "trading_volumes   -2.3356498954153215\n",
      "price_volatilities   0.21535760402177276\n",
      "vwaps_order_sizes_buy   -0.8590538438763069\n",
      "vwaps_order_sizes_sell   -0.8299440937303043\n",
      "s2f_order_sizes_buy   -0.6452875844863888\n",
      "s2f_order_sizes_sell   -0.1405047683635571\n",
      "next_trade_time   -0.02160041495404361\n",
      "next_trade_size   0.6830909716143884\n",
      "next_trade_price   0.308972740199551\n",
      "Number of positive class in training dataset = 479\n",
      "Number of negative class in training dataset = 340\n",
      "Number of positive class in testing dataset = 55\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "0.46153846153846156\n",
      "Confusion matrix:\n",
      "[[14 41]\n",
      " [ 8 28]]\n",
      "Precision:\n",
      "0.2545454545454545\n",
      "Recall:\n",
      "0.6363636363636364\n",
      "Coefficient impact:\n",
      "order_inbalance   0.018320619437839192\n",
      "vwaps_buy   0.18619175455951503\n",
      "vwaps_sell   -0.8969653031383522\n",
      "s2f_impact_buy   -0.2231872847658192\n",
      "s2f_impact_sell   0.16658778364474588\n",
      "trading_volumes   -2.644268065020816\n",
      "price_volatilities   0.10438554512768183\n",
      "vwaps_order_sizes_buy   -1.2032032310121283\n",
      "vwaps_order_sizes_sell   -0.7531648406578008\n",
      "s2f_order_sizes_buy   -1.0985802439340717\n",
      "s2f_order_sizes_sell   0.5398167540113231\n",
      "next_trade_time   0.16346511103803005\n",
      "next_trade_size   0.7332155878785116\n",
      "next_trade_price   0.4193347849442316\n",
      "Number of positive class in training dataset = 498\n",
      "Number of negative class in training dataset = 321\n",
      "Number of positive class in testing dataset = 36\n",
      "Number of negative class in testing dataset = 55\n",
      "Percent of correct classification:\n",
      "0.5274725274725275\n",
      "Confusion matrix:\n",
      "[[34  2]\n",
      " [41 14]]\n",
      "Precision:\n",
      "0.9444444444444444\n",
      "Recall:\n",
      "0.4533333333333333\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.17478198234498082\n",
      "vwaps_buy   -0.09109907692150897\n",
      "vwaps_sell   -0.8060960323296024\n",
      "s2f_impact_buy   -0.026738739422413168\n",
      "s2f_impact_sell   -0.05765467987387493\n",
      "trading_volumes   -2.5315404358370404\n",
      "price_volatilities   0.2323914266202111\n",
      "vwaps_order_sizes_buy   -0.9311666307854879\n",
      "vwaps_order_sizes_sell   -1.0547240822087685\n",
      "s2f_order_sizes_buy   -1.18900462657015\n",
      "s2f_order_sizes_sell   0.25472288076769173\n",
      "next_trade_time   0.045537477222376374\n",
      "next_trade_size   0.4971602175574128\n",
      "next_trade_price   0.14494123664680034\n",
      "Number of positive class in training dataset = 475\n",
      "Number of negative class in training dataset = 344\n",
      "Number of positive class in testing dataset = 59\n",
      "Number of negative class in testing dataset = 32\n",
      "Percent of correct classification:\n",
      "0.6593406593406593\n",
      "Confusion matrix:\n",
      "[[55  4]\n",
      " [27  5]]\n",
      "Precision:\n",
      "0.9322033898305084\n",
      "Recall:\n",
      "0.6707317073170732\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.39241113870011357\n",
      "vwaps_buy   -0.25583888657077625\n",
      "vwaps_sell   -0.7355014175698469\n",
      "s2f_impact_buy   -0.12662727907195953\n",
      "s2f_impact_sell   -0.07053922337605978\n",
      "trading_volumes   -2.4843418322361015\n",
      "price_volatilities   0.16164003711917388\n",
      "vwaps_order_sizes_buy   -0.12860527348430548\n",
      "vwaps_order_sizes_sell   -0.40228509661421163\n",
      "s2f_order_sizes_buy   -0.08868879251969417\n",
      "s2f_order_sizes_sell   0.31018846874246375\n",
      "next_trade_time   -0.1147731224921946\n",
      "next_trade_size   0.5216572866123798\n",
      "next_trade_price   0.2954318576217433\n",
      "Number of positive class in training dataset = 491\n",
      "Number of negative class in training dataset = 328\n",
      "Number of positive class in testing dataset = 43\n",
      "Number of negative class in testing dataset = 48\n",
      "Percent of correct classification:\n",
      "0.5604395604395604\n",
      "Confusion matrix:\n",
      "[[41  2]\n",
      " [38 10]]\n",
      "Precision:\n",
      "0.9534883720930233\n",
      "Recall:\n",
      "0.5189873417721519\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.5116807842874159\n",
      "vwaps_buy   0.3139274146914635\n",
      "vwaps_sell   -0.3430273482731112\n",
      "s2f_impact_buy   0.039651556251073694\n",
      "s2f_impact_sell   0.10145431116008982\n",
      "trading_volumes   -2.38248721630661\n",
      "price_volatilities   0.20441188146060324\n",
      "vwaps_order_sizes_buy   -0.9612611885686909\n",
      "vwaps_order_sizes_sell   -0.8099860821688141\n",
      "s2f_order_sizes_buy   -0.7289784221809787\n",
      "s2f_order_sizes_sell   0.027280081472453067\n",
      "next_trade_time   0.34405655673759433\n",
      "next_trade_size   0.6316176178341727\n",
      "next_trade_price   0.12887009293328655\n",
      "Number of positive class in training dataset = 464\n",
      "Number of negative class in training dataset = 355\n",
      "Number of positive class in testing dataset = 70\n",
      "Number of negative class in testing dataset = 21\n",
      "Percent of correct classification:\n",
      "0.8021978021978022\n",
      "Confusion matrix:\n",
      "[[67  3]\n",
      " [15  6]]\n",
      "Precision:\n",
      "0.9571428571428572\n",
      "Recall:\n",
      "0.8170731707317073\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.39085971460642127\n",
      "vwaps_buy   0.3959580555624758\n",
      "vwaps_sell   -0.4360143142582746\n",
      "s2f_impact_buy   -0.33523431224794437\n",
      "s2f_impact_sell   0.08209212611153045\n",
      "trading_volumes   -2.658928230777119\n",
      "price_volatilities   0.3282449296654079\n",
      "vwaps_order_sizes_buy   -0.7731795377012431\n",
      "vwaps_order_sizes_sell   -1.6102937233782832\n",
      "s2f_order_sizes_buy   -0.6572186998496677\n",
      "s2f_order_sizes_sell   0.45423268484170176\n",
      "next_trade_time   0.37275612407019026\n",
      "next_trade_size   0.649808318231169\n",
      "next_trade_price   0.0066242611117599895\n",
      "Number of positive class in training dataset = 474\n",
      "Number of negative class in training dataset = 345\n",
      "Number of positive class in testing dataset = 60\n",
      "Number of negative class in testing dataset = 31\n",
      "Percent of correct classification:\n",
      "0.6153846153846154\n",
      "Confusion matrix:\n",
      "[[55  5]\n",
      " [30  1]]\n",
      "Precision:\n",
      "0.9166666666666666\n",
      "Recall:\n",
      "0.6470588235294118\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.054914104854477626\n",
      "vwaps_buy   -0.01628479255872235\n",
      "vwaps_sell   -0.8697463627940135\n",
      "s2f_impact_buy   -0.14563200375553453\n",
      "s2f_impact_sell   0.18983967324235806\n",
      "trading_volumes   -2.456533427010282\n",
      "price_volatilities   0.061249301476516076\n",
      "vwaps_order_sizes_buy   -1.0031830047309753\n",
      "vwaps_order_sizes_sell   -0.7433371932608569\n",
      "s2f_order_sizes_buy   -1.0779133294033378\n",
      "s2f_order_sizes_sell   0.1114020318070011\n",
      "next_trade_time   0.017288718658363875\n",
      "next_trade_size   0.8913976356783802\n",
      "next_trade_price   0.17664861251349798\n",
      "Number of positive class in training dataset = 485\n",
      "Number of negative class in training dataset = 334\n",
      "Number of positive class in testing dataset = 49\n",
      "Number of negative class in testing dataset = 42\n",
      "Percent of correct classification:\n",
      "0.5384615384615384\n",
      "Confusion matrix:\n",
      "[[49  0]\n",
      " [42  0]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.5384615384615384\n"
     ]
    }
   ],
   "source": [
    "interval=5\n",
    "time_to_skip=30\n",
    "time_back=5\n",
    "y_name='true_price'\n",
    "swing_interval = 60\n",
    "check = 'swing_min'\n",
    "use_scaling = True\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.001\n",
    "sum_of_acc = 0.0\n",
    "sum_of_prec = 0.0\n",
    "sum_of_recall = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, 'log_reg',use_scaling = use_scaling)\n",
    "    sum_of_acc+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: 0.5399267399267399\n",
      "Average precision with scaling: 0.6712206892217817\n",
      "Average recall with scaling: nan\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy with scaling:\",sum_of_acc/99)\n",
    "print(\"Average precision with scaling:\",sum_of_prec/99)\n",
    "print(\"Average recall with scaling:\",sum_of_recall/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min z kolejnej godziny patrząc na ostatnie 10 min grupując dane co 5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.119960958511734\n",
      "vwaps_buy   -0.051257706239803594\n",
      "vwaps_sell   -0.8255542956573823\n",
      "s2f_impact_buy   -0.30514933438140374\n",
      "s2f_impact_sell   0.25520374527736706\n",
      "trading_volumes   -2.2381125193312963\n",
      "price_volatilities   -0.05414456978059676\n",
      "vwaps_order_sizes_buy   -0.4358681052214441\n",
      "vwaps_order_sizes_sell   -1.4116762899391597\n",
      "s2f_order_sizes_buy   -0.816207508838169\n",
      "s2f_order_sizes_sell   0.1870966574572602\n",
      "next_trade_time   -0.7262775320546416\n",
      "next_trade_size   0.48859660993298265\n",
      "next_trade_price   0.3605843190398258\n",
      "Number of positive class in training dataset = 452\n",
      "Number of negative class in training dataset = 322\n",
      "Number of positive class in testing dataset = 47\n",
      "Number of negative class in testing dataset = 39\n",
      "Percent of correct classification:\n",
      "0.5465116279069767\n",
      "Confusion matrix:\n",
      "[[47  0]\n",
      " [39  0]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.5465116279069767\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.2641870788309541\n",
      "vwaps_buy   0.27374857968999317\n",
      "vwaps_sell   -0.7638539121078951\n",
      "s2f_impact_buy   -0.6586834422292533\n",
      "s2f_impact_sell   0.36311740324068664\n",
      "trading_volumes   -2.279156327914834\n",
      "price_volatilities   0.2778078973608307\n",
      "vwaps_order_sizes_buy   -0.500734350056425\n",
      "vwaps_order_sizes_sell   -1.5405107156538078\n",
      "s2f_order_sizes_buy   -0.7588752531126575\n",
      "s2f_order_sizes_sell   0.23187730189330888\n",
      "next_trade_time   -0.10815755568474042\n",
      "next_trade_size   0.9963770516128622\n",
      "next_trade_price   0.4443647639581904\n",
      "Number of positive class in training dataset = 450\n",
      "Number of negative class in training dataset = 324\n",
      "Number of positive class in testing dataset = 49\n",
      "Number of negative class in testing dataset = 37\n",
      "Percent of correct classification:\n",
      "0.5581395348837209\n",
      "Confusion matrix:\n",
      "[[48  1]\n",
      " [37  0]]\n",
      "Precision:\n",
      "0.9795918367346939\n",
      "Recall:\n",
      "0.5647058823529412\n",
      "Coefficient impact:\n",
      "order_inbalance   0.4091683545231048\n",
      "vwaps_buy   0.24466586701191206\n",
      "vwaps_sell   -0.6120722039269348\n",
      "s2f_impact_buy   0.13528714474244186\n",
      "s2f_impact_sell   0.24770224937187896\n",
      "trading_volumes   -2.0435131663668322\n",
      "price_volatilities   0.581225868674876\n",
      "vwaps_order_sizes_buy   -0.5731862191086792\n",
      "vwaps_order_sizes_sell   -0.9472052007865199\n",
      "s2f_order_sizes_buy   -1.5020634705863427\n",
      "s2f_order_sizes_sell   -0.6134464867153897\n",
      "next_trade_time   -0.13516801847367282\n",
      "next_trade_size   1.1636351761138324\n",
      "next_trade_price   0.24970044489125232\n",
      "Number of positive class in training dataset = 443\n",
      "Number of negative class in training dataset = 331\n",
      "Number of positive class in testing dataset = 56\n",
      "Number of negative class in testing dataset = 30\n",
      "Percent of correct classification:\n",
      "0.5232558139534884\n",
      "Confusion matrix:\n",
      "[[21 35]\n",
      " [ 6 24]]\n",
      "Precision:\n",
      "0.375\n",
      "Recall:\n",
      "0.7777777777777778\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.17687450687422834\n",
      "vwaps_buy   0.19011914211515504\n",
      "vwaps_sell   -1.2379990671266248\n",
      "s2f_impact_buy   -0.4228593342576544\n",
      "s2f_impact_sell   0.6681813407992572\n",
      "trading_volumes   -2.1441618834151805\n",
      "price_volatilities   0.013927202561124096\n",
      "vwaps_order_sizes_buy   -0.5228428096952912\n",
      "vwaps_order_sizes_sell   -0.9230275971335737\n",
      "s2f_order_sizes_buy   -0.5812862978234198\n",
      "s2f_order_sizes_sell   0.029430038419567445\n",
      "next_trade_time   -0.8321185087468964\n",
      "next_trade_size   1.1750211968690398\n",
      "next_trade_price   0.5417171014228174\n",
      "Number of positive class in training dataset = 449\n",
      "Number of negative class in training dataset = 325\n",
      "Number of positive class in testing dataset = 50\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "0.45348837209302323\n",
      "Confusion matrix:\n",
      "[[ 9 41]\n",
      " [ 6 30]]\n",
      "Precision:\n",
      "0.18\n",
      "Recall:\n",
      "0.6\n",
      "Coefficient impact:\n",
      "order_inbalance   0.22654277668399156\n",
      "vwaps_buy   0.7178020701386774\n",
      "vwaps_sell   -0.7877709316117728\n",
      "s2f_impact_buy   -0.6109291146252906\n",
      "s2f_impact_sell   0.4867493699352678\n",
      "trading_volumes   -2.4073758795120965\n",
      "price_volatilities   0.026698882243705663\n",
      "vwaps_order_sizes_buy   -0.6221949294334275\n",
      "vwaps_order_sizes_sell   -1.1262508116593903\n",
      "s2f_order_sizes_buy   -1.177952404520389\n",
      "s2f_order_sizes_sell   0.8250123365526877\n",
      "next_trade_time   -0.5444925159892124\n",
      "next_trade_size   1.1813563185545115\n",
      "next_trade_price   0.8636652290370517\n",
      "Number of positive class in training dataset = 465\n",
      "Number of negative class in training dataset = 309\n",
      "Number of positive class in testing dataset = 34\n",
      "Number of negative class in testing dataset = 52\n",
      "Percent of correct classification:\n",
      "0.5232558139534884\n",
      "Confusion matrix:\n",
      "[[32  2]\n",
      " [39 13]]\n",
      "Precision:\n",
      "0.9411764705882353\n",
      "Recall:\n",
      "0.4507042253521127\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.00597676110543462\n",
      "vwaps_buy   0.3317512580201084\n",
      "vwaps_sell   -0.6882761623990341\n",
      "s2f_impact_buy   -0.23934821542401602\n",
      "s2f_impact_sell   0.4733463521828365\n",
      "trading_volumes   -2.256744791428602\n",
      "price_volatilities   -0.004069236078724294\n",
      "vwaps_order_sizes_buy   -0.38451904358453937\n",
      "vwaps_order_sizes_sell   -1.3703124390934847\n",
      "s2f_order_sizes_buy   -1.2550989145215763\n",
      "s2f_order_sizes_sell   0.24824468715057038\n",
      "next_trade_time   -0.6196183556591673\n",
      "next_trade_size   0.6785924274050599\n",
      "next_trade_price   0.3955483950396049\n",
      "Number of positive class in training dataset = 445\n",
      "Number of negative class in training dataset = 329\n",
      "Number of positive class in testing dataset = 54\n",
      "Number of negative class in testing dataset = 32\n",
      "Percent of correct classification:\n",
      "0.5581395348837209\n",
      "Confusion matrix:\n",
      "[[44 10]\n",
      " [28  4]]\n",
      "Precision:\n",
      "0.8148148148148148\n",
      "Recall:\n",
      "0.6111111111111112\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.1294451527106159\n",
      "vwaps_buy   0.05100922660899466\n",
      "vwaps_sell   -0.5973619476174714\n",
      "s2f_impact_buy   -0.47179673779198605\n",
      "s2f_impact_sell   0.6180069237970018\n",
      "trading_volumes   -2.4410727860353525\n",
      "price_volatilities   0.09499393226755697\n",
      "vwaps_order_sizes_buy   -0.2036159514758429\n",
      "vwaps_order_sizes_sell   -1.2204892026609009\n",
      "s2f_order_sizes_buy   -0.21419608497457537\n",
      "s2f_order_sizes_sell   0.2588692195970909\n",
      "next_trade_time   -0.8930847715865347\n",
      "next_trade_size   0.6204854475653148\n",
      "next_trade_price   0.5719019904159819\n",
      "Number of positive class in training dataset = 457\n",
      "Number of negative class in training dataset = 317\n",
      "Number of positive class in testing dataset = 42\n",
      "Number of negative class in testing dataset = 44\n",
      "Percent of correct classification:\n",
      "0.5697674418604651\n",
      "Confusion matrix:\n",
      "[[38  4]\n",
      " [33 11]]\n",
      "Precision:\n",
      "0.9047619047619048\n",
      "Recall:\n",
      "0.5352112676056338\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.295842601836211\n",
      "vwaps_buy   0.5823462701270318\n",
      "vwaps_sell   -0.44180944089418067\n",
      "s2f_impact_buy   -0.4370355454743617\n",
      "s2f_impact_sell   0.3790340683692506\n",
      "trading_volumes   -2.282980230109988\n",
      "price_volatilities   0.2194577372240062\n",
      "vwaps_order_sizes_buy   -0.5411474687858403\n",
      "vwaps_order_sizes_sell   -1.1719266898268503\n",
      "s2f_order_sizes_buy   -0.546943839113453\n",
      "s2f_order_sizes_sell   0.0715566162412834\n",
      "next_trade_time   -0.43145231307886867\n",
      "next_trade_size   1.0916587799106856\n",
      "next_trade_price   0.23475078960943146\n",
      "Number of positive class in training dataset = 434\n",
      "Number of negative class in training dataset = 340\n",
      "Number of positive class in testing dataset = 65\n",
      "Number of negative class in testing dataset = 21\n",
      "Percent of correct classification:\n",
      "0.8255813953488372\n",
      "Confusion matrix:\n",
      "[[65  0]\n",
      " [15  6]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.8125\n",
      "Coefficient impact:\n",
      "order_inbalance   -0.06279477574642178\n",
      "vwaps_buy   0.7076339280554065\n",
      "vwaps_sell   -0.376655675045173\n",
      "s2f_impact_buy   -0.5475296187345204\n",
      "s2f_impact_sell   0.3678319513839091\n",
      "trading_volumes   -2.5129395727442425\n",
      "price_volatilities   0.041131232350535216\n",
      "vwaps_order_sizes_buy   -0.265155832209459\n",
      "vwaps_order_sizes_sell   -1.8996376111966211\n",
      "s2f_order_sizes_buy   -0.6014914580752184\n",
      "s2f_order_sizes_sell   0.4270697436369865\n",
      "next_trade_time   -0.7588221917432045\n",
      "next_trade_size   0.7983028460407386\n",
      "next_trade_price   0.0010033620543686058\n",
      "Number of positive class in training dataset = 444\n",
      "Number of negative class in training dataset = 330\n",
      "Number of positive class in testing dataset = 55\n",
      "Number of negative class in testing dataset = 31\n",
      "Percent of correct classification:\n",
      "0.6511627906976745\n",
      "Confusion matrix:\n",
      "[[52  3]\n",
      " [27  4]]\n",
      "Precision:\n",
      "0.9454545454545454\n",
      "Recall:\n",
      "0.6582278481012658\n",
      "Coefficient impact:\n",
      "order_inbalance   0.08385555206503878\n",
      "vwaps_buy   0.104946618972498\n",
      "vwaps_sell   -0.7266489245946262\n",
      "s2f_impact_buy   -0.2958218484605665\n",
      "s2f_impact_sell   0.2502938689399469\n",
      "trading_volumes   -2.3627224522623003\n",
      "price_volatilities   0.027959667619099317\n",
      "vwaps_order_sizes_buy   -0.5375099699934677\n",
      "vwaps_order_sizes_sell   -1.1794577473711565\n",
      "s2f_order_sizes_buy   -1.0750180960652256\n",
      "s2f_order_sizes_sell   0.4219304552474202\n",
      "next_trade_time   -1.0928710488326232\n",
      "next_trade_size   1.122206721321078\n",
      "next_trade_price   0.46937385645675833\n",
      "Number of positive class in training dataset = 452\n",
      "Number of negative class in training dataset = 322\n",
      "Number of positive class in testing dataset = 47\n",
      "Number of negative class in testing dataset = 39\n",
      "Percent of correct classification:\n",
      "0.5465116279069767\n",
      "Confusion matrix:\n",
      "[[47  0]\n",
      " [39  0]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.5465116279069767\n"
     ]
    }
   ],
   "source": [
    "interval=5\n",
    "time_to_skip=30\n",
    "time_back=10\n",
    "y_name='true_price'\n",
    "swing_interval = 60\n",
    "check = 'swing_min'\n",
    "use_scaling = True\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.001\n",
    "sum_of_acc = 0.0\n",
    "sum_of_prec = 0.0\n",
    "sum_of_recall = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, 'log_reg',use_scaling = use_scaling)\n",
    "    sum_of_acc+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: 0.5285647169368097\n",
      "Average precision with scaling: 0.6261866393564482\n",
      "Average recall with scaling: nan\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy with scaling:\",sum_of_acc/99)\n",
    "print(\"Average precision with scaling:\",sum_of_prec/99)\n",
    "print(\"Average recall with scaling:\",sum_of_recall/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max z kolejnych 3 godzin patrząc na ostatnie 30 min i biorąc threshold 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n",
      "Coefficient impact:\n",
      "order_inbalance   -2.6123341387702146\n",
      "vwaps_buy   2.06927046474056\n",
      "vwaps_sell   3.4353028989134637\n",
      "s2f_impact_buy   -0.9490639397214353\n",
      "s2f_impact_sell   1.864408578960992\n",
      "trading_volumes   -0.7961945640001656\n",
      "price_volatilities   -2.2618370881502137\n",
      "vwaps_order_sizes_buy   -1.2408060195870145\n",
      "vwaps_order_sizes_sell   0.42290528315951287\n",
      "s2f_order_sizes_buy   0.30124511536610227\n",
      "s2f_order_sizes_sell   -0.6261908130907351\n",
      "next_trade_time   0.024599367223285273\n",
      "next_trade_size   -0.4793236240746324\n",
      "next_trade_price   1.6006442005714576\n",
      "Number of positive class in training dataset = 102\n",
      "Number of negative class in training dataset = 492\n",
      "Number of positive class in testing dataset = 16\n",
      "Number of negative class in testing dataset = 50\n",
      "Percent of correct classification:\n",
      "0.7575757575757576\n",
      "Confusion matrix:\n",
      "[[ 0 16]\n",
      " [ 0 50]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "Coefficient impact:\n",
      "order_inbalance   -3.20828239566348\n",
      "vwaps_buy   1.8857455640975214\n",
      "vwaps_sell   3.0636654079898884\n",
      "s2f_impact_buy   -0.9184565143335611\n",
      "s2f_impact_sell   2.1282644470556256\n",
      "trading_volumes   -0.8326449884202539\n",
      "price_volatilities   -2.39002773673345\n",
      "vwaps_order_sizes_buy   -1.313177317778214\n",
      "vwaps_order_sizes_sell   0.37829305921586126\n",
      "s2f_order_sizes_buy   0.8259382754430277\n",
      "s2f_order_sizes_sell   -0.8077290023525663\n",
      "next_trade_time   1.623211558792441\n",
      "next_trade_size   -0.5044088867669029\n",
      "next_trade_price   1.3602088647722517\n",
      "Number of positive class in training dataset = 116\n",
      "Number of negative class in training dataset = 478\n",
      "Number of positive class in testing dataset = 2\n",
      "Number of negative class in testing dataset = 64\n",
      "Percent of correct classification:\n",
      "0.7272727272727273\n",
      "Confusion matrix:\n",
      "[[ 0  2]\n",
      " [16 48]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "0.0\n",
      "Coefficient impact:\n",
      "order_inbalance   0.029356117842456314\n",
      "vwaps_buy   2.220622388697836\n",
      "vwaps_sell   3.352796142840522\n",
      "s2f_impact_buy   1.0845172997663388\n",
      "s2f_impact_sell   2.9857366428133494\n",
      "trading_volumes   -0.9715522644866698\n",
      "price_volatilities   -1.7975717264373343\n",
      "vwaps_order_sizes_buy   -0.6417295835675212\n",
      "vwaps_order_sizes_sell   -0.2937970376797367\n",
      "s2f_order_sizes_buy   1.649790255298105\n",
      "s2f_order_sizes_sell   -1.9110326946288387\n",
      "next_trade_time   1.430095682006754\n",
      "next_trade_size   0.05530428765395352\n",
      "next_trade_price   0.38526820895142366\n",
      "Number of positive class in training dataset = 80\n",
      "Number of negative class in training dataset = 514\n",
      "Number of positive class in testing dataset = 38\n",
      "Number of negative class in testing dataset = 28\n",
      "Percent of correct classification:\n",
      "0.42424242424242425\n",
      "Confusion matrix:\n",
      "[[ 0 38]\n",
      " [ 0 28]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "Coefficient impact:\n",
      "order_inbalance   -2.1788851657300734\n",
      "vwaps_buy   1.4368211998347098\n",
      "vwaps_sell   3.34876026906495\n",
      "s2f_impact_buy   -0.8881123283326051\n",
      "s2f_impact_sell   1.9780102637416022\n",
      "trading_volumes   -0.7129101265973717\n",
      "price_volatilities   -2.482308257000968\n",
      "vwaps_order_sizes_buy   -1.1082689590229104\n",
      "vwaps_order_sizes_sell   0.44512829331186066\n",
      "s2f_order_sizes_buy   1.1612389077176672\n",
      "s2f_order_sizes_sell   -0.6428889816293433\n",
      "next_trade_time   0.147090401127155\n",
      "next_trade_size   -1.4451705101821404\n",
      "next_trade_price   1.1266059038823812\n",
      "Number of positive class in training dataset = 115\n",
      "Number of negative class in training dataset = 479\n",
      "Number of positive class in testing dataset = 3\n",
      "Number of negative class in testing dataset = 63\n",
      "Percent of correct classification:\n",
      "0.9545454545454546\n",
      "Confusion matrix:\n",
      "[[ 0  3]\n",
      " [ 0 63]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "Coefficient impact:\n",
      "order_inbalance   -4.011424602032708\n",
      "vwaps_buy   -0.7562393248104257\n",
      "vwaps_sell   2.1017582656722795\n",
      "s2f_impact_buy   0.07936362699361273\n",
      "s2f_impact_sell   0.417571342556144\n",
      "trading_volumes   -0.6220425629087614\n",
      "price_volatilities   -1.7260647051083378\n",
      "vwaps_order_sizes_buy   -0.3335622366465626\n",
      "vwaps_order_sizes_sell   -0.35847098380183495\n",
      "s2f_order_sizes_buy   2.023753308115625\n",
      "s2f_order_sizes_sell   -1.4430261752486186\n",
      "next_trade_time   -0.35935039407996877\n",
      "next_trade_size   -1.147672807340212\n",
      "next_trade_price   -0.8953659319727836\n",
      "Number of positive class in training dataset = 87\n",
      "Number of negative class in training dataset = 507\n",
      "Number of positive class in testing dataset = 31\n",
      "Number of negative class in testing dataset = 35\n",
      "Percent of correct classification:\n",
      "0.5303030303030303\n",
      "Confusion matrix:\n",
      "[[ 0 31]\n",
      " [ 0 35]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "Coefficient impact:\n",
      "order_inbalance   -2.580719505539402\n",
      "vwaps_buy   1.2991148659015943\n",
      "vwaps_sell   3.1634720056348256\n",
      "s2f_impact_buy   -0.6197487957789742\n",
      "s2f_impact_sell   2.191191895554347\n",
      "trading_volumes   -0.9498253792789078\n",
      "price_volatilities   -2.503563035848497\n",
      "vwaps_order_sizes_buy   -1.2557947747835223\n",
      "vwaps_order_sizes_sell   0.2732422091299699\n",
      "s2f_order_sizes_buy   1.4642859877585581\n",
      "s2f_order_sizes_sell   -0.8896622595510235\n",
      "next_trade_time   0.09333414554225354\n",
      "next_trade_size   -1.417238009224572\n",
      "next_trade_price   1.1927671683912744\n",
      "Number of positive class in training dataset = 117\n",
      "Number of negative class in training dataset = 477\n",
      "Number of positive class in testing dataset = 1\n",
      "Number of negative class in testing dataset = 65\n",
      "Percent of correct classification:\n",
      "0.9848484848484849\n",
      "Confusion matrix:\n",
      "[[ 0  1]\n",
      " [ 0 65]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "Coefficient impact:\n",
      "order_inbalance   -2.4067268928606005\n",
      "vwaps_buy   1.8660662763821083\n",
      "vwaps_sell   3.681879927824196\n",
      "s2f_impact_buy   -1.0204346786119942\n",
      "s2f_impact_sell   2.534200327965068\n",
      "trading_volumes   -0.5533772911307463\n",
      "price_volatilities   -1.9592424152702563\n",
      "vwaps_order_sizes_buy   -0.9984966858881005\n",
      "vwaps_order_sizes_sell   0.22723481227099335\n",
      "s2f_order_sizes_buy   0.2732700302495832\n",
      "s2f_order_sizes_sell   -1.2193094778125844\n",
      "next_trade_time   -0.22867678427775545\n",
      "next_trade_size   -2.2434677423071157\n",
      "next_trade_price   1.6429146971403517\n",
      "Number of positive class in training dataset = 105\n",
      "Number of negative class in training dataset = 489\n",
      "Number of positive class in testing dataset = 13\n",
      "Number of negative class in testing dataset = 53\n",
      "Percent of correct classification:\n",
      "0.803030303030303\n",
      "Confusion matrix:\n",
      "[[ 0 13]\n",
      " [ 0 53]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "Coefficient impact:\n",
      "order_inbalance   -2.170410515303608\n",
      "vwaps_buy   1.3457413220476728\n",
      "vwaps_sell   3.2607263698595035\n",
      "s2f_impact_buy   -0.39831751714676833\n",
      "s2f_impact_sell   2.3690392347582363\n",
      "trading_volumes   -0.6871618250937376\n",
      "price_volatilities   -3.0783822407560097\n",
      "vwaps_order_sizes_buy   -1.2113568836970412\n",
      "vwaps_order_sizes_sell   0.5498118725213048\n",
      "s2f_order_sizes_buy   0.7872436107378246\n",
      "s2f_order_sizes_sell   -1.0658632298624136\n",
      "next_trade_time   -0.861007803851932\n",
      "next_trade_size   -1.366078416113819\n",
      "next_trade_price   1.2313234667007644\n",
      "Number of positive class in training dataset = 118\n",
      "Number of negative class in training dataset = 476\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 66\n",
      "Percent of correct classification:\n",
      "0.9393939393939394\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 4 62]]\n",
      "Coefficient impact:\n",
      "order_inbalance   -2.9480514660432773\n",
      "vwaps_buy   1.144623189939019\n",
      "vwaps_sell   2.3560767640508344\n",
      "s2f_impact_buy   -0.8336023815173254\n",
      "s2f_impact_sell   2.282655880565\n",
      "trading_volumes   -0.9569677237324263\n",
      "price_volatilities   -3.1923404181398456\n",
      "vwaps_order_sizes_buy   -1.2550568589981823\n",
      "vwaps_order_sizes_sell   0.22682004562843325\n",
      "s2f_order_sizes_buy   1.190847128363579\n",
      "s2f_order_sizes_sell   0.23283373026453852\n",
      "next_trade_time   -0.11486639867024637\n",
      "next_trade_size   -0.6374039222364202\n",
      "next_trade_price   2.1022761803233263\n",
      "Number of positive class in training dataset = 104\n",
      "Number of negative class in training dataset = 490\n",
      "Number of positive class in testing dataset = 14\n",
      "Number of negative class in testing dataset = 52\n",
      "Percent of correct classification:\n",
      "0.7878787878787878\n",
      "Confusion matrix:\n",
      "[[ 0 14]\n",
      " [ 0 52]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "Coefficient impact:\n",
      "order_inbalance   -3.1816263029590566\n",
      "vwaps_buy   1.3075654785572988\n",
      "vwaps_sell   2.7820767047038393\n",
      "s2f_impact_buy   -0.18565696000023696\n",
      "s2f_impact_sell   2.7496528817804986\n",
      "trading_volumes   -1.237070091105285\n",
      "price_volatilities   -2.126760944719626\n",
      "vwaps_order_sizes_buy   -1.4260834716226594\n",
      "vwaps_order_sizes_sell   0.10156912432014498\n",
      "s2f_order_sizes_buy   0.47790244537493\n",
      "s2f_order_sizes_sell   -1.4879181788587343\n",
      "next_trade_time   -0.39853275619351874\n",
      "next_trade_size   -1.4538433827136552\n",
      "next_trade_price   1.3873752863227389\n",
      "Number of positive class in training dataset = 118\n",
      "Number of negative class in training dataset = 476\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 66\n",
      "Percent of correct classification:\n",
      "1.0\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 0 66]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n"
     ]
    }
   ],
   "source": [
    "interval=5\n",
    "time_to_skip=30\n",
    "time_back=30\n",
    "y_name='true_price'\n",
    "swing_interval = 180\n",
    "check = 'swing_max'\n",
    "use_scaling = True\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.005\n",
    "sum_of_acc = 0.0\n",
    "sum_of_prec = 0.0\n",
    "sum_of_recall = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, 'log_reg',use_scaling = use_scaling)\n",
    "    sum_of_acc+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: 0.6944750535659625\n",
      "Average precision with scaling: nan\n",
      "Average recall with scaling: nan\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy with scaling:\",sum_of_acc/99)\n",
    "print(\"Average precision with scaling:\",sum_of_prec/99)\n",
    "print(\"Average recall with scaling:\",sum_of_recall/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max z kolejnych 3 godzin patrząc na ostatnie 60 min i biorąc threshold 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n",
      "Coefficient impact:\n",
      "order_inbalance   -1.9793547496059787\n",
      "vwaps_buy   0.4220978952088691\n",
      "vwaps_sell   0.4639352872787656\n",
      "s2f_impact_buy   -3.5811839194328767\n",
      "s2f_impact_sell   0.6777484928156183\n",
      "trading_volumes   0.4232396390942271\n",
      "price_volatilities   -0.6964738828727357\n",
      "vwaps_order_sizes_buy   -0.20296750220963553\n",
      "vwaps_order_sizes_sell   1.0344385411617245\n",
      "s2f_order_sizes_buy   -0.19723783679386572\n",
      "s2f_order_sizes_sell   0.9367912958895693\n",
      "next_trade_time   -0.7640494431503029\n",
      "next_trade_size   -1.0108544392221273\n",
      "next_trade_price   1.970720130452098\n",
      "Number of positive class in training dataset = 34\n",
      "Number of negative class in training dataset = 290\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "1.0\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 0 36]]\n",
      "Coefficient impact:\n",
      "order_inbalance   -2.1073138157332116\n",
      "vwaps_buy   0.4330582056838721\n",
      "vwaps_sell   0.3990639332191807\n",
      "s2f_impact_buy   -3.477975926942075\n",
      "s2f_impact_sell   0.7926157397679091\n",
      "trading_volumes   0.3604272316817791\n",
      "price_volatilities   -0.8431766543383821\n",
      "vwaps_order_sizes_buy   -0.25699679618265114\n",
      "vwaps_order_sizes_sell   0.9817522247308376\n",
      "s2f_order_sizes_buy   -0.4531581273071098\n",
      "s2f_order_sizes_sell   1.0128584419793707\n",
      "next_trade_time   -0.3165755727151984\n",
      "next_trade_size   -0.6430014438182039\n",
      "next_trade_price   1.9667015742981218\n",
      "Number of positive class in training dataset = 34\n",
      "Number of negative class in training dataset = 290\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "1.0\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 0 36]]\n",
      "Coefficient impact:\n",
      "order_inbalance   0.5922493976710859\n",
      "vwaps_buy   1.302120382061279\n",
      "vwaps_sell   -0.03786711595209564\n",
      "s2f_impact_buy   -0.4654119815377055\n",
      "s2f_impact_sell   0.5847261814977762\n",
      "trading_volumes   0.30184724714061917\n",
      "price_volatilities   -0.2535929528904901\n",
      "vwaps_order_sizes_buy   0.4413545038275535\n",
      "vwaps_order_sizes_sell   -0.07169815291357598\n",
      "s2f_order_sizes_buy   0.437590473100509\n",
      "s2f_order_sizes_sell   -0.19309317390375197\n",
      "next_trade_time   0.07684902453704993\n",
      "next_trade_size   -0.17935483893016207\n",
      "next_trade_price   1.843555826829279\n",
      "Number of positive class in training dataset = 12\n",
      "Number of negative class in training dataset = 312\n",
      "Number of positive class in testing dataset = 22\n",
      "Number of negative class in testing dataset = 14\n",
      "Percent of correct classification:\n",
      "0.3888888888888889\n",
      "Confusion matrix:\n",
      "[[ 0 22]\n",
      " [ 0 14]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "Coefficient impact:\n",
      "order_inbalance   -1.5818236921201676\n",
      "vwaps_buy   0.3268045913646696\n",
      "vwaps_sell   0.8442199104819098\n",
      "s2f_impact_buy   -3.622773188652638\n",
      "s2f_impact_sell   0.7089289704730821\n",
      "trading_volumes   0.5548281738755564\n",
      "price_volatilities   -0.42106857786081664\n",
      "vwaps_order_sizes_buy   -0.1520760087915721\n",
      "vwaps_order_sizes_sell   1.1682847480917695\n",
      "s2f_order_sizes_buy   -0.3448474188367391\n",
      "s2f_order_sizes_sell   1.2258859307208843\n",
      "next_trade_time   -0.6867540794032053\n",
      "next_trade_size   -0.7807967399436642\n",
      "next_trade_price   1.718157723218314\n",
      "Number of positive class in training dataset = 34\n",
      "Number of negative class in training dataset = 290\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "1.0\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 0 36]]\n",
      "Coefficient impact:\n",
      "order_inbalance   -2.817254052125644\n",
      "vwaps_buy   -1.1747440064172074\n",
      "vwaps_sell   -0.046357484942199816\n",
      "s2f_impact_buy   -2.6602899429644364\n",
      "s2f_impact_sell   0.4066668342674546\n",
      "trading_volumes   0.7054490688135429\n",
      "price_volatilities   0.17982986990964858\n",
      "vwaps_order_sizes_buy   0.24028471070375568\n",
      "vwaps_order_sizes_sell   0.8042909190472614\n",
      "s2f_order_sizes_buy   -0.29515717825444404\n",
      "s2f_order_sizes_sell   0.995786846221824\n",
      "next_trade_time   -0.5793784787737889\n",
      "next_trade_size   -0.09350339693275132\n",
      "next_trade_price   -0.09834623749068352\n",
      "Number of positive class in training dataset = 24\n",
      "Number of negative class in training dataset = 300\n",
      "Number of positive class in testing dataset = 10\n",
      "Number of negative class in testing dataset = 26\n",
      "Percent of correct classification:\n",
      "0.7222222222222222\n",
      "Confusion matrix:\n",
      "[[ 0 10]\n",
      " [ 0 26]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "Coefficient impact:\n",
      "order_inbalance   -1.7858097284302896\n",
      "vwaps_buy   0.26540940952487024\n",
      "vwaps_sell   0.34741059652916556\n",
      "s2f_impact_buy   -3.4962306381360637\n",
      "s2f_impact_sell   0.856534150899526\n",
      "trading_volumes   0.49263297806772005\n",
      "price_volatilities   -0.39640842692322414\n",
      "vwaps_order_sizes_buy   -0.2016745267755535\n",
      "vwaps_order_sizes_sell   1.1429205698652287\n",
      "s2f_order_sizes_buy   -0.16341913932845006\n",
      "s2f_order_sizes_sell   1.1845475876446958\n",
      "next_trade_time   -0.6552565296496217\n",
      "next_trade_size   -1.0228277580004392\n",
      "next_trade_price   1.9210331416576696\n",
      "Number of positive class in training dataset = 34\n",
      "Number of negative class in training dataset = 290\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "1.0\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 0 36]]\n",
      "Coefficient impact:\n",
      "order_inbalance   -1.9478597974823861\n",
      "vwaps_buy   0.37339291491898174\n",
      "vwaps_sell   0.6151655963713738\n",
      "s2f_impact_buy   -3.595835488224363\n",
      "s2f_impact_sell   0.8952021013148352\n",
      "trading_volumes   0.5433388909611224\n",
      "price_volatilities   -0.43587966838824277\n",
      "vwaps_order_sizes_buy   -0.10759447501767871\n",
      "vwaps_order_sizes_sell   1.0334668802821065\n",
      "s2f_order_sizes_buy   -0.24480113335148537\n",
      "s2f_order_sizes_sell   1.0082301414436934\n",
      "next_trade_time   -0.7290891157292925\n",
      "next_trade_size   -0.8845805680148079\n",
      "next_trade_price   1.9679184876406106\n",
      "Number of positive class in training dataset = 32\n",
      "Number of negative class in training dataset = 292\n",
      "Number of positive class in testing dataset = 2\n",
      "Number of negative class in testing dataset = 34\n",
      "Percent of correct classification:\n",
      "0.9444444444444444\n",
      "Confusion matrix:\n",
      "[[ 0  2]\n",
      " [ 0 34]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "Coefficient impact:\n",
      "order_inbalance   -1.7953132177519358\n",
      "vwaps_buy   0.3573169703319095\n",
      "vwaps_sell   0.5035671315137158\n",
      "s2f_impact_buy   -3.5280600961530513\n",
      "s2f_impact_sell   0.9349612569759727\n",
      "trading_volumes   0.5071684986675639\n",
      "price_volatilities   -0.7478995849045375\n",
      "vwaps_order_sizes_buy   -0.14434385708868241\n",
      "vwaps_order_sizes_sell   1.0812489463185009\n",
      "s2f_order_sizes_buy   -0.36485494599897556\n",
      "s2f_order_sizes_sell   1.0541787760215862\n",
      "next_trade_time   -0.7539211409188304\n",
      "next_trade_size   -0.9130977291254961\n",
      "next_trade_price   1.887704929462579\n",
      "Number of positive class in training dataset = 34\n",
      "Number of negative class in training dataset = 290\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "1.0\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 0 36]]\n",
      "Coefficient impact:\n",
      "order_inbalance   -1.8836954975602802\n",
      "vwaps_buy   0.37399021282261447\n",
      "vwaps_sell   0.7236818029317691\n",
      "s2f_impact_buy   -3.5058301340052322\n",
      "s2f_impact_sell   0.9983599342932246\n",
      "trading_volumes   0.40908670825299226\n",
      "price_volatilities   -0.4212157052322564\n",
      "vwaps_order_sizes_buy   -0.1807022473917258\n",
      "vwaps_order_sizes_sell   0.9777086043857028\n",
      "s2f_order_sizes_buy   -0.30452117053795374\n",
      "s2f_order_sizes_sell   0.9473861571114895\n",
      "next_trade_time   -0.6675099914271905\n",
      "next_trade_size   -0.814693392685504\n",
      "next_trade_price   1.8438327297469495\n",
      "Number of positive class in training dataset = 34\n",
      "Number of negative class in training dataset = 290\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "1.0\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 0 36]]\n",
      "Coefficient impact:\n",
      "order_inbalance   -2.1431865024741237\n",
      "vwaps_buy   0.1842155428156308\n",
      "vwaps_sell   0.22420193487062073\n",
      "s2f_impact_buy   -3.3291820619030696\n",
      "s2f_impact_sell   1.0547059301420072\n",
      "trading_volumes   0.16972843200881046\n",
      "price_volatilities   -0.11068482613922084\n",
      "vwaps_order_sizes_buy   -0.3678669292141882\n",
      "vwaps_order_sizes_sell   0.8700487564034557\n",
      "s2f_order_sizes_buy   -0.5279658415683008\n",
      "s2f_order_sizes_sell   0.7717274529988555\n",
      "next_trade_time   -0.9267070625732643\n",
      "next_trade_size   -1.0477325103364066\n",
      "next_trade_price   2.00915473137458\n",
      "Number of positive class in training dataset = 34\n",
      "Number of negative class in training dataset = 290\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "1.0\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 0 36]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n"
     ]
    }
   ],
   "source": [
    "interval=5\n",
    "time_to_skip=30\n",
    "time_back=60\n",
    "y_name='true_price'\n",
    "swing_interval = 180\n",
    "check = 'swing_max'\n",
    "use_scaling = True\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.005\n",
    "sum_of_acc = 0.0\n",
    "sum_of_prec = 0.0\n",
    "sum_of_recall = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, 'log_reg',use_scaling = use_scaling)\n",
    "    sum_of_acc+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: nan\n",
      "Average precision with scaling: nan\n",
      "Average recall with scaling: nan\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy with scaling:\",sum_of_acc/99)\n",
    "print(\"Average precision with scaling:\",sum_of_prec/99)\n",
    "print(\"Average recall with scaling:\",sum_of_recall/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min z kolejnych 3 godzin patrząc na ostatnie 30 min i biorąc threshold 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n",
      "Coefficient impact:\n",
      "order_inbalance   2.7940300907250557\n",
      "vwaps_buy   1.329453353472366\n",
      "vwaps_sell   0.12652234610724308\n",
      "s2f_impact_buy   -0.5959122803821979\n",
      "s2f_impact_sell   -1.3967584891115594\n",
      "trading_volumes   -0.9481923263891125\n",
      "price_volatilities   -2.82638753042126\n",
      "vwaps_order_sizes_buy   0.1594059095245737\n",
      "vwaps_order_sizes_sell   -1.3663147638783602\n",
      "s2f_order_sizes_buy   -1.8282730483021774\n",
      "s2f_order_sizes_sell   -0.48487502108658276\n",
      "next_trade_time   -1.8320241201983694\n",
      "next_trade_size   -0.4176346659412485\n",
      "next_trade_price   0.37979894408419457\n",
      "Number of positive class in training dataset = 112\n",
      "Number of negative class in training dataset = 482\n",
      "Number of positive class in testing dataset = 1\n",
      "Number of negative class in testing dataset = 65\n",
      "Percent of correct classification:\n",
      "0.30303030303030304\n",
      "Confusion matrix:\n",
      "[[ 1  0]\n",
      " [46 19]]\n",
      "Precision:\n",
      "1.0\n",
      "Recall:\n",
      "0.02127659574468085\n",
      "Coefficient impact:\n",
      "order_inbalance   1.9496313465075306\n",
      "vwaps_buy   1.7446089414778485\n",
      "vwaps_sell   -0.15714172914384036\n",
      "s2f_impact_buy   -1.0544614942074673\n",
      "s2f_impact_sell   -0.1121396206685939\n",
      "trading_volumes   -0.7930534803918702\n",
      "price_volatilities   -2.287186228474321\n",
      "vwaps_order_sizes_buy   0.1640437053076798\n",
      "vwaps_order_sizes_sell   -1.1042317463247975\n",
      "s2f_order_sizes_buy   -2.5435401102722244\n",
      "s2f_order_sizes_sell   0.017919765269310817\n",
      "next_trade_time   -0.15380273240075218\n",
      "next_trade_size   0.5015061147991412\n",
      "next_trade_price   0.44259606967473386\n",
      "Number of positive class in training dataset = 113\n",
      "Number of negative class in training dataset = 481\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 66\n",
      "Percent of correct classification:\n",
      "1.0\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 0 66]]\n",
      "Coefficient impact:\n",
      "order_inbalance   1.8997447406202819\n",
      "vwaps_buy   1.6109212848602248\n",
      "vwaps_sell   0.7201332026490145\n",
      "s2f_impact_buy   0.2571056267574188\n",
      "s2f_impact_sell   -0.09597926187480542\n",
      "trading_volumes   -0.43333441979896503\n",
      "price_volatilities   -1.9911527314403985\n",
      "vwaps_order_sizes_buy   0.7141041024516342\n",
      "vwaps_order_sizes_sell   -1.4253886282878778\n",
      "s2f_order_sizes_buy   -2.0788966699859643\n",
      "s2f_order_sizes_sell   -0.7312212438195749\n",
      "next_trade_time   0.06188606948640416\n",
      "next_trade_size   0.07202980156631497\n",
      "next_trade_price   -0.14981786789943513\n",
      "Number of positive class in training dataset = 101\n",
      "Number of negative class in training dataset = 493\n",
      "Number of positive class in testing dataset = 12\n",
      "Number of negative class in testing dataset = 54\n",
      "Percent of correct classification:\n",
      "0.8181818181818182\n",
      "Confusion matrix:\n",
      "[[ 0 12]\n",
      " [ 0 54]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "Coefficient impact:\n",
      "order_inbalance   2.725177648601707\n",
      "vwaps_buy   1.4269076470630158\n",
      "vwaps_sell   -0.21564435346730773\n",
      "s2f_impact_buy   -1.9719580246469044\n",
      "s2f_impact_sell   0.14029455084133974\n",
      "trading_volumes   -0.3687094324728884\n",
      "price_volatilities   -2.534439208689233\n",
      "vwaps_order_sizes_buy   0.3929532063702143\n",
      "vwaps_order_sizes_sell   -0.7140445001831188\n",
      "s2f_order_sizes_buy   -2.1559702459091334\n",
      "s2f_order_sizes_sell   -0.10947943356575691\n",
      "next_trade_time   -1.1240576001041158\n",
      "next_trade_size   -0.29176013996700795\n",
      "next_trade_price   0.6793887521364251\n",
      "Number of positive class in training dataset = 100\n",
      "Number of negative class in training dataset = 494\n",
      "Number of positive class in testing dataset = 13\n",
      "Number of negative class in testing dataset = 53\n",
      "Percent of correct classification:\n",
      "0.803030303030303\n",
      "Confusion matrix:\n",
      "[[ 0 13]\n",
      " [ 0 53]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "Coefficient impact:\n",
      "order_inbalance   2.524587920649984\n",
      "vwaps_buy   -0.613754325573656\n",
      "vwaps_sell   -0.16784893207280904\n",
      "s2f_impact_buy   -0.35029651050617\n",
      "s2f_impact_sell   1.8911922686856193\n",
      "trading_volumes   -0.27462413620969994\n",
      "price_volatilities   -2.618891719117005\n",
      "vwaps_order_sizes_buy   1.105905425092719\n",
      "vwaps_order_sizes_sell   -1.3781813955520914\n",
      "s2f_order_sizes_buy   -1.688549788404513\n",
      "s2f_order_sizes_sell   -0.16213066441031693\n",
      "next_trade_time   -1.3007560685313662\n",
      "next_trade_size   -0.009800425250736614\n",
      "next_trade_price   -0.2085492844600105\n",
      "Number of positive class in training dataset = 80\n",
      "Number of negative class in training dataset = 514\n",
      "Number of positive class in testing dataset = 33\n",
      "Number of negative class in testing dataset = 33\n",
      "Percent of correct classification:\n",
      "0.4696969696969697\n",
      "Confusion matrix:\n",
      "[[ 0 33]\n",
      " [ 2 31]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "0.0\n",
      "Coefficient impact:\n",
      "order_inbalance   2.8223539915966755\n",
      "vwaps_buy   1.2083908368195215\n",
      "vwaps_sell   -0.34300540786603834\n",
      "s2f_impact_buy   -0.8828900823155557\n",
      "s2f_impact_sell   -0.0036318250106082187\n",
      "trading_volumes   -0.5870461915309314\n",
      "price_volatilities   -2.0094107735702016\n",
      "vwaps_order_sizes_buy   0.33801189468815407\n",
      "vwaps_order_sizes_sell   -0.9155554535988228\n",
      "s2f_order_sizes_buy   -1.9900207203197342\n",
      "s2f_order_sizes_sell   0.5396198592346478\n",
      "next_trade_time   -0.8805644912204957\n",
      "next_trade_size   -0.4381882368386581\n",
      "next_trade_price   0.516204903142144\n",
      "Number of positive class in training dataset = 112\n",
      "Number of negative class in training dataset = 482\n",
      "Number of positive class in testing dataset = 1\n",
      "Number of negative class in testing dataset = 65\n",
      "Percent of correct classification:\n",
      "0.9848484848484849\n",
      "Confusion matrix:\n",
      "[[ 0  1]\n",
      " [ 0 65]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "Coefficient impact:\n",
      "order_inbalance   2.578359859531397\n",
      "vwaps_buy   1.9203214898872305\n",
      "vwaps_sell   0.20127114024929996\n",
      "s2f_impact_buy   -0.9741061170769959\n",
      "s2f_impact_sell   -0.07933526382313806\n",
      "trading_volumes   -1.746863455648219\n",
      "price_volatilities   -2.1686443704924088\n",
      "vwaps_order_sizes_buy   -1.7322301915139682\n",
      "vwaps_order_sizes_sell   -0.9771002911852215\n",
      "s2f_order_sizes_buy   -2.122985648492798\n",
      "s2f_order_sizes_sell   0.13584154407082674\n",
      "next_trade_time   -1.469443500234448\n",
      "next_trade_size   -0.9082521712212512\n",
      "next_trade_price   0.8745250923385326\n",
      "Number of positive class in training dataset = 107\n",
      "Number of negative class in training dataset = 487\n",
      "Number of positive class in testing dataset = 6\n",
      "Number of negative class in testing dataset = 60\n",
      "Percent of correct classification:\n",
      "0.9090909090909091\n",
      "Confusion matrix:\n",
      "[[ 0  6]\n",
      " [ 0 60]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "Coefficient impact:\n",
      "order_inbalance   1.4767266609340834\n",
      "vwaps_buy   1.9222264085313958\n",
      "vwaps_sell   0.3931504632139644\n",
      "s2f_impact_buy   -1.1192205028759257\n",
      "s2f_impact_sell   -0.38768549880010966\n",
      "trading_volumes   -0.7408672861295871\n",
      "price_volatilities   -0.264547955386779\n",
      "vwaps_order_sizes_buy   0.15942398224584667\n",
      "vwaps_order_sizes_sell   -0.9641258327438844\n",
      "s2f_order_sizes_buy   -1.7370528534921104\n",
      "s2f_order_sizes_sell   0.5795105293178582\n",
      "next_trade_time   -1.1339739112683318\n",
      "next_trade_size   0.27790567754167306\n",
      "next_trade_price   0.8085984947857918\n",
      "Number of positive class in training dataset = 78\n",
      "Number of negative class in training dataset = 516\n",
      "Number of positive class in testing dataset = 35\n",
      "Number of negative class in testing dataset = 31\n",
      "Percent of correct classification:\n",
      "0.4696969696969697\n",
      "Confusion matrix:\n",
      "[[ 0 35]\n",
      " [ 0 31]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "Coefficient impact:\n",
      "order_inbalance   2.6460736915581475\n",
      "vwaps_buy   1.6827454988138295\n",
      "vwaps_sell   0.4842697362788773\n",
      "s2f_impact_buy   -1.001104364322249\n",
      "s2f_impact_sell   0.20988062779859368\n",
      "trading_volumes   -0.8569112772595222\n",
      "price_volatilities   -2.032850640548447\n",
      "vwaps_order_sizes_buy   0.32581042687550854\n",
      "vwaps_order_sizes_sell   -1.338001785241757\n",
      "s2f_order_sizes_buy   -2.2263407328325218\n",
      "s2f_order_sizes_sell   -0.5311448131981457\n",
      "next_trade_time   -1.2630432072272777\n",
      "next_trade_size   0.178253246961632\n",
      "next_trade_price   0.1990570182031348\n",
      "Number of positive class in training dataset = 110\n",
      "Number of negative class in training dataset = 484\n",
      "Number of positive class in testing dataset = 3\n",
      "Number of negative class in testing dataset = 63\n",
      "Percent of correct classification:\n",
      "0.9545454545454546\n",
      "Confusion matrix:\n",
      "[[ 0  3]\n",
      " [ 0 63]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "Coefficient impact:\n",
      "order_inbalance   3.0167910592416254\n",
      "vwaps_buy   1.7522985251452394\n",
      "vwaps_sell   0.3487013893752496\n",
      "s2f_impact_buy   -1.0086142153284807\n",
      "s2f_impact_sell   -0.09287742057585988\n",
      "trading_volumes   -0.5441502699465106\n",
      "price_volatilities   -2.4344630307154587\n",
      "vwaps_order_sizes_buy   0.500103814662395\n",
      "vwaps_order_sizes_sell   -1.0943312397534626\n",
      "s2f_order_sizes_buy   -2.033563302107935\n",
      "s2f_order_sizes_sell   0.4314546217697063\n",
      "next_trade_time   -0.774438874861029\n",
      "next_trade_size   0.04977010028505235\n",
      "next_trade_price   0.4678652573774713\n",
      "Number of positive class in training dataset = 104\n",
      "Number of negative class in training dataset = 490\n",
      "Number of positive class in testing dataset = 9\n",
      "Number of negative class in testing dataset = 57\n",
      "Percent of correct classification:\n",
      "0.8636363636363636\n",
      "Confusion matrix:\n",
      "[[ 0  9]\n",
      " [ 0 57]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n"
     ]
    }
   ],
   "source": [
    "interval=5\n",
    "time_to_skip=30\n",
    "time_back=30\n",
    "y_name='true_price'\n",
    "swing_interval = 180\n",
    "check = 'swing_min'\n",
    "use_scaling = True\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.005\n",
    "sum_of_acc = 0.0\n",
    "sum_of_prec = 0.0\n",
    "sum_of_recall = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, 'log_reg',use_scaling = use_scaling)\n",
    "    sum_of_acc+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: nan\n",
      "Average precision with scaling: nan\n",
      "Average recall with scaling: nan\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy with scaling:\",sum_of_acc/99)\n",
    "print(\"Average precision with scaling:\",sum_of_prec/99)\n",
    "print(\"Average recall with scaling:\",sum_of_recall/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min z kolejnych 3 godzin patrząc na ostatnie 60 min i biorąc threshold 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n",
      "Coefficient impact:\n",
      "order_inbalance   2.6840627131930814\n",
      "vwaps_buy   0.3886506219892076\n",
      "vwaps_sell   0.06430818807763453\n",
      "s2f_impact_buy   0.2001345058656266\n",
      "s2f_impact_sell   1.5175083406073886\n",
      "trading_volumes   -1.9363698351340493\n",
      "price_volatilities   -1.5462989629868404\n",
      "vwaps_order_sizes_buy   -1.0101799769070485\n",
      "vwaps_order_sizes_sell   -1.537306377408505\n",
      "s2f_order_sizes_buy   -1.0959467237792333\n",
      "s2f_order_sizes_sell   -1.851161959382355\n",
      "next_trade_time   -0.13701677404250423\n",
      "next_trade_size   -1.3185665761404537\n",
      "next_trade_price   0.34596704338292483\n",
      "Number of positive class in training dataset = 46\n",
      "Number of negative class in training dataset = 278\n",
      "Number of positive class in testing dataset = 1\n",
      "Number of negative class in testing dataset = 35\n",
      "Percent of correct classification:\n",
      "0.9166666666666666\n",
      "Confusion matrix:\n",
      "[[ 0  1]\n",
      " [ 2 33]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "0.0\n",
      "Coefficient impact:\n",
      "order_inbalance   2.0267239759682143\n",
      "vwaps_buy   0.6098895734565404\n",
      "vwaps_sell   0.1686869283429132\n",
      "s2f_impact_buy   -0.21650510023412595\n",
      "s2f_impact_sell   2.321299993060257\n",
      "trading_volumes   -1.7697319613031548\n",
      "price_volatilities   -1.610665015669641\n",
      "vwaps_order_sizes_buy   -1.2072929402698096\n",
      "vwaps_order_sizes_sell   -1.0315569944253398\n",
      "s2f_order_sizes_buy   -1.864623663992804\n",
      "s2f_order_sizes_sell   -1.1009890777455142\n",
      "next_trade_time   0.8955730283896071\n",
      "next_trade_size   -0.8157056580912764\n",
      "next_trade_price   0.4803106507151506\n",
      "Number of positive class in training dataset = 47\n",
      "Number of negative class in training dataset = 277\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "1.0\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 0 36]]\n",
      "Coefficient impact:\n",
      "order_inbalance   1.9771855872386934\n",
      "vwaps_buy   0.14316590201716245\n",
      "vwaps_sell   0.08112493850780755\n",
      "s2f_impact_buy   -0.18863871818797492\n",
      "s2f_impact_sell   2.467192342065983\n",
      "trading_volumes   -1.8794226758893424\n",
      "price_volatilities   -0.7766434701762078\n",
      "vwaps_order_sizes_buy   -1.1160513080559185\n",
      "vwaps_order_sizes_sell   -1.3051571302356193\n",
      "s2f_order_sizes_buy   -1.778170581590443\n",
      "s2f_order_sizes_sell   -1.2300302197801805\n",
      "next_trade_time   0.14936944595015522\n",
      "next_trade_size   -0.9365788564497349\n",
      "next_trade_price   0.24935568824947407\n",
      "Number of positive class in training dataset = 47\n",
      "Number of negative class in training dataset = 277\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "1.0\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 0 36]]\n",
      "Coefficient impact:\n",
      "order_inbalance   2.898708386357435\n",
      "vwaps_buy   0.4137498245036907\n",
      "vwaps_sell   0.44750489304330937\n",
      "s2f_impact_buy   -0.18561306743511122\n",
      "s2f_impact_sell   2.338143019277093\n",
      "trading_volumes   -1.5820784944785027\n",
      "price_volatilities   -1.2155847158031141\n",
      "vwaps_order_sizes_buy   -1.063810307199515\n",
      "vwaps_order_sizes_sell   -0.916047571860055\n",
      "s2f_order_sizes_buy   -1.6488813452145954\n",
      "s2f_order_sizes_sell   -1.115130038100228\n",
      "next_trade_time   -0.11660268864084397\n",
      "next_trade_size   -1.1836688261265775\n",
      "next_trade_price   0.25093147023314377\n",
      "Number of positive class in training dataset = 46\n",
      "Number of negative class in training dataset = 278\n",
      "Number of positive class in testing dataset = 1\n",
      "Number of negative class in testing dataset = 35\n",
      "Percent of correct classification:\n",
      "0.9722222222222222\n",
      "Confusion matrix:\n",
      "[[ 0  1]\n",
      " [ 0 35]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "Coefficient impact:\n",
      "order_inbalance   2.276784840047383\n",
      "vwaps_buy   -0.8821641280256094\n",
      "vwaps_sell   -0.5425794618045201\n",
      "s2f_impact_buy   0.11624979004715214\n",
      "s2f_impact_sell   1.4782553781974017\n",
      "trading_volumes   -1.3664363373559631\n",
      "price_volatilities   -1.261421651356592\n",
      "vwaps_order_sizes_buy   -0.6512357735311028\n",
      "vwaps_order_sizes_sell   -1.1312367648909016\n",
      "s2f_order_sizes_buy   -1.5301502079341243\n",
      "s2f_order_sizes_sell   -1.3547150006380828\n",
      "next_trade_time   -0.28604735646183055\n",
      "next_trade_size   -1.3611068817723904\n",
      "next_trade_price   -0.24938222656278733\n",
      "Number of positive class in training dataset = 32\n",
      "Number of negative class in training dataset = 292\n",
      "Number of positive class in testing dataset = 15\n",
      "Number of negative class in testing dataset = 21\n",
      "Percent of correct classification:\n",
      "0.5833333333333334\n",
      "Confusion matrix:\n",
      "[[ 0 15]\n",
      " [ 0 21]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "Coefficient impact:\n",
      "order_inbalance   2.81037644183606\n",
      "vwaps_buy   0.303341191366088\n",
      "vwaps_sell   0.1231964027348052\n",
      "s2f_impact_buy   -0.16814122607326493\n",
      "s2f_impact_sell   2.439092268117292\n",
      "trading_volumes   -1.7122149246925864\n",
      "price_volatilities   -1.1317736553307134\n",
      "vwaps_order_sizes_buy   -1.095407636693224\n",
      "vwaps_order_sizes_sell   -1.0771679330478436\n",
      "s2f_order_sizes_buy   -1.5615690652859455\n",
      "s2f_order_sizes_sell   -1.1217513980034968\n",
      "next_trade_time   0.02472337671960223\n",
      "next_trade_size   -1.2516525405215182\n",
      "next_trade_price   0.3868462187460757\n",
      "Number of positive class in training dataset = 46\n",
      "Number of negative class in training dataset = 278\n",
      "Number of positive class in testing dataset = 1\n",
      "Number of negative class in testing dataset = 35\n",
      "Percent of correct classification:\n",
      "0.9722222222222222\n",
      "Confusion matrix:\n",
      "[[ 0  1]\n",
      " [ 0 35]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "Coefficient impact:\n",
      "order_inbalance   2.734744912125664\n",
      "vwaps_buy   0.4512622740085169\n",
      "vwaps_sell   0.2669106062339605\n",
      "s2f_impact_buy   -0.20212019592098018\n",
      "s2f_impact_sell   2.4356491285003403\n",
      "trading_volumes   -1.589871371716406\n",
      "price_volatilities   -1.2401763052460872\n",
      "vwaps_order_sizes_buy   -1.2741543394944503\n",
      "vwaps_order_sizes_sell   -1.2065400302561569\n",
      "s2f_order_sizes_buy   -1.5048163070856448\n",
      "s2f_order_sizes_sell   -1.3168068192190503\n",
      "next_trade_time   -0.0385652958523186\n",
      "next_trade_size   -1.1157743742913986\n",
      "next_trade_price   0.45638153940863496\n",
      "Number of positive class in training dataset = 47\n",
      "Number of negative class in training dataset = 277\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "1.0\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 0 36]]\n",
      "Coefficient impact:\n",
      "order_inbalance   1.194811175145934\n",
      "vwaps_buy   1.2247367799646791\n",
      "vwaps_sell   0.9639165807046578\n",
      "s2f_impact_buy   -0.10108149869081608\n",
      "s2f_impact_sell   2.2449105408381733\n",
      "trading_volumes   -1.4486001447430836\n",
      "price_volatilities   -0.4244157830279643\n",
      "vwaps_order_sizes_buy   -1.1113583774040143\n",
      "vwaps_order_sizes_sell   -0.6981797245716141\n",
      "s2f_order_sizes_buy   -0.8816286438319256\n",
      "s2f_order_sizes_sell   -0.7424594225089229\n",
      "next_trade_time   0.052161204267527655\n",
      "next_trade_size   -0.6576948128353666\n",
      "next_trade_price   0.6764184036766946\n",
      "Number of positive class in training dataset = 26\n",
      "Number of negative class in training dataset = 298\n",
      "Number of positive class in testing dataset = 21\n",
      "Number of negative class in testing dataset = 15\n",
      "Percent of correct classification:\n",
      "0.4166666666666667\n",
      "Confusion matrix:\n",
      "[[ 0 21]\n",
      " [ 0 15]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "Coefficient impact:\n",
      "order_inbalance   2.727744501429827\n",
      "vwaps_buy   0.30358023415243707\n",
      "vwaps_sell   0.46969499990107005\n",
      "s2f_impact_buy   -0.31247876609617586\n",
      "s2f_impact_sell   2.5085922249143744\n",
      "trading_volumes   -1.8848472611562912\n",
      "price_volatilities   -1.1669102704459668\n",
      "vwaps_order_sizes_buy   -1.1017959317948347\n",
      "vwaps_order_sizes_sell   -1.3558351260700459\n",
      "s2f_order_sizes_buy   -1.6460949281568653\n",
      "s2f_order_sizes_sell   -1.2867220776108703\n",
      "next_trade_time   -0.017859892238699316\n",
      "next_trade_size   -0.888124634131751\n",
      "next_trade_price   0.38471228833077\n",
      "Number of positive class in training dataset = 44\n",
      "Number of negative class in training dataset = 280\n",
      "Number of positive class in testing dataset = 3\n",
      "Number of negative class in testing dataset = 33\n",
      "Percent of correct classification:\n",
      "0.9166666666666666\n",
      "Confusion matrix:\n",
      "[[ 0  3]\n",
      " [ 0 33]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "Coefficient impact:\n",
      "order_inbalance   3.5069541093895165\n",
      "vwaps_buy   0.6469530256486996\n",
      "vwaps_sell   0.6796096873726591\n",
      "s2f_impact_buy   -0.24583694246255838\n",
      "s2f_impact_sell   2.2089565709168815\n",
      "trading_volumes   -1.4851605656116975\n",
      "price_volatilities   -1.6951976821175836\n",
      "vwaps_order_sizes_buy   -0.8833303938755054\n",
      "vwaps_order_sizes_sell   -1.0253806640381657\n",
      "s2f_order_sizes_buy   -1.3962244563343924\n",
      "s2f_order_sizes_sell   -1.0018611636453467\n",
      "next_trade_time   0.2847780086382433\n",
      "next_trade_size   -0.8686612887864147\n",
      "next_trade_price   0.22438409544818147\n",
      "Number of positive class in training dataset = 42\n",
      "Number of negative class in training dataset = 282\n",
      "Number of positive class in testing dataset = 5\n",
      "Number of negative class in testing dataset = 31\n",
      "Percent of correct classification:\n",
      "0.8611111111111112\n",
      "Confusion matrix:\n",
      "[[ 0  5]\n",
      " [ 0 31]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "<ipython-input-41-0a9b583c1b63>:39: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n"
     ]
    }
   ],
   "source": [
    "interval=5\n",
    "time_to_skip=30\n",
    "time_back=60\n",
    "y_name='true_price'\n",
    "swing_interval = 180\n",
    "check = 'swing_min'\n",
    "use_scaling = True\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.005\n",
    "sum_of_acc = 0.0\n",
    "sum_of_prec = 0.0\n",
    "sum_of_recall = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, 'log_reg',use_scaling = use_scaling)\n",
    "    sum_of_acc+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: nan\n",
      "Average precision with scaling: nan\n",
      "Average recall with scaling: nan\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy with scaling:\",sum_of_acc/99)\n",
    "print(\"Average precision with scaling:\",sum_of_prec/99)\n",
    "print(\"Average recall with scaling:\",sum_of_recall/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bez skalowania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean of all companies for max:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n",
      "[10:50:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 843\n",
      "Number of negative class in training dataset = 552\n",
      "Number of positive class in testing dataset = 92\n",
      "Number of negative class in testing dataset = 63\n",
      "Percent of correct classification:\n",
      "0.5161290322580645\n",
      "Confusion matrix:\n",
      "[[54 38]\n",
      " [37 26]]\n",
      "Precision:\n",
      "0.5869565217391305\n",
      "Recall:\n",
      "0.5934065934065934\n",
      "[10:50:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 832\n",
      "Number of negative class in training dataset = 563\n",
      "Number of positive class in testing dataset = 103\n",
      "Number of negative class in testing dataset = 52\n",
      "Percent of correct classification:\n",
      "0.6451612903225806\n",
      "Confusion matrix:\n",
      "[[76 27]\n",
      " [28 24]]\n",
      "Precision:\n",
      "0.7378640776699029\n",
      "Recall:\n",
      "0.7307692307692307\n",
      "[10:50:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 844\n",
      "Number of negative class in training dataset = 551\n",
      "Number of positive class in testing dataset = 91\n",
      "Number of negative class in testing dataset = 64\n",
      "Percent of correct classification:\n",
      "0.5741935483870968\n",
      "Confusion matrix:\n",
      "[[68 23]\n",
      " [43 21]]\n",
      "Precision:\n",
      "0.7472527472527473\n",
      "Recall:\n",
      "0.6126126126126126\n",
      "[10:50:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 853\n",
      "Number of negative class in training dataset = 542\n",
      "Number of positive class in testing dataset = 82\n",
      "Number of negative class in testing dataset = 73\n",
      "Percent of correct classification:\n",
      "0.4064516129032258\n",
      "Confusion matrix:\n",
      "[[45 37]\n",
      " [55 18]]\n",
      "Precision:\n",
      "0.5487804878048781\n",
      "Recall:\n",
      "0.45\n",
      "[10:50:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 821\n",
      "Number of negative class in training dataset = 574\n",
      "Number of positive class in testing dataset = 114\n",
      "Number of negative class in testing dataset = 41\n",
      "Percent of correct classification:\n",
      "0.5612903225806452\n",
      "Confusion matrix:\n",
      "[[61 53]\n",
      " [15 26]]\n",
      "Precision:\n",
      "0.5350877192982456\n",
      "Recall:\n",
      "0.8026315789473685\n",
      "[10:50:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 835\n",
      "Number of negative class in training dataset = 560\n",
      "Number of positive class in testing dataset = 100\n",
      "Number of negative class in testing dataset = 55\n",
      "Percent of correct classification:\n",
      "0.7032258064516129\n",
      "Confusion matrix:\n",
      "[[86 14]\n",
      " [32 23]]\n",
      "Precision:\n",
      "0.86\n",
      "Recall:\n",
      "0.7288135593220338\n",
      "[10:50:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 815\n",
      "Number of negative class in training dataset = 580\n",
      "Number of positive class in testing dataset = 120\n",
      "Number of negative class in testing dataset = 35\n",
      "Percent of correct classification:\n",
      "0.6516129032258065\n",
      "Confusion matrix:\n",
      "[[82 38]\n",
      " [16 19]]\n",
      "Precision:\n",
      "0.6833333333333333\n",
      "Recall:\n",
      "0.8367346938775511\n",
      "[10:50:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 884\n",
      "Number of negative class in training dataset = 511\n",
      "Number of positive class in testing dataset = 51\n",
      "Number of negative class in testing dataset = 104\n",
      "Percent of correct classification:\n",
      "0.3548387096774194\n",
      "Confusion matrix:\n",
      "[[42  9]\n",
      " [91 13]]\n",
      "Precision:\n",
      "0.8235294117647058\n",
      "Recall:\n",
      "0.3157894736842105\n",
      "[10:50:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 854\n",
      "Number of negative class in training dataset = 541\n",
      "Number of positive class in testing dataset = 81\n",
      "Number of negative class in testing dataset = 74\n",
      "Percent of correct classification:\n",
      "0.6645161290322581\n",
      "Confusion matrix:\n",
      "[[65 16]\n",
      " [36 38]]\n",
      "Precision:\n",
      "0.8024691358024691\n",
      "Recall:\n",
      "0.6435643564356436\n",
      "[10:50:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 834\n",
      "Number of negative class in training dataset = 561\n",
      "Number of positive class in testing dataset = 101\n",
      "Number of negative class in testing dataset = 54\n",
      "Percent of correct classification:\n",
      "0.5870967741935483\n",
      "Confusion matrix:\n",
      "[[75 26]\n",
      " [38 16]]\n",
      "Precision:\n",
      "0.7425742574257426\n",
      "Recall:\n",
      "0.6637168141592921\n"
     ]
    }
   ],
   "source": [
    "interval=3\n",
    "time_to_skip=30\n",
    "time_back=5\n",
    "y_name='true_price'\n",
    "swing_interval = 60\n",
    "check = 'swing_max'\n",
    "use_scaling = False\n",
    "model = 'xgb'\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.001\n",
    "sum_of_acc_xgb = 0.0\n",
    "sum_of_prec_xgb = 0.0\n",
    "sum_of_recall_xgb = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, model = model,use_scaling = use_scaling)\n",
    "    sum_of_acc_xgb+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec_xgb += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall_xgb += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: 0.5523884001303355\n",
      "Average precision with scaling: 0.6682267891620438\n",
      "Average recall with scaling: 0.6117661260258433\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy without scaling:\",sum_of_acc_xgb/99)\n",
    "print(\"Average precision without scaling:\",sum_of_prec_xgb/99)\n",
    "print(\"Average recall without scaling:\",sum_of_recall_xgb/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean of all companies for min:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n",
      "[11:00:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 897\n",
      "Number of negative class in training dataset = 498\n",
      "Number of positive class in testing dataset = 88\n",
      "Number of negative class in testing dataset = 67\n",
      "Percent of correct classification:\n",
      "0.5935483870967742\n",
      "Confusion matrix:\n",
      "[[69 19]\n",
      " [44 23]]\n",
      "Precision:\n",
      "0.7840909090909091\n",
      "Recall:\n",
      "0.6106194690265486\n",
      "[11:00:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 885\n",
      "Number of negative class in training dataset = 510\n",
      "Number of positive class in testing dataset = 100\n",
      "Number of negative class in testing dataset = 55\n",
      "Percent of correct classification:\n",
      "0.6387096774193548\n",
      "Confusion matrix:\n",
      "[[83 17]\n",
      " [39 16]]\n",
      "Precision:\n",
      "0.83\n",
      "Recall:\n",
      "0.680327868852459\n",
      "[11:00:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 873\n",
      "Number of negative class in training dataset = 522\n",
      "Number of positive class in testing dataset = 112\n",
      "Number of negative class in testing dataset = 43\n",
      "Percent of correct classification:\n",
      "0.632258064516129\n",
      "Confusion matrix:\n",
      "[[71 41]\n",
      " [16 27]]\n",
      "Precision:\n",
      "0.6339285714285714\n",
      "Recall:\n",
      "0.8160919540229885\n",
      "[11:00:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 889\n",
      "Number of negative class in training dataset = 506\n",
      "Number of positive class in testing dataset = 96\n",
      "Number of negative class in testing dataset = 59\n",
      "Percent of correct classification:\n",
      "0.6451612903225806\n",
      "Confusion matrix:\n",
      "[[70 26]\n",
      " [29 30]]\n",
      "Precision:\n",
      "0.7291666666666666\n",
      "Recall:\n",
      "0.7070707070707071\n",
      "[11:00:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 913\n",
      "Number of negative class in training dataset = 482\n",
      "Number of positive class in testing dataset = 72\n",
      "Number of negative class in testing dataset = 83\n",
      "Percent of correct classification:\n",
      "0.5612903225806452\n",
      "Confusion matrix:\n",
      "[[62 10]\n",
      " [58 25]]\n",
      "Precision:\n",
      "0.8611111111111112\n",
      "Recall:\n",
      "0.5166666666666667\n",
      "[11:00:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 879\n",
      "Number of negative class in training dataset = 516\n",
      "Number of positive class in testing dataset = 106\n",
      "Number of negative class in testing dataset = 49\n",
      "Percent of correct classification:\n",
      "0.5483870967741935\n",
      "Confusion matrix:\n",
      "[[76 30]\n",
      " [40  9]]\n",
      "Precision:\n",
      "0.7169811320754716\n",
      "Recall:\n",
      "0.6551724137931034\n",
      "[11:00:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 900\n",
      "Number of negative class in training dataset = 495\n",
      "Number of positive class in testing dataset = 85\n",
      "Number of negative class in testing dataset = 70\n",
      "Percent of correct classification:\n",
      "0.5935483870967742\n",
      "Confusion matrix:\n",
      "[[65 20]\n",
      " [43 27]]\n",
      "Precision:\n",
      "0.7647058823529411\n",
      "Recall:\n",
      "0.6018518518518519\n",
      "[11:00:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 858\n",
      "Number of negative class in training dataset = 537\n",
      "Number of positive class in testing dataset = 127\n",
      "Number of negative class in testing dataset = 28\n",
      "Percent of correct classification:\n",
      "0.5806451612903226\n",
      "Confusion matrix:\n",
      "[[80 47]\n",
      " [18 10]]\n",
      "Precision:\n",
      "0.6299212598425197\n",
      "Recall:\n",
      "0.8163265306122449\n",
      "[11:00:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 881\n",
      "Number of negative class in training dataset = 514\n",
      "Number of positive class in testing dataset = 104\n",
      "Number of negative class in testing dataset = 51\n",
      "Percent of correct classification:\n",
      "0.567741935483871\n",
      "Confusion matrix:\n",
      "[[83 21]\n",
      " [46  5]]\n",
      "Precision:\n",
      "0.7980769230769231\n",
      "Recall:\n",
      "0.6434108527131783\n",
      "[11:00:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 890\n",
      "Number of negative class in training dataset = 505\n",
      "Number of positive class in testing dataset = 95\n",
      "Number of negative class in testing dataset = 60\n",
      "Percent of correct classification:\n",
      "0.5806451612903226\n",
      "Confusion matrix:\n",
      "[[81 14]\n",
      " [51  9]]\n",
      "Precision:\n",
      "0.8526315789473684\n",
      "Recall:\n",
      "0.6136363636363636\n"
     ]
    }
   ],
   "source": [
    "interval=3\n",
    "time_to_skip=30\n",
    "time_back=5\n",
    "y_name='true_price'\n",
    "swing_interval = 60\n",
    "check = 'swing_min'\n",
    "use_scaling = False\n",
    "model = 'xgb'\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.001\n",
    "sum_of_acc_xgb = 0.0\n",
    "sum_of_prec_xgb = 0.0\n",
    "sum_of_recall_xgb = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, model = model,use_scaling = use_scaling)\n",
    "    sum_of_acc_xgb+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec_xgb += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall_xgb += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: 0.5414793092212448\n",
      "Average precision with scaling: 0.6484219982877512\n",
      "Average recall with scaling: 0.5942665976192917\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy with scaling:\",sum_of_acc_xgb/99)\n",
    "print(\"Average precision with scaling:\",sum_of_prec_xgb/99)\n",
    "print(\"Average recall with scaling:\",sum_of_recall_xgb/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ze skalowaniem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean of all companies for max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:08:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 843\n",
      "Number of negative class in training dataset = 552\n",
      "Number of positive class in testing dataset = 92\n",
      "Number of negative class in testing dataset = 63\n",
      "Percent of correct classification:\n",
      "0.5225806451612903\n",
      "Confusion matrix:\n",
      "[[48 44]\n",
      " [30 33]]\n",
      "Precision:\n",
      "0.5217391304347826\n",
      "Recall:\n",
      "0.6153846153846154\n",
      "[11:08:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 832\n",
      "Number of negative class in training dataset = 563\n",
      "Number of positive class in testing dataset = 103\n",
      "Number of negative class in testing dataset = 52\n",
      "Percent of correct classification:\n",
      "0.632258064516129\n",
      "Confusion matrix:\n",
      "[[69 34]\n",
      " [23 29]]\n",
      "Precision:\n",
      "0.6699029126213593\n",
      "Recall:\n",
      "0.75\n",
      "[11:08:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 844\n",
      "Number of negative class in training dataset = 551\n",
      "Number of positive class in testing dataset = 91\n",
      "Number of negative class in testing dataset = 64\n",
      "Percent of correct classification:\n",
      "0.45806451612903226\n",
      "Confusion matrix:\n",
      "[[48 43]\n",
      " [41 23]]\n",
      "Precision:\n",
      "0.5274725274725275\n",
      "Recall:\n",
      "0.5393258426966292\n",
      "[11:08:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 853\n",
      "Number of negative class in training dataset = 542\n",
      "Number of positive class in testing dataset = 82\n",
      "Number of negative class in testing dataset = 73\n",
      "Percent of correct classification:\n",
      "0.41935483870967744\n",
      "Confusion matrix:\n",
      "[[49 33]\n",
      " [57 16]]\n",
      "Precision:\n",
      "0.5975609756097561\n",
      "Recall:\n",
      "0.46226415094339623\n",
      "[11:08:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 821\n",
      "Number of negative class in training dataset = 574\n",
      "Number of positive class in testing dataset = 114\n",
      "Number of negative class in testing dataset = 41\n",
      "Percent of correct classification:\n",
      "0.5096774193548387\n",
      "Confusion matrix:\n",
      "[[53 61]\n",
      " [15 26]]\n",
      "Precision:\n",
      "0.4649122807017544\n",
      "Recall:\n",
      "0.7794117647058824\n",
      "[11:08:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 835\n",
      "Number of negative class in training dataset = 560\n",
      "Number of positive class in testing dataset = 100\n",
      "Number of negative class in testing dataset = 55\n",
      "Percent of correct classification:\n",
      "0.6774193548387096\n",
      "Confusion matrix:\n",
      "[[79 21]\n",
      " [29 26]]\n",
      "Precision:\n",
      "0.79\n",
      "Recall:\n",
      "0.7314814814814815\n",
      "[11:08:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 815\n",
      "Number of negative class in training dataset = 580\n",
      "Number of positive class in testing dataset = 120\n",
      "Number of negative class in testing dataset = 35\n",
      "Percent of correct classification:\n",
      "0.5161290322580645\n",
      "Confusion matrix:\n",
      "[[61 59]\n",
      " [16 19]]\n",
      "Precision:\n",
      "0.5083333333333333\n",
      "Recall:\n",
      "0.7922077922077922\n",
      "[11:08:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 884\n",
      "Number of negative class in training dataset = 511\n",
      "Number of positive class in testing dataset = 51\n",
      "Number of negative class in testing dataset = 104\n",
      "Percent of correct classification:\n",
      "0.3225806451612903\n",
      "Confusion matrix:\n",
      "[[40 11]\n",
      " [94 10]]\n",
      "Precision:\n",
      "0.7843137254901961\n",
      "Recall:\n",
      "0.29850746268656714\n",
      "[11:08:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 854\n",
      "Number of negative class in training dataset = 541\n",
      "Number of positive class in testing dataset = 81\n",
      "Number of negative class in testing dataset = 74\n",
      "Percent of correct classification:\n",
      "0.5870967741935483\n",
      "Confusion matrix:\n",
      "[[48 33]\n",
      " [31 43]]\n",
      "Precision:\n",
      "0.5925925925925926\n",
      "Recall:\n",
      "0.6075949367088608\n",
      "[11:08:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 834\n",
      "Number of negative class in training dataset = 561\n",
      "Number of positive class in testing dataset = 101\n",
      "Number of negative class in testing dataset = 54\n",
      "Percent of correct classification:\n",
      "0.5612903225806452\n",
      "Confusion matrix:\n",
      "[[72 29]\n",
      " [39 15]]\n",
      "Precision:\n",
      "0.7128712871287128\n",
      "Recall:\n",
      "0.6486486486486487\n"
     ]
    }
   ],
   "source": [
    "interval=3\n",
    "time_to_skip=30\n",
    "time_back=5\n",
    "y_name='true_price'\n",
    "swing_interval = 60\n",
    "check = 'swing_max'\n",
    "use_scaling = True\n",
    "model = 'xgb'\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.001\n",
    "sum_of_acc_xgb = 0.0\n",
    "sum_of_prec_xgb = 0.0\n",
    "sum_of_recall_xgb = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, model = model,use_scaling = use_scaling)\n",
    "    sum_of_acc_xgb+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec_xgb += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall_xgb += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: 0.5425610948191594\n",
      "Average precision with scaling: 0.6300610007028212\n",
      "Average recall with scaling: 0.6126012589170201\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy without scaling:\",sum_of_acc_xgb/99)\n",
    "print(\"Average precision without scaling:\",sum_of_prec_xgb/99)\n",
    "print(\"Average recall without scaling:\",sum_of_recall_xgb/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean of all companies for min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:15:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 897\n",
      "Number of negative class in training dataset = 498\n",
      "Number of positive class in testing dataset = 88\n",
      "Number of negative class in testing dataset = 67\n",
      "Percent of correct classification:\n",
      "0.5741935483870968\n",
      "Confusion matrix:\n",
      "[[64 24]\n",
      " [42 25]]\n",
      "Precision:\n",
      "0.7272727272727273\n",
      "Recall:\n",
      "0.6037735849056604\n",
      "[11:15:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 885\n",
      "Number of negative class in training dataset = 510\n",
      "Number of positive class in testing dataset = 100\n",
      "Number of negative class in testing dataset = 55\n",
      "Percent of correct classification:\n",
      "0.6258064516129033\n",
      "Confusion matrix:\n",
      "[[78 22]\n",
      " [36 19]]\n",
      "Precision:\n",
      "0.78\n",
      "Recall:\n",
      "0.6842105263157895\n",
      "[11:15:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 873\n",
      "Number of negative class in training dataset = 522\n",
      "Number of positive class in testing dataset = 112\n",
      "Number of negative class in testing dataset = 43\n",
      "Percent of correct classification:\n",
      "0.5548387096774193\n",
      "Confusion matrix:\n",
      "[[58 54]\n",
      " [15 28]]\n",
      "Precision:\n",
      "0.5178571428571429\n",
      "Recall:\n",
      "0.7945205479452054\n",
      "[11:15:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 889\n",
      "Number of negative class in training dataset = 506\n",
      "Number of positive class in testing dataset = 96\n",
      "Number of negative class in testing dataset = 59\n",
      "Percent of correct classification:\n",
      "0.6709677419354839\n",
      "Confusion matrix:\n",
      "[[61 35]\n",
      " [16 43]]\n",
      "Precision:\n",
      "0.6354166666666666\n",
      "Recall:\n",
      "0.7922077922077922\n",
      "[11:15:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 913\n",
      "Number of negative class in training dataset = 482\n",
      "Number of positive class in testing dataset = 72\n",
      "Number of negative class in testing dataset = 83\n",
      "Percent of correct classification:\n",
      "0.5741935483870968\n",
      "Confusion matrix:\n",
      "[[57 15]\n",
      " [51 32]]\n",
      "Precision:\n",
      "0.7916666666666666\n",
      "Recall:\n",
      "0.5277777777777778\n",
      "[11:15:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 879\n",
      "Number of negative class in training dataset = 516\n",
      "Number of positive class in testing dataset = 106\n",
      "Number of negative class in testing dataset = 49\n",
      "Percent of correct classification:\n",
      "0.43870967741935485\n",
      "Confusion matrix:\n",
      "[[59 47]\n",
      " [40  9]]\n",
      "Precision:\n",
      "0.5566037735849056\n",
      "Recall:\n",
      "0.5959595959595959\n",
      "[11:15:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 900\n",
      "Number of negative class in training dataset = 495\n",
      "Number of positive class in testing dataset = 85\n",
      "Number of negative class in testing dataset = 70\n",
      "Percent of correct classification:\n",
      "0.5741935483870968\n",
      "Confusion matrix:\n",
      "[[57 28]\n",
      " [38 32]]\n",
      "Precision:\n",
      "0.6705882352941176\n",
      "Recall:\n",
      "0.6\n",
      "[11:15:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 858\n",
      "Number of negative class in training dataset = 537\n",
      "Number of positive class in testing dataset = 127\n",
      "Number of negative class in testing dataset = 28\n",
      "Percent of correct classification:\n",
      "0.5419354838709678\n",
      "Confusion matrix:\n",
      "[[73 54]\n",
      " [17 11]]\n",
      "Precision:\n",
      "0.5748031496062992\n",
      "Recall:\n",
      "0.8111111111111111\n",
      "[11:15:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 881\n",
      "Number of negative class in training dataset = 514\n",
      "Number of positive class in testing dataset = 104\n",
      "Number of negative class in testing dataset = 51\n",
      "Percent of correct classification:\n",
      "0.5290322580645161\n",
      "Confusion matrix:\n",
      "[[78 26]\n",
      " [47  4]]\n",
      "Precision:\n",
      "0.75\n",
      "Recall:\n",
      "0.624\n",
      "[11:15:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 890\n",
      "Number of negative class in training dataset = 505\n",
      "Number of positive class in testing dataset = 95\n",
      "Number of negative class in testing dataset = 60\n",
      "Percent of correct classification:\n",
      "0.567741935483871\n",
      "Confusion matrix:\n",
      "[[76 19]\n",
      " [48 12]]\n",
      "Precision:\n",
      "0.8\n",
      "Recall:\n",
      "0.6129032258064516\n"
     ]
    }
   ],
   "source": [
    "interval=3\n",
    "time_to_skip=30\n",
    "time_back=5\n",
    "y_name='true_price'\n",
    "swing_interval = 60\n",
    "check = 'swing_min'\n",
    "use_scaling = True\n",
    "model = 'xgb'\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.001\n",
    "sum_of_acc_xgb = 0.0\n",
    "sum_of_prec_xgb = 0.0\n",
    "sum_of_recall_xgb = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, model = model,use_scaling = use_scaling)\n",
    "    sum_of_acc_xgb+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec_xgb += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall_xgb += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: 0.5347865754317367\n",
      "Average precision with scaling: 0.6160047169855155\n",
      "Average recall with scaling: 0.5946867135722924\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy with scaling:\",sum_of_acc_xgb/99)\n",
    "print(\"Average precision with scaling:\",sum_of_prec_xgb/99)\n",
    "print(\"Average recall with scaling:\",sum_of_recall_xgb/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max z kolejnej godziny patrząc na ostatnie 5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:22:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 460\n",
      "Number of negative class in training dataset = 359\n",
      "Number of positive class in testing dataset = 53\n",
      "Number of negative class in testing dataset = 38\n",
      "Percent of correct classification:\n",
      "0.5164835164835165\n",
      "Confusion matrix:\n",
      "[[28 25]\n",
      " [19 19]]\n",
      "Precision:\n",
      "0.5283018867924528\n",
      "Recall:\n",
      "0.5957446808510638\n",
      "[11:22:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 460\n",
      "Number of negative class in training dataset = 359\n",
      "Number of positive class in testing dataset = 53\n",
      "Number of negative class in testing dataset = 38\n",
      "Percent of correct classification:\n",
      "0.5274725274725275\n",
      "Confusion matrix:\n",
      "[[29 24]\n",
      " [19 19]]\n",
      "Precision:\n",
      "0.5471698113207547\n",
      "Recall:\n",
      "0.6041666666666666\n",
      "[11:22:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 465\n",
      "Number of negative class in training dataset = 354\n",
      "Number of positive class in testing dataset = 48\n",
      "Number of negative class in testing dataset = 43\n",
      "Percent of correct classification:\n",
      "0.32967032967032966\n",
      "Confusion matrix:\n",
      "[[13 35]\n",
      " [26 17]]\n",
      "Precision:\n",
      "0.2708333333333333\n",
      "Recall:\n",
      "0.3333333333333333\n",
      "[11:22:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 471\n",
      "Number of negative class in training dataset = 348\n",
      "Number of positive class in testing dataset = 42\n",
      "Number of negative class in testing dataset = 49\n",
      "Percent of correct classification:\n",
      "0.5164835164835165\n",
      "Confusion matrix:\n",
      "[[24 18]\n",
      " [26 23]]\n",
      "Precision:\n",
      "0.5714285714285714\n",
      "Recall:\n",
      "0.48\n",
      "[11:22:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 448\n",
      "Number of negative class in training dataset = 371\n",
      "Number of positive class in testing dataset = 65\n",
      "Number of negative class in testing dataset = 26\n",
      "Percent of correct classification:\n",
      "0.4835164835164835\n",
      "Confusion matrix:\n",
      "[[30 35]\n",
      " [12 14]]\n",
      "Precision:\n",
      "0.46153846153846156\n",
      "Recall:\n",
      "0.7142857142857143\n",
      "[11:22:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 459\n",
      "Number of negative class in training dataset = 360\n",
      "Number of positive class in testing dataset = 54\n",
      "Number of negative class in testing dataset = 37\n",
      "Percent of correct classification:\n",
      "0.4065934065934066\n",
      "Confusion matrix:\n",
      "[[24 30]\n",
      " [24 13]]\n",
      "Precision:\n",
      "0.4444444444444444\n",
      "Recall:\n",
      "0.5\n",
      "[11:22:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 446\n",
      "Number of negative class in training dataset = 373\n",
      "Number of positive class in testing dataset = 67\n",
      "Number of negative class in testing dataset = 24\n",
      "Percent of correct classification:\n",
      "0.4725274725274725\n",
      "Confusion matrix:\n",
      "[[26 41]\n",
      " [ 7 17]]\n",
      "Precision:\n",
      "0.3880597014925373\n",
      "Recall:\n",
      "0.7878787878787878\n",
      "[11:22:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 487\n",
      "Number of negative class in training dataset = 332\n",
      "Number of positive class in testing dataset = 26\n",
      "Number of negative class in testing dataset = 65\n",
      "Percent of correct classification:\n",
      "0.31868131868131866\n",
      "Confusion matrix:\n",
      "[[11 15]\n",
      " [47 18]]\n",
      "Precision:\n",
      "0.4230769230769231\n",
      "Recall:\n",
      "0.1896551724137931\n",
      "[11:22:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 465\n",
      "Number of negative class in training dataset = 354\n",
      "Number of positive class in testing dataset = 48\n",
      "Number of negative class in testing dataset = 43\n",
      "Percent of correct classification:\n",
      "0.5164835164835165\n",
      "Confusion matrix:\n",
      "[[31 17]\n",
      " [27 16]]\n",
      "Precision:\n",
      "0.6458333333333334\n",
      "Recall:\n",
      "0.5344827586206896\n",
      "[11:22:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 456\n",
      "Number of negative class in training dataset = 363\n",
      "Number of positive class in testing dataset = 57\n",
      "Number of negative class in testing dataset = 34\n",
      "Percent of correct classification:\n",
      "0.3626373626373626\n",
      "Confusion matrix:\n",
      "[[20 37]\n",
      " [21 13]]\n",
      "Precision:\n",
      "0.3508771929824561\n",
      "Recall:\n",
      "0.4878048780487805\n"
     ]
    }
   ],
   "source": [
    "interval=5\n",
    "time_to_skip=30\n",
    "time_back=5\n",
    "y_name='true_price'\n",
    "swing_interval = 60\n",
    "check = 'swing_max'\n",
    "use_scaling = True\n",
    "model = 'xgb'\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.001\n",
    "sum_of_acc_xgb = 0.0\n",
    "sum_of_prec_xgb = 0.0\n",
    "sum_of_recall_xgb = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, model = model,use_scaling = use_scaling)\n",
    "    sum_of_acc_xgb+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec_xgb += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall_xgb += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: 0.5323010323010325\n",
      "Average precision with scaling: 0.5925258957686671\n",
      "Average recall with scaling: 0.5803551584769941\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy with scaling:\",sum_of_acc_xgb/99)\n",
    "print(\"Average precision with scaling:\",sum_of_prec_xgb/99)\n",
    "print(\"Average recall with scaling:\",sum_of_recall_xgb/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max z kolejnej godziny patrząc na ostatnie 10 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 435\n",
      "Number of negative class in training dataset = 339\n",
      "Number of positive class in testing dataset = 48\n",
      "Number of negative class in testing dataset = 38\n",
      "Percent of correct classification:\n",
      "0.5697674418604651\n",
      "Confusion matrix:\n",
      "[[20 28]\n",
      " [ 9 29]]\n",
      "Precision:\n",
      "0.4166666666666667\n",
      "Recall:\n",
      "0.6896551724137931\n",
      "[11:28:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 431\n",
      "Number of negative class in training dataset = 343\n",
      "Number of positive class in testing dataset = 52\n",
      "Number of negative class in testing dataset = 34\n",
      "Percent of correct classification:\n",
      "0.5116279069767442\n",
      "Confusion matrix:\n",
      "[[36 16]\n",
      " [26  8]]\n",
      "Precision:\n",
      "0.6923076923076923\n",
      "Recall:\n",
      "0.5806451612903226\n",
      "[11:28:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 438\n",
      "Number of negative class in training dataset = 336\n",
      "Number of positive class in testing dataset = 45\n",
      "Number of negative class in testing dataset = 41\n",
      "Percent of correct classification:\n",
      "0.20930232558139536\n",
      "Confusion matrix:\n",
      "[[13 32]\n",
      " [36  5]]\n",
      "Precision:\n",
      "0.28888888888888886\n",
      "Recall:\n",
      "0.2653061224489796\n",
      "[11:28:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 444\n",
      "Number of negative class in training dataset = 330\n",
      "Number of positive class in testing dataset = 39\n",
      "Number of negative class in testing dataset = 47\n",
      "Percent of correct classification:\n",
      "0.5348837209302325\n",
      "Confusion matrix:\n",
      "[[22 17]\n",
      " [23 24]]\n",
      "Precision:\n",
      "0.5641025641025641\n",
      "Recall:\n",
      "0.4888888888888889\n",
      "[11:28:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 422\n",
      "Number of negative class in training dataset = 352\n",
      "Number of positive class in testing dataset = 61\n",
      "Number of negative class in testing dataset = 25\n",
      "Percent of correct classification:\n",
      "0.3953488372093023\n",
      "Confusion matrix:\n",
      "[[21 40]\n",
      " [12 13]]\n",
      "Precision:\n",
      "0.3442622950819672\n",
      "Recall:\n",
      "0.6363636363636364\n",
      "[11:28:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 430\n",
      "Number of negative class in training dataset = 344\n",
      "Number of positive class in testing dataset = 53\n",
      "Number of negative class in testing dataset = 33\n",
      "Percent of correct classification:\n",
      "0.45348837209302323\n",
      "Confusion matrix:\n",
      "[[28 25]\n",
      " [22 11]]\n",
      "Precision:\n",
      "0.5283018867924528\n",
      "Recall:\n",
      "0.56\n",
      "[11:28:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 421\n",
      "Number of negative class in training dataset = 353\n",
      "Number of positive class in testing dataset = 62\n",
      "Number of negative class in testing dataset = 24\n",
      "Percent of correct classification:\n",
      "0.5232558139534884\n",
      "Confusion matrix:\n",
      "[[36 26]\n",
      " [15  9]]\n",
      "Precision:\n",
      "0.5806451612903226\n",
      "Recall:\n",
      "0.7058823529411765\n",
      "[11:28:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 460\n",
      "Number of negative class in training dataset = 314\n",
      "Number of positive class in testing dataset = 23\n",
      "Number of negative class in testing dataset = 63\n",
      "Percent of correct classification:\n",
      "0.47674418604651164\n",
      "Confusion matrix:\n",
      "[[11 12]\n",
      " [33 30]]\n",
      "Precision:\n",
      "0.4782608695652174\n",
      "Recall:\n",
      "0.25\n",
      "[11:28:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 435\n",
      "Number of negative class in training dataset = 339\n",
      "Number of positive class in testing dataset = 48\n",
      "Number of negative class in testing dataset = 38\n",
      "Percent of correct classification:\n",
      "0.5930232558139535\n",
      "Confusion matrix:\n",
      "[[42  6]\n",
      " [29  9]]\n",
      "Precision:\n",
      "0.875\n",
      "Recall:\n",
      "0.5915492957746479\n",
      "[11:28:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 431\n",
      "Number of negative class in training dataset = 343\n",
      "Number of positive class in testing dataset = 52\n",
      "Number of negative class in testing dataset = 34\n",
      "Percent of correct classification:\n",
      "0.4883720930232558\n",
      "Confusion matrix:\n",
      "[[29 23]\n",
      " [21 13]]\n",
      "Precision:\n",
      "0.5576923076923077\n",
      "Recall:\n",
      "0.58\n"
     ]
    }
   ],
   "source": [
    "interval=5\n",
    "time_to_skip=30\n",
    "time_back=10\n",
    "y_name='true_price'\n",
    "swing_interval = 60\n",
    "check = 'swing_max'\n",
    "use_scaling = True\n",
    "model = 'xgb'\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.001\n",
    "sum_of_acc_xgb = 0.0\n",
    "sum_of_prec_xgb = 0.0\n",
    "sum_of_recall_xgb = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, model = model,use_scaling = use_scaling)\n",
    "    sum_of_acc_xgb+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec_xgb += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall_xgb += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: 0.5349541930937282\n",
      "Average precision with scaling: 0.594315967751326\n",
      "Average recall with scaling: 0.5854015548554582\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy with scaling:\",sum_of_acc_xgb/99)\n",
    "print(\"Average precision with scaling:\",sum_of_prec_xgb/99)\n",
    "print(\"Average recall with scaling:\",sum_of_recall_xgb/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min z kolejnej godziny patrząc na ostatnie 5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:34:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 487\n",
      "Number of negative class in training dataset = 332\n",
      "Number of positive class in testing dataset = 47\n",
      "Number of negative class in testing dataset = 44\n",
      "Percent of correct classification:\n",
      "0.43956043956043955\n",
      "Confusion matrix:\n",
      "[[27 20]\n",
      " [31 13]]\n",
      "Precision:\n",
      "0.574468085106383\n",
      "Recall:\n",
      "0.46551724137931033\n",
      "[11:34:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 480\n",
      "Number of negative class in training dataset = 339\n",
      "Number of positive class in testing dataset = 54\n",
      "Number of negative class in testing dataset = 37\n",
      "Percent of correct classification:\n",
      "0.5604395604395604\n",
      "Confusion matrix:\n",
      "[[44 10]\n",
      " [30  7]]\n",
      "Precision:\n",
      "0.8148148148148148\n",
      "Recall:\n",
      "0.5945945945945946\n",
      "[11:34:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 473\n",
      "Number of negative class in training dataset = 346\n",
      "Number of positive class in testing dataset = 61\n",
      "Number of negative class in testing dataset = 30\n",
      "Percent of correct classification:\n",
      "0.5714285714285714\n",
      "Confusion matrix:\n",
      "[[31 30]\n",
      " [ 9 21]]\n",
      "Precision:\n",
      "0.5081967213114754\n",
      "Recall:\n",
      "0.775\n",
      "[11:34:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 479\n",
      "Number of negative class in training dataset = 340\n",
      "Number of positive class in testing dataset = 55\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "0.6813186813186813\n",
      "Confusion matrix:\n",
      "[[27 28]\n",
      " [ 1 35]]\n",
      "Precision:\n",
      "0.4909090909090909\n",
      "Recall:\n",
      "0.9642857142857143\n",
      "[11:34:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 498\n",
      "Number of negative class in training dataset = 321\n",
      "Number of positive class in testing dataset = 36\n",
      "Number of negative class in testing dataset = 55\n",
      "Percent of correct classification:\n",
      "0.5274725274725275\n",
      "Confusion matrix:\n",
      "[[24 12]\n",
      " [31 24]]\n",
      "Precision:\n",
      "0.6666666666666666\n",
      "Recall:\n",
      "0.43636363636363634\n",
      "[11:34:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 475\n",
      "Number of negative class in training dataset = 344\n",
      "Number of positive class in testing dataset = 59\n",
      "Number of negative class in testing dataset = 32\n",
      "Percent of correct classification:\n",
      "0.4835164835164835\n",
      "Confusion matrix:\n",
      "[[33 26]\n",
      " [21 11]]\n",
      "Precision:\n",
      "0.559322033898305\n",
      "Recall:\n",
      "0.6111111111111112\n",
      "[11:34:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 491\n",
      "Number of negative class in training dataset = 328\n",
      "Number of positive class in testing dataset = 43\n",
      "Number of negative class in testing dataset = 48\n",
      "Percent of correct classification:\n",
      "0.5714285714285714\n",
      "Confusion matrix:\n",
      "[[35  8]\n",
      " [31 17]]\n",
      "Precision:\n",
      "0.813953488372093\n",
      "Recall:\n",
      "0.5303030303030303\n",
      "[11:34:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 464\n",
      "Number of negative class in training dataset = 355\n",
      "Number of positive class in testing dataset = 70\n",
      "Number of negative class in testing dataset = 21\n",
      "Percent of correct classification:\n",
      "0.6483516483516484\n",
      "Confusion matrix:\n",
      "[[45 25]\n",
      " [ 7 14]]\n",
      "Precision:\n",
      "0.6428571428571429\n",
      "Recall:\n",
      "0.8653846153846154\n",
      "[11:34:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 474\n",
      "Number of negative class in training dataset = 345\n",
      "Number of positive class in testing dataset = 60\n",
      "Number of negative class in testing dataset = 31\n",
      "Percent of correct classification:\n",
      "0.5934065934065934\n",
      "Confusion matrix:\n",
      "[[46 14]\n",
      " [23  8]]\n",
      "Precision:\n",
      "0.7666666666666667\n",
      "Recall:\n",
      "0.6666666666666666\n",
      "[11:34:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 485\n",
      "Number of negative class in training dataset = 334\n",
      "Number of positive class in testing dataset = 49\n",
      "Number of negative class in testing dataset = 42\n",
      "Percent of correct classification:\n",
      "0.45054945054945056\n",
      "Confusion matrix:\n",
      "[[36 13]\n",
      " [37  5]]\n",
      "Precision:\n",
      "0.7346938775510204\n",
      "Recall:\n",
      "0.4931506849315068\n"
     ]
    }
   ],
   "source": [
    "interval=5\n",
    "time_to_skip=30\n",
    "time_back=5\n",
    "y_name='true_price'\n",
    "swing_interval = 60\n",
    "check = 'swing_min'\n",
    "use_scaling = True\n",
    "model = 'xgb'\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.001\n",
    "sum_of_acc_xgb = 0.0\n",
    "sum_of_prec_xgb = 0.0\n",
    "sum_of_recall_xgb = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, model = model,use_scaling = use_scaling)\n",
    "    sum_of_acc_xgb+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec_xgb += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall_xgb += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: 0.5231879231879234\n",
      "Average precision with scaling: 0.5761647396637581\n",
      "Average recall with scaling: 0.5598581318550807\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy with scaling:\",sum_of_acc_xgb/99)\n",
    "print(\"Average precision with scaling:\",sum_of_prec_xgb/99)\n",
    "print(\"Average recall with scaling:\",sum_of_recall_xgb/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min z kolejnej godziny patrząc na ostatnie 10 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:40:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 452\n",
      "Number of negative class in training dataset = 322\n",
      "Number of positive class in testing dataset = 47\n",
      "Number of negative class in testing dataset = 39\n",
      "Percent of correct classification:\n",
      "0.6046511627906976\n",
      "Confusion matrix:\n",
      "[[40  7]\n",
      " [27 12]]\n",
      "Precision:\n",
      "0.851063829787234\n",
      "Recall:\n",
      "0.5970149253731343\n",
      "[11:40:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 450\n",
      "Number of negative class in training dataset = 324\n",
      "Number of positive class in testing dataset = 49\n",
      "Number of negative class in testing dataset = 37\n",
      "Percent of correct classification:\n",
      "0.6162790697674418\n",
      "Confusion matrix:\n",
      "[[41  8]\n",
      " [25 12]]\n",
      "Precision:\n",
      "0.8367346938775511\n",
      "Recall:\n",
      "0.6212121212121212\n",
      "[11:40:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 443\n",
      "Number of negative class in training dataset = 331\n",
      "Number of positive class in testing dataset = 56\n",
      "Number of negative class in testing dataset = 30\n",
      "Percent of correct classification:\n",
      "0.5348837209302325\n",
      "Confusion matrix:\n",
      "[[21 35]\n",
      " [ 5 25]]\n",
      "Precision:\n",
      "0.375\n",
      "Recall:\n",
      "0.8076923076923077\n",
      "[11:40:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 449\n",
      "Number of negative class in training dataset = 325\n",
      "Number of positive class in testing dataset = 50\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "0.5930232558139535\n",
      "Confusion matrix:\n",
      "[[22 28]\n",
      " [ 7 29]]\n",
      "Precision:\n",
      "0.44\n",
      "Recall:\n",
      "0.7586206896551724\n",
      "[11:40:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 465\n",
      "Number of negative class in training dataset = 309\n",
      "Number of positive class in testing dataset = 34\n",
      "Number of negative class in testing dataset = 52\n",
      "Percent of correct classification:\n",
      "0.5697674418604651\n",
      "Confusion matrix:\n",
      "[[26  8]\n",
      " [29 23]]\n",
      "Precision:\n",
      "0.7647058823529411\n",
      "Recall:\n",
      "0.4727272727272727\n",
      "[11:40:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 445\n",
      "Number of negative class in training dataset = 329\n",
      "Number of positive class in testing dataset = 54\n",
      "Number of negative class in testing dataset = 32\n",
      "Percent of correct classification:\n",
      "0.5116279069767442\n",
      "Confusion matrix:\n",
      "[[24 30]\n",
      " [12 20]]\n",
      "Precision:\n",
      "0.4444444444444444\n",
      "Recall:\n",
      "0.6666666666666666\n",
      "[11:40:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 457\n",
      "Number of negative class in training dataset = 317\n",
      "Number of positive class in testing dataset = 42\n",
      "Number of negative class in testing dataset = 44\n",
      "Percent of correct classification:\n",
      "0.6046511627906976\n",
      "Confusion matrix:\n",
      "[[35  7]\n",
      " [27 17]]\n",
      "Precision:\n",
      "0.8333333333333334\n",
      "Recall:\n",
      "0.5645161290322581\n",
      "[11:40:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 434\n",
      "Number of negative class in training dataset = 340\n",
      "Number of positive class in testing dataset = 65\n",
      "Number of negative class in testing dataset = 21\n",
      "Percent of correct classification:\n",
      "0.6627906976744186\n",
      "Confusion matrix:\n",
      "[[44 21]\n",
      " [ 8 13]]\n",
      "Precision:\n",
      "0.676923076923077\n",
      "Recall:\n",
      "0.8461538461538461\n",
      "[11:40:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 444\n",
      "Number of negative class in training dataset = 330\n",
      "Number of positive class in testing dataset = 55\n",
      "Number of negative class in testing dataset = 31\n",
      "Percent of correct classification:\n",
      "0.6162790697674418\n",
      "Confusion matrix:\n",
      "[[49  6]\n",
      " [27  4]]\n",
      "Precision:\n",
      "0.8909090909090909\n",
      "Recall:\n",
      "0.6447368421052632\n",
      "[11:40:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 452\n",
      "Number of negative class in training dataset = 322\n",
      "Number of positive class in testing dataset = 47\n",
      "Number of negative class in testing dataset = 39\n",
      "Percent of correct classification:\n",
      "0.5\n",
      "Confusion matrix:\n",
      "[[36 11]\n",
      " [32  7]]\n",
      "Precision:\n",
      "0.7659574468085106\n",
      "Recall:\n",
      "0.5294117647058824\n"
     ]
    }
   ],
   "source": [
    "interval=5\n",
    "time_to_skip=30\n",
    "time_back=10\n",
    "y_name='true_price'\n",
    "swing_interval = 60\n",
    "check = 'swing_min'\n",
    "use_scaling = True\n",
    "model = 'xgb'\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.001\n",
    "sum_of_acc_xgb = 0.0\n",
    "sum_of_prec_xgb = 0.0\n",
    "sum_of_recall_xgb = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, model = model,use_scaling = use_scaling)\n",
    "    sum_of_acc_xgb+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec_xgb += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall_xgb += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: 0.5142706131078223\n",
      "Average precision with scaling: 0.5498742053257208\n",
      "Average recall with scaling: 0.5445310605497603\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy with scaling:\",sum_of_acc_xgb/99)\n",
    "print(\"Average precision with scaling:\",sum_of_prec_xgb/99)\n",
    "print(\"Average recall with scaling:\",sum_of_recall_xgb/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max z kolejnych 3 godzin patrząc na ostatnie 30 min i biorąc threshold 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:46:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 102\n",
      "Number of negative class in training dataset = 492\n",
      "Number of positive class in testing dataset = 16\n",
      "Number of negative class in testing dataset = 50\n",
      "Percent of correct classification:\n",
      "0.7575757575757576\n",
      "Confusion matrix:\n",
      "[[ 5 11]\n",
      " [ 5 45]]\n",
      "Precision:\n",
      "0.3125\n",
      "Recall:\n",
      "0.5\n",
      "[11:46:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 116\n",
      "Number of negative class in training dataset = 478\n",
      "Number of positive class in testing dataset = 2\n",
      "Number of negative class in testing dataset = 64\n",
      "Percent of correct classification:\n",
      "0.8787878787878788\n",
      "Confusion matrix:\n",
      "[[ 0  2]\n",
      " [ 6 58]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "0.0\n",
      "[11:46:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 80\n",
      "Number of negative class in training dataset = 514\n",
      "Number of positive class in testing dataset = 38\n",
      "Number of negative class in testing dataset = 28\n",
      "Percent of correct classification:\n",
      "0.42424242424242425\n",
      "Confusion matrix:\n",
      "[[ 0 38]\n",
      " [ 0 28]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "[11:46:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-56ac5bcae465>:23: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 115\n",
      "Number of negative class in training dataset = 479\n",
      "Number of positive class in testing dataset = 3\n",
      "Number of negative class in testing dataset = 63\n",
      "Percent of correct classification:\n",
      "0.9545454545454546\n",
      "Confusion matrix:\n",
      "[[ 0  3]\n",
      " [ 0 63]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "[11:46:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-56ac5bcae465>:23: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 87\n",
      "Number of negative class in training dataset = 507\n",
      "Number of positive class in testing dataset = 31\n",
      "Number of negative class in testing dataset = 35\n",
      "Percent of correct classification:\n",
      "0.5303030303030303\n",
      "Confusion matrix:\n",
      "[[ 0 31]\n",
      " [ 0 35]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "[11:46:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-56ac5bcae465>:23: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 117\n",
      "Number of negative class in training dataset = 477\n",
      "Number of positive class in testing dataset = 1\n",
      "Number of negative class in testing dataset = 65\n",
      "Percent of correct classification:\n",
      "0.8939393939393939\n",
      "Confusion matrix:\n",
      "[[ 0  1]\n",
      " [ 6 59]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "0.0\n",
      "[11:46:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 105\n",
      "Number of negative class in training dataset = 489\n",
      "Number of positive class in testing dataset = 13\n",
      "Number of negative class in testing dataset = 53\n",
      "Percent of correct classification:\n",
      "0.7727272727272727\n",
      "Confusion matrix:\n",
      "[[ 0 13]\n",
      " [ 2 51]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "0.0\n",
      "[11:46:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 118\n",
      "Number of negative class in training dataset = 476\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 66\n",
      "Percent of correct classification:\n",
      "0.6818181818181818\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [21 45]]\n",
      "[11:46:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 104\n",
      "Number of negative class in training dataset = 490\n",
      "Number of positive class in testing dataset = 14\n",
      "Number of negative class in testing dataset = 52\n",
      "Percent of correct classification:\n",
      "0.7878787878787878\n",
      "Confusion matrix:\n",
      "[[ 0 14]\n",
      " [ 0 52]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "[11:46:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-56ac5bcae465>:23: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 118\n",
      "Number of negative class in training dataset = 476\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 66\n",
      "Percent of correct classification:\n",
      "0.9696969696969697\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 2 64]]\n"
     ]
    }
   ],
   "source": [
    "interval=5\n",
    "time_to_skip=30\n",
    "time_back=30\n",
    "y_name='true_price'\n",
    "swing_interval = 180\n",
    "check = 'swing_max'\n",
    "use_scaling = True\n",
    "model = 'xgb'\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.005\n",
    "sum_of_acc_xgb = 0.0\n",
    "sum_of_prec_xgb = 0.0\n",
    "sum_of_recall_xgb = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, model = model,use_scaling = use_scaling)\n",
    "    sum_of_acc_xgb+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec_xgb += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall_xgb += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: 0.6676461585552494\n",
      "Average precision with scaling: nan\n",
      "Average recall with scaling: nan\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy with scaling:\",sum_of_acc_xgb/99)\n",
    "print(\"Average precision with scaling:\",sum_of_prec_xgb/99)\n",
    "print(\"Average recall with scaling:\",sum_of_recall_xgb/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max z kolejnych 3 godzin patrząc na ostatnie 60 min i biorąc threshold 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:50:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 34\n",
      "Number of negative class in training dataset = 290\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "1.0\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 0 36]]\n",
      "[11:50:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 34\n",
      "Number of negative class in training dataset = 290\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "1.0\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 0 36]]\n",
      "[11:50:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset ="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "<ipython-input-81-56ac5bcae465>:23: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12\n",
      "Number of negative class in training dataset = 312\n",
      "Number of positive class in testing dataset = 22\n",
      "Number of negative class in testing dataset = 14\n",
      "Percent of correct classification:\n",
      "0.3888888888888889\n",
      "Confusion matrix:\n",
      "[[ 0 22]\n",
      " [ 0 14]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "[11:50:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 34\n",
      "Number of negative class in training dataset = 290\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "0.8611111111111112\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 5 31]]\n",
      "[11:50:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 24\n",
      "Number of negative class in training dataset = 300\n",
      "Number of positive class in testing dataset = 10\n",
      "Number of negative class in testing dataset = 26\n",
      "Percent of correct classification:\n",
      "0.7222222222222222\n",
      "Confusion matrix:\n",
      "[[ 0 10]\n",
      " [ 0 26]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "[11:50:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-56ac5bcae465>:23: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 34\n",
      "Number of negative class in training dataset = 290\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "1.0\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 0 36]]\n",
      "[11:50:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 32\n",
      "Number of negative class in training dataset = 292\n",
      "Number of positive class in testing dataset = 2\n",
      "Number of negative class in testing dataset = 34\n",
      "Percent of correct classification:\n",
      "0.9722222222222222\n",
      "Confusion matrix:\n",
      "[[ 1  1]\n",
      " [ 0 34]]\n",
      "Precision:\n",
      "0.5\n",
      "Recall:\n",
      "1.0\n",
      "[11:50:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 34\n",
      "Number of negative class in training dataset = 290\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "1.0\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 0 36]]\n",
      "[11:50:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 34\n",
      "Number of negative class in training dataset = 290\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "1.0\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 0 36]]\n",
      "[11:50:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset ="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34\n",
      "Number of negative class in training dataset = 290\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "1.0\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 0 36]]\n"
     ]
    }
   ],
   "source": [
    "interval=5\n",
    "time_to_skip=30\n",
    "time_back=60\n",
    "y_name='true_price'\n",
    "swing_interval = 180\n",
    "check = 'swing_max'\n",
    "use_scaling = True\n",
    "model = 'xgb'\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.005\n",
    "sum_of_acc_xgb = 0.0\n",
    "sum_of_prec_xgb = 0.0\n",
    "sum_of_recall_xgb = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, model = model,use_scaling = use_scaling)\n",
    "    sum_of_acc_xgb+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec_xgb += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall_xgb += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: 0.7453984287317623\n",
      "Average precision with scaling: nan\n",
      "Average recall with scaling: nan\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy with scaling:\",sum_of_acc_xgb/99)\n",
    "print(\"Average precision with scaling:\",sum_of_prec_xgb/99)\n",
    "print(\"Average recall with scaling:\",sum_of_recall_xgb/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min z kolejnych 3 godzin patrząc na ostatnie 30 min i biorąc threshold 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:55:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 112\n",
      "Number of negative class in training dataset = 482\n",
      "Number of positive class in testing dataset = 1\n",
      "Number of negative class in testing dataset = 65\n",
      "Percent of correct classification:\n",
      "0.5454545454545454\n",
      "Confusion matrix:\n",
      "[[ 0  1]\n",
      " [29 36]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "0.0\n",
      "[11:55:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 113\n",
      "Number of negative class in training dataset = 481\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 66\n",
      "Percent of correct classification:\n",
      "0.8939393939393939\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 7 59]]\n",
      "[11:55:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 101\n",
      "Number of negative class in training dataset = 493\n",
      "Number of positive class in testing dataset = 12\n",
      "Number of negative class in testing dataset = 54\n",
      "Percent of correct classification:\n",
      "0.8181818181818182\n",
      "Confusion matrix:\n",
      "[[ 0 12]\n",
      " [ 0 54]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "[11:55:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-56ac5bcae465>:23: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 100\n",
      "Number of negative class in training dataset = 494\n",
      "Number of positive class in testing dataset = 13\n",
      "Number of negative class in testing dataset = 53\n",
      "Percent of correct classification:\n",
      "0.7878787878787878\n",
      "Confusion matrix:\n",
      "[[ 0 13]\n",
      " [ 1 52]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "0.0\n",
      "[11:55:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 80\n",
      "Number of negative class in training dataset = 514\n",
      "Number of positive class in testing dataset = 33\n",
      "Number of negative class in testing dataset = 33\n",
      "Percent of correct classification:\n",
      "0.5151515151515151\n",
      "Confusion matrix:\n",
      "[[ 2 31]\n",
      " [ 1 32]]\n",
      "Precision:\n",
      "0.06060606060606061\n",
      "Recall:\n",
      "0.6666666666666666\n",
      "[11:55:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 112\n",
      "Number of negative class in training dataset = 482\n",
      "Number of positive class in testing dataset = 1\n",
      "Number of negative class in testing dataset = 65\n",
      "Percent of correct classification:\n",
      "0.9393939393939394\n",
      "Confusion matrix:\n",
      "[[ 0  1]\n",
      " [ 3 62]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "0.0\n",
      "[11:55:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 107\n",
      "Number of negative class in training dataset = 487\n",
      "Number of positive class in testing dataset = 6\n",
      "Number of negative class in testing dataset = 60\n",
      "Percent of correct classification:\n",
      "0.9090909090909091\n",
      "Confusion matrix:\n",
      "[[ 0  6]\n",
      " [ 0 60]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "[11:55:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-56ac5bcae465>:23: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 78\n",
      "Number of negative class in training dataset = 516\n",
      "Number of positive class in testing dataset = 35\n",
      "Number of negative class in testing dataset = 31\n",
      "Percent of correct classification:\n",
      "0.45454545454545453\n",
      "Confusion matrix:\n",
      "[[ 3 32]\n",
      " [ 4 27]]\n",
      "Precision:\n",
      "0.08571428571428572\n",
      "Recall:\n",
      "0.42857142857142855\n",
      "[11:55:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 110\n",
      "Number of negative class in training dataset = 484\n",
      "Number of positive class in testing dataset = 3\n",
      "Number of negative class in testing dataset = 63\n",
      "Percent of correct classification:\n",
      "0.9545454545454546\n",
      "Confusion matrix:\n",
      "[[ 0  3]\n",
      " [ 0 63]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "[11:55:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-56ac5bcae465>:23: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 104\n",
      "Number of negative class in training dataset = 490\n",
      "Number of positive class in testing dataset = 9\n",
      "Number of negative class in testing dataset = 57\n",
      "Percent of correct classification:\n",
      "0.8636363636363636\n",
      "Confusion matrix:\n",
      "[[ 0  9]\n",
      " [ 0 57]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-56ac5bcae465>:23: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n"
     ]
    }
   ],
   "source": [
    "interval=5\n",
    "time_to_skip=30\n",
    "time_back=30\n",
    "y_name='true_price'\n",
    "swing_interval = 180\n",
    "check = 'swing_min'\n",
    "use_scaling = True\n",
    "model = 'xgb'\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.005\n",
    "sum_of_acc_xgb = 0.0\n",
    "sum_of_prec_xgb = 0.0\n",
    "sum_of_recall_xgb = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, model = model,use_scaling = use_scaling)\n",
    "    sum_of_acc_xgb+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec_xgb += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall_xgb += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: 0.7649525558616467\n",
      "Average precision with scaling: nan\n",
      "Average recall with scaling: nan\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy with scaling:\",sum_of_acc_xgb/99)\n",
    "print(\"Average precision with scaling:\",sum_of_prec_xgb/99)\n",
    "print(\"Average recall with scaling:\",sum_of_recall_xgb/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min z kolejnych 3 godzin patrząc na ostatnie 60 min i biorąc threshold 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_id = 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:00:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 46\n",
      "Number of negative class in training dataset = 278\n",
      "Number of positive class in testing dataset = 1\n",
      "Number of negative class in testing dataset = 35\n",
      "Percent of correct classification:\n",
      "0.8333333333333334\n",
      "Confusion matrix:\n",
      "[[ 0  1]\n",
      " [ 5 30]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:00:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 47\n",
      "Number of negative class in training dataset = 277\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "0.7777777777777778\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 8 28]]\n",
      "[12:00:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of positive class in training dataset = 47\n",
      "Number of negative class in training dataset = 277\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "0.8611111111111112\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 5 31]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:00:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 46\n",
      "Number of negative class in training dataset = 278\n",
      "Number of positive class in testing dataset = 1\n",
      "Number of negative class in testing dataset = 35\n",
      "Percent of correct classification:\n",
      "0.9722222222222222\n",
      "Confusion matrix:\n",
      "[[ 0  1]\n",
      " [ 0 35]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "[12:00:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 32\n",
      "Number of negative class in training dataset = 292\n",
      "Number of positive class in testing dataset = 15\n",
      "Number of negative class in testing dataset = 21\n",
      "Percent of correct classification:\n",
      "0.5833333333333334\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-56ac5bcae465>:23: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 15]\n",
      " [ 0 21]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "[12:00:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-56ac5bcae465>:23: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive class in training dataset = 46\n",
      "Number of negative class in training dataset = 278\n",
      "Number of positive class in testing dataset = 1\n",
      "Number of negative class in testing dataset = 35\n",
      "Percent of correct classification:\n",
      "0.9722222222222222\n",
      "Confusion matrix:\n",
      "[[ 0  1]\n",
      " [ 0 35]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n",
      "[12:00:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 47\n",
      "Number of negative class in training dataset = 277\n",
      "Number of positive class in testing dataset = 0\n",
      "Number of negative class in testing dataset = 36\n",
      "Percent of correct classification:\n",
      "1.0\n",
      "Confusion matrix:\n",
      "[[ 0  0]\n",
      " [ 0 36]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-56ac5bcae465>:23: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:00:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 26\n",
      "Number of negative class in training dataset = 298\n",
      "Number of positive class in testing dataset = 21\n",
      "Number of negative class in testing dataset = 15\n",
      "Percent of correct classification:\n",
      "0.6944444444444444\n",
      "Confusion matrix:\n",
      "[[10 11]\n",
      " [ 0 15]]\n",
      "Precision:\n",
      "0.47619047619047616\n",
      "Recall:\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:00:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 44\n",
      "Number of negative class in training dataset = 280\n",
      "Number of positive class in testing dataset = 3\n",
      "Number of negative class in testing dataset = 33\n",
      "Percent of correct classification:\n",
      "0.9166666666666666\n",
      "Confusion matrix:\n",
      "[[ 0  3]\n",
      " [ 0 33]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-56ac5bcae465>:23: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:00:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Number of positive class in training dataset = 42\n",
      "Number of negative class in training dataset = 282\n",
      "Number of positive class in testing dataset = 5\n",
      "Number of negative class in testing dataset = 31\n",
      "Percent of correct classification:\n",
      "0.8611111111111112\n",
      "Confusion matrix:\n",
      "[[ 0  5]\n",
      " [ 0 31]]\n",
      "Precision:\n",
      "0.0\n",
      "Recall:\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-56ac5bcae465>:23: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  recall = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[1][0])\n"
     ]
    }
   ],
   "source": [
    "interval=5\n",
    "time_to_skip=30\n",
    "time_back=60\n",
    "y_name='true_price'\n",
    "swing_interval = 180\n",
    "check = 'swing_min'\n",
    "use_scaling = True\n",
    "model = 'xgb'\n",
    "names=[         \n",
    "   # 'mid_price',\n",
    "    #'true_price', \n",
    "    'order_inbalance', \n",
    "    'vwaps_buy', \n",
    "    'vwaps_sell', \n",
    "    's2f_impact_buy', \n",
    "    's2f_impact_sell', \n",
    "    'trading_volumes', \n",
    "    'price_volatilities',\n",
    "    'vwaps_order_sizes_buy', \n",
    "    'vwaps_order_sizes_sell',\n",
    "    's2f_order_sizes_buy', \n",
    "    's2f_order_sizes_sell',\n",
    "    'next_trade_time',\n",
    "    'next_trade_size',\n",
    "    'next_trade_price',\n",
    "    #'price change'\n",
    "      ]\n",
    "threshold = 0.005\n",
    "sum_of_acc_xgb = 0.0\n",
    "sum_of_prec_xgb = 0.0\n",
    "sum_of_recall_xgb = 0.0\n",
    "print(\"Threshold = \", threshold)\n",
    "for comp_id in range(99):\n",
    "    print(\"comp_id =\",comp_id)\n",
    "    X = get_X(comp_id, interval, time_to_skip, time_back, names)\n",
    "    y = get_y(comp_id, interval, time_to_skip, time_back, check = check, swing_interval = swing_interval, threshold=threshold)\n",
    "    res_per_day = cross_validation(X, y, model = model,use_scaling = use_scaling)\n",
    "    sum_of_acc_xgb+=np.sum(res_per_day[:,0])/res_per_day.shape[0]\n",
    "    sum_of_prec_xgb += np.sum(res_per_day[:,1])/res_per_day.shape[0]\n",
    "    sum_of_recall_xgb += np.sum(res_per_day[:,2])/res_per_day.shape[0]\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with scaling: 0.7517676767676769\n",
      "Average precision with scaling: nan\n",
      "Average recall with scaling: nan\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy with scaling:\",sum_of_acc_xgb/99)\n",
    "print(\"Average precision with scaling:\",sum_of_prec_xgb/99)\n",
    "print(\"Average recall with scaling:\",sum_of_recall_xgb/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
